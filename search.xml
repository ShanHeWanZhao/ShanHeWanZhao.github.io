<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CMS</title>
    <url>/2020-09-19/cms/</url>
    <content><![CDATA[
​	主要分析了CMS收集器的算法实现和收集流程，和部分关键参数对CMS的影响，以及三色标记如何解决对象漏标问题。并在最后总结了CMS的优缺点




​	CMS（Concurrent Mark-Sweep）是一种基于标记-清除算法实现的老年代垃圾回收器，以获取最短停顿时间为目标，适合对响应时间敏感的应用（如 Web 系统）。其核心思想是尽可能地让 GC 工作与用户线程并发执行，降低停顿时间。
​	一次CMS gc会算作两次full gc，分别为初始标记和最终标记（算上的时STW次数），但在多次收集后产生的空间碎片如果影响到了对象的分配，也会才用标记-整理算法收集一次
​	清除算法会产生空间碎片，如果cms区预留的空闲内存不能满足新对象的分配，那么会触发Concurrent Mode Failure，这时会冻结用户线程，临时启用Serial Old收集器重新回收老年代的垃圾，全程STW，耗时很长

初始标记(CMS initial mark): STW，仅标记GCRoots对象的下一个可达对象，很快
并发标记(CMS concurent mark)
重新标记(CMS remark): STW，解决并发标记时”那些消失的对象“
并发清除(CMS concurrent sweep)

1.参数
-XX:+UseConcMarkSweepGC   ： 启用CMS收集器（年轻代默认使用ParNew收集器）

–XX:CMSWaitDuration&#x3D;2000 ： cms后台线程的轮询间隔时间（ms单位)

-XX:+UseCMSInitiatingOccupancyOnly : 使用基于设定的阈值进行CMS gc，值为CMSInitiatingOccupancyFraction

-XX:CMSInitiatingOccupancyFraction&#x3D;80 : 在UseCMSInitiatingOccupancyOnly参数启用后生效。当CMS区（老年代）占比达到80%后，启用CMS垃圾回收。默认为-1，代表不启用，则老年代垃圾回收阈值算法为：**( (100 - MinHeapFreeRatio) + (CMSTriggerRatio * MinHeapFreeRatio) &#x2F; 100.0) &#x2F; 100.0** &#x3D; 92%

-XX:ConcGCThreads&#x3D;2 ：并发gc线程数，默认为（ParallelGCThreads+3）&#x2F; 4。ParallelGCThreads为新生代并行GC线程数，当CPU数量小于8时，ParallelGCThreads的值就是CPU的数量，当CPU数量大于8时，ParallelGCThreads的值等于3+5*cpuCount &#x2F; 8 （可用jstack查看）


2 三色标记2.1 含义


颜色
含义



白色
尚未被标记的对象，可能是垃圾


灰色
被标记为可达，但其内部引用的对象还没有全部扫描完


黑色
可达，且其所有引用的对象也都已经被标记（扫描完）


​	在三色标记开始时，所有对象初始状态都是白色。GC 从 GCRoots 出发，只能扫描到 GCRoots 可达的对象。每当扫描到一个新对象时，它会先被标记为灰色（表示已经被发现但尚未处理完）。当该对象的所有引用对象也都被扫描并标记后，它就会被染为黑色（表示处理完毕，不可回收）。
而对于那些不可达的对象，由于没有任何路径从 GCRoots 可以触达它们，因此它们不会被扫描，颜色保持为白色，最终被识别为垃圾对象。
因此，在三色标记结束时，只会存在黑色和白色两类对象：

黑色对象：可达、已完全处理，不能被回收
白色对象：不可达、未被处理，将被回收

2.2 问题
浮动垃圾：被标记为黑色的对象还会继续存活。但如果我们的用户线程此时对黑色对象丢弃引用，这个黑色对象就不可达了，就应该在本次垃圾清理中被回收。但这个影响不大，下次GC可进行处理
对象漏标：在并发标记阶段，应用线程可能会修改对象引用关系，导致本应可达的对象未被正确扫描，仍然保持白色，最终被误回收。有如下两种情况
对黑色对象A（此时A已完全扫描完毕）内部赋值一个白色对象B。B产生了漏标
对灰色对象C（此时C内部还未扫描完）内部暂时断开了一个对象D使其变为白色，并在扫描完成后重新将D赋值到C中



2.3 增量更新（Incremental Update）顾名思义，表示增加了引用。增量更新关注的是引用新增的情况，尤其是解决以下对象漏标场景：

黑色对象 A 在并发标记后，新增引用了一个未被标记的白色对象 B。	

在这种情况下，为了避免漏标，写屏障机制会将 A 重新标记为灰色，使其在“重新标记（Remark）”阶段重新被扫描一次，从而发现并标记 B，确保其不会被错误回收。总结就是黑色对象A一旦新插入了白色对象B的引用之后，A就变回灰色对象了。
​	CMS 使用增量更新策略，因为它是老年代回收器，老年代中的对象多数是长寿命的，结构稳定，引用新增比引用删除更常见。但增量更新只能处理“新增引用”，无法处理“引用删除”导致的漏标，因此并不完美。这也是 CMS 在 JDK9 被标记为过时的重要原因之一。
2.4 原始快照（Snapshot-At-The-Beginning，SATB）​	保存一份并发标记开始时的引用快照，当后续并发标记过程中对这些引用删除时，都会被记录到SATB缓冲区，标记结束后SATB缓冲区的对象被重新标记为存活。
​	原始快照只处理对灰色对象C删除白色对象D的情况（将D记录到SATB缓冲区），重新标记阶段会在将D标为活跃。但不处理黑色新增引用，需要依赖其他机制保证（一般都是依赖写屏障，将B直接标为存活）
​	G1使用原始快照能完全避免对象漏标，因为它就是用写屏障直接标记白色对象为存活的方式来处理给黑色对象新增的白色对象这种漏标情况。即SATB处理删除，写屏障兜底新增。虽不可避免的会增加浮动垃圾，但肯定不会漏标
3 cms gc触发条件
原文
foreground collector  ：空间分配不够触发
background collector
显式调用 System.gc()，且配置了 -XX:+ExplicitGCInvokesConcurrent
未配置 UseCMSInitiatingOccupancyOnly 时，JVM 会根据运行统计数据动态判断
OldGen 达到某个使用阈值（静态或动态计算）
Young GC 失败或预计失败，JVM 触发 CMS 作为悲观策略
元空间（Metaspace）扩容触发，且 CMSClassUnloadingEnabled=true（默认开启）



4 总结
CMS 是一种低停顿老年代收集器，适合延迟敏感型系统。
优点是并发执行、停顿低，缺点如下
空间碎片严重
需要预留足够空间，否则触发Concurrent Mode Failure 会退化为Serial GC，非常耗时
只用了增量更新，没有完全解决漏标
会产生浮动垃圾


推荐配合 CMSInitiatingOccupancyFraction 与 UseCMSInitiatingOccupancyOnly 控制触发阈值，防止内存不足时被动触发 Full GC。

]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>CMS</tag>
        <tag>三色标记</tag>
      </tags>
  </entry>
  <entry>
    <title>CloudFlare-CDN缓存清除</title>
    <url>/2024-06-14/cloudflare-cdn-huan-cun-qing-chu/</url>
    <content><![CDATA[
​	给出了一些api用于清除Cloudflare的CDN缓存方式
 



​		搭建个人博客网站时，域名托管到CF，会使用CF的CDN。当你重新修改博客网站的样式css和js文件等再重新部署，一般都不会立马生效，因为CDN里的缓存还在，前端访问用的还是旧css和js文件。这时我们需要主动清除CDN的缓存，来让缓存重新加载，以便让我们修改的样式在网站立马生效
1 purgeUrl
2 使用ApiKey清除（不推荐）
ZONE_ID：区域id，即你在CF上托管的根域名id
EMAIL：你的邮箱
API_KEY：可自建apiKey，也可使用CF默认有的GlobalApiKey（个人资料 -&gt; API令牌 -&gt; API密钥 -&gt; Global API Key）

2.1 全部清除curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "X-Auth-Email: $EMAIL" \
    -H "X-Auth-Key: $API_KEY" \
    -d '{"purge_everything": true}'

2.2 批量清除具体文件一次性调用有文件数量限制： Free&#x2F;Pro&#x2F;Business一次上限30个，Enterprise一次上限500个
curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "X-Auth-Email: $EMAIL" \
    -H "X-Auth-Key: $API_KEY" \
    -d '{
    "files": [
        "https://blog.shanzhao.site/css/my.css",
        "https://blog.shanzhao.site/libs/others/snow.js"
    ]
}'

3 自定义token清除（推荐）自定义token不仅可以最小化的控制权限，也可以设置token的有效时常。使用如下方式创建一个专用于清理指定根域名的token

3.1 验证token是否生效curl -X GET "https://api.cloudflare.com/client/v4/user/tokens/verify" \
     -H "Authorization: Bearer $API_TOKEN" \
     -H "Content-Type:application/json"

3.2 全部清除curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "Authorization: Bearer $API_TOKEN" \
    -d '{"purge_everything": true}'

3.3 批量清除具体文件一次性调用有文件数量限制： Free&#x2F;Pro&#x2F;Business一次上限30个，Enterprise一次上限500个
curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "Authorization: Bearer $API_TOKEN" \
    -d '{
    "files": [
        "https://blog.shanzhao.site/css/my.css",
        "https://blog.shanzhao.site/libs/others/snow.js"
    ]
}'

4 其他还有其他的参数，比如tags，hosts，prefixes，但这些都是企业版的用户才能使用，这里就不写了
5 参考链接
官方清除缓存文档
cloudflare dashboard创建token和查看ApiKey
ZoneId获取

]]></content>
      <categories>
        <category>cloudflare</category>
      </categories>
      <tags>
        <tag>cdn缓存清除</tag>
      </tags>
  </entry>
  <entry>
    <title>G1</title>
    <url>/2020-11-25/g1/</url>
    <content><![CDATA[
​	简单总结了G1和其常用参数，并分析了的G1日志




​	G1（Garbage First）是 JDK 7 引入，并在 JDK 9 默认启用的服务端垃圾回收器。它的核心理念是将整个 Java 堆划分为多个大小相等的 Region，打破了传统“新生代 &#x2F; 老年代”的物理分区模式，转而以 Region 为基本单位进行垃圾管理与回收。	

整堆收集：G1 是一个真正的 整堆并行压缩收集器，新生代和老年代都可以并行回收。
并发标记：采用 三色标记法 + SATB + 写屏障机制，保证并发标记期间的准确性。
可预测的停顿时间：用户可设置 -XX:MaxGCPauseMillis 控制最大停顿时间，G1 会在这个目标下选择哪些 Region 进入回收集（CSet）。

常用参数设置
-XX:+UseG1GC
-XX:G1HeapRegionSize&#x3D;2M：一个Region的大小
-XX:MaxGCPauseMillis&#x3D;80：允许收集停顿的最大时常（毫秒）
-XX:InitiatingHeapOccupancyPercent&#x3D;45 ：老年代占用到 45% 时触发并发标记周期（默认45）
不要再设置-xmn和-XX:NewRatio

Region划分
整个堆被分成多个 Region（默认 2048 个），每个 Region 的大小为 1MB ~ 32MB，并且必须是 2 的幂次方。
每个 Region 会被动态标记为不同用途：
E：Eden 区（新生代分配对象）
S：Survivor 区（新生代存活对象）
O：Old 区（长生命周期对象）
H：Humongous 区（大对象，直接分配在老年代）



​	大对象（如数组、长字符串等）若超过一个 Region 一半大小，会被当作 Humongous 对象，分配连续的多个 Region。由于这些对象移动成本高，G1 默认不会移动 Humongous 对象，而是直接将它们标记为老年代区域。
Remembered Set（RSet）​	由于 G1 会独立地对某些 Region 进行回收，它必须知道老年代是否引用了某个新生代对象。这正是 Remembered Set（记忆集） 的作用：

每个 Region 都维护了一个对应的 RSet，记录有哪些其它 Region 的对象引用了自己。
在回收某个 Region 时，G1 只需要扫描这个 RSet，而不必全堆扫描，大幅降低了跨代引用处理的成本。


简单说：RSet 让分区式回收变得可能而高效。

Card Table（卡表）RSet 的实现依赖于 Card Table + 写屏障：

Java 堆被进一步划分为更小的单位：Card，默认每个 Card 是 512 字节。
JVM 在写引用字段时会触发 写屏障（Write Barrier），将对应 Card 标记为 dirty，并记录引用变更。
在 GC 时，这些 dirty Card 会被用于更新 RSet，确保引用信息完整。


卡表是写屏障的基础，RSet 是分区引用追踪的核心，三者协同构成 G1 的并发收集体系。

日志解析2020-11-23T11:40:46.167+0800: 1.503: [GC pause (G1 Evacuation Pause) (young), 0.0048336 secs]
   // 下面的Min,Avg,Max,Diff,Sum分别表示GC线程最小启动或耗时时间（后面的也是），平均，最大，最大差值，和总耗时，单位都为ms
   [Parallel Time: 3.1 ms, GC Workers: 6] // 本次YGC共6个GC线程，总耗时3.1ms
      [GC Worker Start (ms): Min: 1503.0, Avg: 1504.5, Max: 1506.1, Diff: 3.0] // 本次GC线程启动（相对于JVM的启动）
      [Ext Root Scanning (ms): Min: 0.0, Avg: 0.2, Max: 0.7, Diff: 0.7, Sum: 1.1] // 本次GC线程的GC Roots扫描时间
      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] // 更新Remember Sets 的耗时统计信息（记忆集一般使用来解决跨Region的引用）
         [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0]
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] // 每个Region都会有一个RSet，RSet又包含指向这个Region的Cards引用，这个阶段就是扫描RSet中的Cards，从而分辨出Eden哪些对象被老年代引用，从而这些不会被GC
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.2, Diff: 0.2, Sum: 0.2] // 扫描代码中的root节点（局部变量）
      [Object Copy (ms): Min: 0.0, Avg: 1.3, Max: 2.7, Diff: 2.7, Sum: 7.6] // 对象copy，将存活的对象copy到目标Region中
      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]
         [Termination Attempts: Min: 1, Avg: 1.2, Max: 2, Diff: 1, Sum: 7]
      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.2] // GC线程完成其他任务的时间
      [GC Worker Total (ms): Min: 0.0, Avg: 1.6, Max: 3.1, Diff: 3.1, Sum: 9.4] // GC线程整个生命周期总计消耗时间
      [GC Worker End (ms): Min: 1506.1, Avg: 1506.1, Max: 1506.1, Diff: 0.0] // GC线程完成任务的停止时间（相对于JVM）
   [Code Root Fixup: 0.0 ms]
   [Code Root Purge: 0.0 ms]
   [Clear CT: 0.1 ms] // 清理Card Table（卡表）
   [Other: 1.6 ms]
      [Choose CSet: 0.0 ms] // 选择要回收的Region放入CSet（会根据停顿时间来决定）
      [Ref Proc: 1.4 ms] // 处理引用对象耗时时间（Weak、Soft、Phantom、JNI等等）
      [Ref Enq: 0.0 ms] // 遍历所有引用，将不能回收的放入pending列表
      [Redirty Cards: 0.0 ms] // 重置card为dirty
      // 大型对象的回收
      [Humongous Register: 0.0 ms] 
      [Humongous Reclaim: 0.0 ms]
      [Free CSet: 0.0 ms] // 释放CSet中Region占用的内存空间所耗时间
   [Eden: 51.0M(51.0M)->0.0B(46.0M) Survivors: 0.0B->5120.0K Heap: 51.0M(1024.0M)->4815.7K(1024.0M)]
 [Times: user=0.05 sys=0.00, real=0.01 secs] 

总结
G1 不再物理区分年轻代和老年代，转而统一使用多个 Region 管理整个堆。

支持 并发标记 + 并发回收 + 可预测停顿，是整堆压缩收集器。

使用 Remembered Set + Card Table + 写屏障 高效维护跨代引用关系。

避免 Full GC 的目标是：通过周期性并发标记、预测性选择 CSet 来进行碎片整理。


]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>G1</tag>
      </tags>
  </entry>
  <entry>
    <title>Git</title>
    <url>/2020-02-07/git/</url>
    <content><![CDATA[​	Git常用命令总结




1 git config# git查看配置
git config --list
# ================= 全局配置（保存在用户目录下的 ～/.gitconfig 文件中）======================
# 设置全局用户名和邮箱（在 git commit 时记录为提交者信息））
git config --global user.name  "reef"
git config --global user.email "shanzhao.rd@gmail.com"
# 设置全局代理（socks5 协议，端口号为 7890）
git config --global http.proxy=socks5://127.0.0.1:7890
git config --global https.proxy=socks5://127.0.0.1:7890

# ================= 当前仓库单独配置（保存在当前仓库中 .git/config 文件中）======================
# 设置仓库专属用户名和邮箱（覆盖全局设置）
git config  user.name  "reef"
git config  user.email "shanzhao.rd@gmail.com"
# 设置当前仓库的代理（仅对该仓库生效）
git config  http.proxy=socks5://127.0.0.1:7890
git config  https.proxy=socks5://127.0.0.1:7890

2 初始化仓库# 将当前文件夹初始化为一个 Git 本地仓库
git init
# 将指定文件夹初始化为一个 Git 本地仓库
git init &lt;目录路径>

3 本地仓库的操作3.1 查看文件状态# 可以查看分支名（branch）和文件的状态，如已修改（Modified），未跟踪的（untracked）,未修改的不会有提示
git status
# 简洁版的git status
# 红色M 代表文件修改了但未加入暂存区
# 绿色M 代表文件修改了并且已加入暂存区
# ?? 代表未跟踪的，
# A 代表文件已被加入到暂存区
git status -s

3.2 未暂存的文件添加到暂存区和解暂存# 将文件加入暂存区
git add 文件名
# 将暂存区的文件取消暂存
git reset 文件名

3.3 commit(暂存区文件的提交)# 不带文件名会提交暂存区所有的文件
git commit -m "提交的日志信息"
# 提交全部暂存区文件，并打开一个编辑器，让你写入提交日志（'i':插入，'ESC':退出编辑，':wq':保存并退出）
git commit
# 该语句可将不是暂存区的文件直接commit，因为-a就代表提交到了暂存区。两步合为一步了
git commit -a -m "提交的日志信息"

3.4 已commit的文件删除# 会放在暂存区，在commit之后就删除了。如果直接在文件夹中删除，则不会放在暂存区，要将其删除，就必须先add进暂存区，再commit
git rm 文件名

3.5 将文件添加至忽略列表
 自动生成的文件，比如日志文件，class文件就不需要通过git提交，git一般只负责提交源代码。这种情况下，我们可以在工作区中创建一个.gitignore文件（文件名固定，可以在git命令行中用touch .gitignore语句创建）

# 通配符（匹配任意）
*
# 取反。比如!hello.class文件，git就不会忽略掉hello.class文件
!
# 忽略当前目录下的xxx文件
/xxx
# 忽略当前目录下的doc文件夹下的所有
doc/
# 忽略当前目录下的doc文件夹里的所有txt文件
doc/*.txt
# 忽略当前目录下的doc文件里的所有文件夹里的class文件
doc/**/*.class

3.6 查看git操作日志# 因为日志太多，不会一次性全部显示，按回车会显示下面的，按Q会退出。
git log

4. 远程仓库的操作4.1 remote# 可以查看到本地关联的的远程仓库的别名（粗略查看）
git remote
# 显示远程仓库地址（详细点）
git remote -v
# 可查看更多信息（更详细）
git remote show 远程仓库的别名
# 添加(add)远程仓库（一个本地仓库可以添加多个远程仓库）
git remote add 仓库别名 远程仓库的url
# 删除本地仓库中配置的某个远程仓库别名及其对应的 URL（该命令不会影响到真正的远程仓库）
git remote rm 远程仓库的别名

4.2 clone# 克隆远程仓库到此命令行文件夹下面
git clone 远程仓库的url

4.3 fetch &amp; pull# 从远程仓库获取最新版本带本地仓库，不会合并(merge)。如果省略这两个参数，即别名为origin，分支为matser
git fetch 仓库别名 远程仓库的branchName
# 合并到本地仓库
git merge origin/master

# 从远程仓库获取最新版本带本地仓库，会合并(merge)。如果省略这两个参数，即别名为origin，分支为matser
git pull 仓库别名 远程仓库的branchName
# 用于合并本地和远程仓库之间没有共同历史的分支内容。（强制合并）
git pull 仓库别名 远程仓库的branchName --allow-unrelated-histories

5 Git分支操作# 列出所有本地分支
git branch
# 列出所有远程分支
git branch -r
# 列出所有本地和远程的分支
git branch -a
# 查看所有本地分支，并可查看是否和远程分支建立映射关系
git branch -v
# 在本仓库中新建一个分支(在正在使用的分支下创建新的分支，新的分支将会复制正在使用的分支的所有内容进行初始化)
git branch 新分支名
# 切换到指定的分支下，前面会有*提示
git checkout 已存在的分支名
# 本地仓库分支推送到远程仓库
git push 仓库别名(shortname) 本地仓库的分支名(branchName)
# 将指定的分支名的分支文件合并到正在使用的分支里（branchName -> 正在使用的分支）
git merge 分支名(branchName)
# 根据分支名删除分支，未push的不能删除
git branch -d 分支名
# 根据分支名强力删除分支，未push的也能删除
git branch -D 分支名
# 删除远程仓库中的分支
git push 远程仓库的别名 -d 分支名
# oldName是当前分支名，newName是想改成的名
git branch -m oldName newName
# 本地更新远程仓库分支
git remote update origin --prune
# =========分支追踪（名字不同也可以）============
# 在本地新建分支local-branchName，并和对应的远程分支remote-branchName做映射，最后再checkout并pull
git checkout -b local-branchName origin/remote-branchName
# 将本地分支local-branchName分支追踪远程分支origin/remote-branchName（建立映射关系）   
git branch --set-upstream local-branchName origin/remote-branchName
# 将当前分支跟踪远程分支origin/remote-branchName   
git branch -u origin/remote-branchName

6 Git标签操作
 标签指的是某个分支的某个特定时间点的状态，记录了截止到当前时间的当前分支的全部内容。根据标签，我们可以很方便的切回到标签标记时的状态

# 创建一个新标签
git tag 新的标签名
# 列出所有标签
git tag
# 查看tag的信息
git show 标签名
# 将指定的标签推送至远程仓库
git push 仓库别名 标签名
# 新建一个分支，根据标签名指向指定的标签
git checkout -b 新的分支名 标签名
# 删除本地仓库中指定的标签
git tag -d 标签名
# 删除远程仓库中指定的标签
git push origin :refs/tags/标签名

7 SSH（secure shell）认证# 生成 SSH 密钥对的命令（由公钥和私钥组成，常用语SSH的连接和认证）
ssh-keygen -t rsa

上诉命令会生成两个文件，将公钥放在git远程仓库的ssh key里接可以使用ssh操作远程仓库了

~&#x2F;.ssh&#x2F;id_rsa：私钥，用于客户端身份认证，需保密，放在本地
~&#x2F;.ssh&#x2F;id_rsa.pub：公钥，可放在远程服务器上

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM参数和垃圾收集器组合</title>
    <url>/2020-12-18/jvm-can-shu/</url>
    <content><![CDATA[JVM常用参数整理和垃圾收集器组合
 



jvm参数整理
-Xms64m ：初始堆大小
-Xmx128m ：最大堆大小
-Xmn32m ：年轻代大小
-XX:MaxNewSize&#x3D;256m : 最大新生代大小
-Xss512k：栈大小
-XX:MetaspaceSize&#x3D;256M ：Metaspace扩容时触发FullGC的初始化阈值(并不是元空间的初始化大小，元空间是不断扩容的，当达到这个值时，就会触发full gc，链接）
-XX:MaxMetaspaceSize&#x3D;512M：Metaspace最大大小
-XX:NewRatio&#x3D;2：老年代和新生代的比例
-XX:SurvivorRatio&#x3D;8 ：Eden区与一个Survivor区的大小比值（所以s0:s1:eden&#x3D;1:1:8）
-XX:MinHeapFreeRatio&#x3D;40：空闲堆空间的最小百分比。如果空闲堆空间的比例小于它，则会进行堆扩容
-XX:MaxHeapFreeRatio&#x3D;70：空闲堆空间的最大百分比。如果空闲堆空间的比例大于它，则会进行堆缩容
-XX:-DisableExplicitGC：禁止显式GC，即禁止程序中System.gc()。个人感觉没必要
-XX:+HeapDumpOnOutOfMemoryError：OOM时导出堆快照到文件
-XX:HeapDumpPath&#x3D;&#x2F;home&#x2F;huskie&#x2F;gc&#x2F;oom.hprof：OOM时导出文件路径
-Xloggc:&#x2F;home&#x2F;ruidong&#x2F;gc.log   存储gc日志的路径
-XX:OnOutOfMemoryError：OOM时操作，比如如执行脚本发送邮件
-XX:+TraceClassLoading：打印加载类的详细信息
-XX:+PrintGCDetails：打印GC详细信息
-XX:+PrintGCTimeStamps：打印CG发生的时间戳（相对于项目启动时间）
-XX:+PrintGCDateStamps：打印GC发生的时间
-XX:+PrintHeapAtGC：每一次GC前和GC后，都打印堆信息
-XX:+PrintClassHistogram：按下Ctrl+Break后，打印类的信息
-XX:+PrintGCApplicationConcurrentTime ：打印应用程序的运行时间（许多事情会导致JVM暂停所有线程，停在安全点。gc也只是其中的一种，当暂停之后在重启应用线程，则会刷新这个时间（归0），在重新计数）链接
-XX:+PrintGCApplicationStoppedTime ：打印应用线程暂停的时间，显示应用线程被暂停了多久和应用线程暂停到安全点花费的时间
-XX:TargetSurvivorRatio&#x3D;50 ：survivor空间的晋升大小空间百分比（默认为50）
-XX:MaxTenuringThreshold&#x3D;15  ：年轻代晋升到老年代的最大年龄阈值(tenuring threshold)。默认值为 15[每次GC，增加1岁，到15岁如果还要存活，放入Old区]。jvm还会动态的计算晋升阈值，方法：依次从年龄为1的对象大小加起来，一直加到大小超过了 [（TargetSurvivorRatio * survivor_capacity）&#x2F; 100 ]值，这时加起来的最大年龄大小即为这次晋升的临界阈值（具体算法在：hotspot\src\share\vm\gc_implementation\shared\ageTable.cpp文件里，方法为compute_tenuring_threshold）
-XX:+PrintTenuringDistribution ：ygc 时打印当前晋升年龄信息

垃圾收集器新生代Serial（hotspot虚拟机在客户端下的默认新生代垃圾收集器）单线程新生代收集器，复制算法，整个过程STW
优势：内存消耗最小
缺点：不适合大内存多处理器工作，慢
ParNew多线程并行的新生代收集器，复制算法，整个过程STW

-XX:ParallelGCThreads&#x3D;4 ：并行收集的线程数

Parallel Scavenge
吞吐量 &#x3D; 运行用户代码时间 &#x2F; ( 运行用户代码时间 + 垃圾收集时间 )

吞吐量优先的新生代并行多线程收集器，复制算法（标记-复制算法）
三个重要参数：

XX:MaxGCPauseMillis ：垃圾收集最大停顿时间，大于0的毫秒数
-XX:GCTimeRatio: 大于0小于100的整数（运行用户代码时间比上垃圾回收的时间），默认为99，即允许最大1%的垃圾回收时间
-XX:+UseAdaptiveSizePolicy：开启垃圾收集器的自适应调节策略。虚拟机动态调整新生代，Eden区，Survivor区的比例和晋升大小

老年代CMS标记-清除算法的老年代收集器
Serial OldSerial的老年代会收集，标记-整理算法
Parallel Scavenge OldParallel Scavenge收集器的老年代版本，标记-整理算法
整堆G1（garbage-frist收集器）垃圾收集器组合
Serial + SerialOld
Serial + CMS (jdk8声明废弃，jdk9已被取消)
ParNew +CMS （使用CMS收集器的默认组合)
ParNew + SerialOld (jdk8声明废弃，jdk9已被取消)
Parallel Scavenge +  SerialOld
Parallel Scavenge + Parallel Scavenge Old（jdk8的默认组合）G1（jdk9的默认收集器，且CMS被标记为废弃了）

tips
java -XX:+PrintFlagsFinal -version  ：查看jvm默认参数。数据太多可配合grep使用

GCRoots对象
虚拟机栈(栈帧中的本地变量表)中引用的对象
本地方法栈(Native 方法)中引用的对象
方法区中类静态属性引用的对象
方法区中常量引用的对象
所有被同步锁持有的对象

]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>JVM参数</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-AQS</title>
    <url>/2020-04-17/java-yuan-ma-pian-aqs/</url>
    <content><![CDATA[
​	总结了LockSupport的作用，并从源码分析了AbstractQueuedSynchronizer的实现逻辑




1 LockSupport1.1 总结Java中实现当前线程的阻塞和定时阻塞，并提供唤醒指定线程的工具，在内部使用sun.misc.Unsafe来实现这一系列的操作。在AQS中普遍被使用

阻塞当前线程：通过 park() 方法使当前线程进入等待状态。
定时阻塞：通过 parkNanos(long nanos) 或 parkUntil(long deadline) 方法使当前线程在指定时间内等待。
唤醒指定线程：通过 unpark(Thread thread) 方法唤醒指定的处于等待状态的线程。

1.2 核心代码/**
 * 唤醒指定的线程（如果该线程被park了）
 * 如果线程先被unpark（解除等待）了，那么该线程下一次调用park(进入等待)则不起作用，也就不会被阻塞
 */
public static void unpark(Thread thread) {
    if (thread != null)
        UNSAFE.unpark(thread);
}

/**
 * 阻塞当前线程，并设置一个blocker（俗称阻塞器，这个只是用来jstack查看，并不能通过notifyAll来唤醒阻塞的线程）
 * blocker只能用来调试和诊断，并不影响线程的阻塞和唤醒
 */
public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}

/**
 * 定时等待，阻塞当前线程指定的纳秒数，当时间到达时就自动唤醒（定时任务会调用）
 */
public static void parkNanos(long nanos) {
    if (nanos > 0)
        UNSAFE.park(false, nanos);
}

/**
 * 定时等待，阻塞当前线程直到指定的时间戳（deadline）到来就自动唤醒（定时任务会调用）
 */
public static void parkUntil(long deadline) {
    UNSAFE.park(true, deadline);
}

2 AbstractQueuedSynchronizer
​		Node是AQS的核心内部类，它是构建同步器的基础数据结构，通过不同的配置可以实现同步队列，也可实现等待队列

2.1 同步队列​		当线程尝试获取锁时，未获取到锁的线程会被构造成一个Node，利用CAS放入同步尾部作为尾节点，等待被唤醒。同步队列关联的是整个锁，一对一的关系。而同步队列中的Node又根据nextWaiter字段判断当前Node是共享节点还是独占节点

Node之间通过prev和next指针构成双向链表

头节点(head)代表当前持有锁的线程

包含waitStatus字段标记节点状态

CANCELLED(1): 线程已取消
SIGNAL(-1): 后继节点需要唤醒
CONDITION(-2): 节点在等待队列中
PROPAGATE(-3): 共享锁需要向后传播
0: 初始状态


使用nextWaiter区分共享&#x2F;互斥模式

共享节点：共享锁的实现（Semaphore、CountDownLatch等）。nextWaiter字段为固定的Node#SHARED。释放当前节点的线程后，还具有向后传播的能力（根据state的值判断是否需要释放后继共享节点里的线程）

互斥节点：互斥锁的实现（ReentrantLock等），nextWaiter字段为Node#EXCLUSIVE（即null），只会释放当前节点里的线程




2.2 等待队列​		当已经获取到锁的线程触发java.util.concurrent.locks.Condition#await()方法阻塞自己，让出锁时。会将当前线程构造成一个Node（等待节点，状态为CONDITION），利用CAS放入等待队列尾部。等待队列关联的是Condition。所以，当ReentrantLock构造多个Condition时，就有多个等待队列，ReentrantLock和等待队列可以为一对多，而Condition和等待队列时一对一。而当其他线程获取当前锁（ReentrantLock）的线程调用java.util.concurrent.locks.Condition#signal等方法时，便会将等待队列的首节点转入到同步队列的尾节点，并重新设置Node的状态

单向链表结构，只使用nextWaiter指针

nextWaiter字段为等待队列中下一个等待节点的指针

当调用signal()时，节点从等待队列转移到同步队列过程中的状态变化如下

CONDITION -&gt; 0
入队同步队列
等待获取锁



2.3 核心代码// 同步队列专属的头尾节点。
// 因为只有在同步队列里的线程才需要被唤醒。等待队列里的线程如果要被唤醒，需要先加入到同步队列
private transient volatile Node head;
private transient volatile Node tail;
// 核心，可获取到锁的次数
// - ReentrantLock: 表示重入次数
// - Semaphore: 表示剩余许可数
// - CountDownLatch: 表示剩余计数
private volatile int state;
// 自旋的阈值（纳秒）。当超时等待时间小于这个值时，就不会再暂停线程，而是自旋。因为这个时间已经很少了，考虑到阻塞线程后上线文切换会消耗时间，就没必要再阻塞了
static final long spinForTimeoutThreshold = 1000L;
// 获取到独占锁的线程
private transient Thread exclusiveOwnerThread;

/**
    留给子类实现的尝试获取共享锁的方法，共享锁获取，返回AQS里state的剩余值 
    1：返回值 > 0，代表当前线程获取成功，且state还有剩余值，表示可以继续传播给下一个共享节点线程，让其尝试获取锁 
    2：返回值 = 0，代表当前线程获取成功，但state值刚好被用完，那么下一个共享节点线程就不应该被唤醒了（因为这时已经获取不到state的剩余值了）
    3：返回值 &lt; 0，代表当前线程都没获取成功，直接获取失败，阻塞等待被其他线程唤醒后在尝试获取
*/
protected int tryAcquireShared(int arg) {
    throw new UnsupportedOperationException();
}

// 获取共享锁
private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) { // 首节点的下个节点才有资格获取锁（首节点就是获取到锁的节点）
                int r = tryAcquireShared(arg);
                if (r >= 0) { // 至少当前线程获取成功了，但可能state值已经被用完了
                    // 获取成功，传播给下一个共享Node，根据state的剩余值来判断是否需要唤醒下一个共享Node里的线程
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt()) // 不能获取到锁线程就park
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
// 释放共享锁（Semaphore会使用）
private void doReleaseShared() {
      // 必要的循环
      // 1. CAS操作可能失败需要重试
    // 2. 在设置head的过程中可能有新的节点入队
    // 3. 传播机制要求必须确保传播状态正确设置
    for (;;) {
        Node h = head;
          // h != tail 检查确保队列中还有后继节点
        if (h != null &amp;&amp; h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            else if (ws == 0 &amp;&amp;
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // loop if head changed
            break;
    }
}

/*
    将目标节点（参数node）设为同步队列的尾部（使用CAS来解决并发问题）。
    所以，在这整个过程中，链表中除首节点外其余节点的prev在任何时刻都不会为空；
        但除尾节点外其余节点的next字段有可能为空 （刚好走完第②步，还没走到第③步）
*/
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // 初始化同步队列，设置一个空Node为首尾节点
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t; // 先将目标节点的prev设置程原尾节点 ①
            if (compareAndSetTail(t, node)) { // CAS设置尾节点 ②
                t.next = node; // 设置成功了，才把原尾节点的next设为目标节点（现尾节点）③
                return t;
            }
        }
    }
}

// 唤醒目标节点（参数node）的最近下一个可唤醒节点中的线程
private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);
    // 首节点的下个节点唤醒失败时，就从尾节点向前遍历，直到找到距首节点最近的可唤醒的节点
    // 目的是避免并发时（节点入队列和唤醒），倒数第二个节点（甚至不止）的next字段为空，导致拿不到其实已经入队列里的后续节点
    Node s = node.next;
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}

// ============内部的Node数据结构=================
static final class Node {
    // 共享锁
    static final Node SHARED = new Node();
    // 互斥锁
    static final Node EXCLUSIVE = null;
    //  取消获取锁
    static final int CANCELLED =  1;

    static final int SIGNAL    = -1;
    // 等待condition唤醒（等待队列才会用到这个状态）
    static final int CONDITION = -2;
    static final int PROPAGATE = -3;
        // 当前节点的状态
    volatile int waitStatus;
    // 同步队列专用
    volatile Node prev;
    // 同步队列专用
    volatile Node next;
    // 等待线程
    volatile Thread thread;
    // 1. 当前Node为同步队列中的共享节点时：SHARED
    // 2. 当前Node为同步队列中的独占节点时：null
    // 3. 当前Node为等待队列中的节点时：下一个等待节点的指针
    Node nextWaiter;
        // 判断当前节点是互斥锁，还是共享锁
    final boolean isShared() {
        return nextWaiter == SHARED;
    }
        // 当前节点的前驱结点
    final Node predecessor() throws NullPointerException {
        Node p = prev;
        if (p == null)
            throw new NullPointerException();
        else
            return p;
    }
}

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>LockSupport</tag>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-Future</title>
    <url>/2020-05-09/java-yuan-ma-pian-future/</url>
    <content><![CDATA[
​	jdk中Future接口实现类相关源码解析。包括FutureTask和 ScheduledFutureTask
 



Future接口表示一个异步操作的结果，即未来的结果，同时实现了 Runnable 和 Future 接口。提供了如下的一些基础方法可获取、判断和取消等操作

get()：阻塞直到计算完成并返回结果（支持超时设置）

isDone()：非阻塞检查任务是否完成（成功&#x2F;失败&#x2F;取消）

cancel(boolean mayInterruptIfRunning)：尝试取消任务，参数决定是否中断执行中的线程

isCancelled()：判断任务是否被取消


其实现类为FutureTask，就是用它来实现Callable接口的功能

1.1 FutureTask1.1.1 重点字段和方法public class FutureTask&lt;V> implements RunnableFuture&lt;V> {
    // state字段，表示了当前Future的状态，取值为如下字段
    private volatile int state;

    private static final int NEW          = 0; // 初始状态，新建
    private static final int COMPLETING   = 1; // 正在结束
    private static final int NORMAL       = 2; // 正常执行完毕
    private static final int EXCEPTIONAL  = 3; // 异常执行完毕
    private static final int CANCELLED    = 4; // 前一个状态必须是NEW，已取消（未中断）
    private static final int INTERRUPTING = 5; // 前一个状态必须是NEW，正在中断（中断）
    private static final int INTERRUPTED  = 6; // 取消成功的才可以设置，中断完成（中断）

    // 待运行的Callable任务
    private Callable&lt;V> callable;
    // Callable执行的结果。如果出现执行的过程中异常，则保存的是异常对象
    private Object outcome;
    // 运行Callable#call方法的线程（也即是运行业务代码的线程）
    private volatile Thread runner;
    // 当这里面的Callable还未执行完，却有其他线程调用Future#get()方法，
    // 	会将其他线程阻塞并构造为等待节点，维持一个链表结构，以便在Callable执行完毕后唤醒并回调
    private volatile WaitNode waiters;


    public void run() {
        if (state != NEW ||
            !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                         null, Thread.currentThread()))
            return;
        try {
            Callable&lt;V> c = callable;
            if (c != null &amp;&amp; state == NEW) {
                V result;
                boolean ran;
                try {
                    // 执行业务方法
                    result = c.call();
                    ran = true;
                } catch (Throwable ex) {
                    result = null;
                    ran = false;
                    setException(ex); // 异常结束，将状态设为EXCEPTIONAL，如果等待队列有节点，则唤醒对应的线程
                }
                if (ran)
                    set(result); // 正常结束，将状态设为NORMAL，如果等待队列有节点，则唤醒对应的线程
            }
        } finally {
            runner = null;
            int s = state;
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
    }
    // 阻塞获取
    public V get() throws InterruptedException, ExecutionException {
        int s = state;
        if (s &lt;= COMPLETING) // 还未完全结束Callabke，进入等待
            s = awaitDone(false, 0L);
        return report(s);
    }
    // 根据state判断是否需要阻塞并做对于的事
    private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
        final long deadline = timed ? System.nanoTime() + nanos : 0L;
        WaitNode q = null;
        boolean queued = false;
        for (;;) {
            if (Thread.interrupted()) { // 当前线程支持响应中断
                removeWaiter(q);
                throw new InterruptedException();
            }

            int s = state;
            if (s > COMPLETING) { // Callable运行完毕，且result已经设置完毕
                if (q != null)
                    q.thread = null;
                return s;
            }
            // 进入到以下分支，就代表Callable还未完全执行完毕

            else if (s == COMPLETING) // cannot time out yet  Callable运行完毕，但正在设置result，让出执行时间，等待下次判断
                Thread.yield();
            else if (q == null) // 第一次循环，构造等待节点
                q = new WaitNode();
            else if (!queued) // 还未加入等待队列，则将节点加入到等待队列中
                queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                                     q.next = waiters, q);
            else if (timed) { // 是否运行超时判断
                nanos = deadline - System.nanoTime();
                if (nanos &lt;= 0L) {
                    removeWaiter(q);
                    return state;
                }
                LockSupport.parkNanos(this, nanos);
            }
            else // 暂停当前线程，等待任务执行完毕的唤醒
                LockSupport.park(this);
        }
    }
    // 任务执行完毕，唤醒等待队列的所有节点
    private void finishCompletion() {
        // assert state > COMPLETING;
        for (WaitNode q; (q = waiters) != null;) {
            if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {
                for (;;) {
                    Thread t = q.thread;
                    if (t != null) {
                        q.thread = null;
                        LockSupport.unpark(t);
                    }
                    WaitNode next = q.next;
                    if (next == null)
                        break;
                    q.next = null; // unlink to help gc
                    q = next;
                }
                break;
            }
        }

        done();

        callable = null;        // to reduce footprint
    }
}

1.1.2 总结
FutureTask根据内部的state字段来判断当前任务运行到了哪个阶段并作出对于的抉择，也使用volatile修饰保证它在多线程环境下的可见性。
state状态流转：
NEW→COMPLETING→NORMAL（成功）
NEW→COMPLETING→EXCEPTIONAL（失败）
NEW→CANCELLED&#x2F;INTERRUPTED（取消）




如果想获取任务执行的结果，要使用get来获取结果，get是个阻塞的方法。当任务还未执行完毕时，会将调用get的方法阻塞并构造成WaitNode，再通过内部的next字段链接下一个WaitNode，形成一个链表结构。当任务执行完毕后，内部调用的finishCompletion方法会判断等待链表是否为空，不为空就代表有线程在获取结果时被阻塞了，这时唤醒阻塞队列的所有线程，最终，调用get方法的线程返回结果。即使用 WaitNode 链表 + CAS 操作管理阻塞线程，避免显式锁开销
只会允许任务执行一次，状态不可逆转

1.2 ScheduledFutureTask​	ScheduledFutureTask继承了FutureTask，当向定时任务线程池投递任务时（Runnable或Callable），都会将其封装为ScheduledFutureTask
1.2.1 重点字段和方法 private class ScheduledFutureTask&lt;V>
            extends FutureTask&lt;V> implements RunnableScheduledFuture&lt;V> {
     /** 
     * 当前任务的id（自增的），代表了进入队列的顺序 &lt;br/>
     * 当两个定时任务下次执行时间一致时，sequenceNumber越小就会越早执行
     */
    private final long sequenceNumber;
    // 下次执行当前任务的纳秒时间戳
    private long time;

    /**
     * 执行定时任务的纳秒间隔时间
     * 大于0：代表固定的频率，不受任务的执行所花费的时间影响
     * 等于0：代表不是一个重复的任务（只会执行一次
     * 小于0：代表固定的时间间隔，基于任务执行完毕后的时间计算。（任务执行完后再基于当前时间计算下次执行时间）
     */
    private final long period;
    // 当前任务在数组中的索引
    int heapIndex;

    public long getDelay(TimeUnit unit) {
        return unit.convert(time - now(), NANOSECONDS);
    }
    // 比较方法，决定了放入数组的位置
    public int compareTo(Delayed other) {
        if (other == this) // compare zero if same object
            return 0;
        if (other instanceof ScheduledFutureTask) {
            ScheduledFutureTask&lt;?> x = (ScheduledFutureTask&lt;?>)other;
            long diff = time - x.time;
            if (diff &lt; 0)
                return -1;
            else if (diff > 0) // 当前任务的下次执行时间更长，返回正数
                return 1;
            else if (sequenceNumber &lt; x.sequenceNumber)
                return -1;
            else
                return 1;
        }
        long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS);
        return (diff &lt; 0) ? -1 : (diff > 0) ? 1 : 0;
    }

    /**
     * false: 代表当前任务为一次性任务
     * true: 定时任务
     */
    public boolean isPeriodic() {
        return period != 0;
    }
    // 当前任务执行完毕后，用来计算下次执行时间
    private void setNextRunTime() {
        long p = period;
        // p为两次执行时间的时间间隔的纳秒值
        if (p > 0) // p大于0，即为固定时间执行的任务，基于初始运行时间计算下一次的执行时间
            time += p;
        else // p小于0，为基于完成任务的时间来执行，基于任务运行完的时间，来计算出下一次的执行时间
            time = triggerTime(-p);
    }
    // 主方法，运行当前定时任务
    public void run() {
        boolean periodic = isPeriodic();
        if (!canRunInCurrentRunState(periodic))
            cancel(false);
        else if (!periodic) // 非定时任务，当作普通任务直接调用FutureTask的run方法运行
            ScheduledFutureTask.super.run();
        else if (ScheduledFutureTask.super.runAndReset()) { // 运行定时任务，且运行成功（没抛异常）
            setNextRunTime(); // 设置下一次执行时间
            reExecutePeriodic(outerTask); // 再把当前任务重新入队列
        }
    }
    /**
      父类的FutureTask中的方法，运行并重置状态，用于任务的多次执行 
         * 正常执行时：不会修改运行状态（也就是说这个操作不会修改state字段值，保持初始值，以支持重复执行）。
         * 出现异常时：还是将state设为EXCEPTIONAL，也就是说一个定时任务要是抛出了异常，之后就不会再执行它了
         */
    protected boolean runAndReset() {
        if (state != NEW || // 不为NEW状态的都不执行
            !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                         null, Thread.currentThread()))
            return false;
        boolean ran = false;
        int s = state;
        try {
            Callable&lt;V> c = callable;
            if (c != null &amp;&amp; s == NEW) {
                try {
                    c.call(); // 不设置返回结果。多次执行的任务就不该有执行结果
                    ran = true;
                } catch (Throwable ex) {
                    setException(ex);  // 抛出异常，修改state为EXCEPTIONAL，以后也不在执行它
                }
            }
        } finally {
            // runner must be non-null until state is settled to
            // prevent concurrent calls to run()
            runner = null;
            // state must be re-read after nulling runner to prevent
            // leaked interrupts
            s = state;
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
        return ran &amp;&amp; s == NEW;
    }
 }

1.2.2 总结ScheduledFutureTask 通过 period 字段判断任务类型：0 表示一次性任务，&gt;0 表示固定频率，&lt;0 表示固定延迟。
在 run() 方法中，若任务为周期性任务，执行完当前任务后会计算下次执行时间，并将自身重新提交至基于小顶堆的 DelayedWorkQueue 中，以维持调度。

基于纳秒时间精度，避免 System.currentTimeMillis() 的系统时间变动干扰。
复用 FutureTask 的任务封装机制，增强任务调度能力。
精简实现，不依赖额外锁，主要通过最小堆和 Delayed 接口实现调度。

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-Map</title>
    <url>/2020-04-09/java-yuan-ma-pian-map/</url>
    <content><![CDATA[​	jdk中常用Map实现类相关源码解析。包括 HashMap，LinkedHashMap，ConcurrentHashMap
 



1 HashMap1.1 重点字段 
/**
 * 数组默认长度
 */
static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16

/**
 * 最大容量（即数组最大长度）
 */
static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;

/**
 * 默认加载因子
 * 加载因子（loadFactor）是哈希表中用于控制数组存放数据疏密程度的参数。
 * 当loadFactor越趋近于1时，数组中存放的数据（entry）越多，哈希冲突的概率增加，
 * 导致单个桶中的链表长度可能增加，进而影响查找元素的效率。反之，当loadFactor越小，
 * 数组中存放的数据越少，数据分布越稀疏，数组的利用率降低。
 *
 * 默认的loadFactor值为0.75f，是官方经过权衡后给出的一个较为理想的平衡点，
 * 旨在兼顾查找效率和空间利用率。
 */
static final float DEFAULT_LOAD_FACTOR = 0.75f;

/**
 * 树化阈值。当桶(bucket)上的结点数大于这个值时会转成红黑树
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 链表化阈值（当桶(bucket)上的结点数小于这个值时树转链表）
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * 桶中结构树化对应的table的最小长度
 */
static final int MIN_TREEIFY_CAPACITY = 64;

/**
 * 扩容阈值（threshold）
 * threshold = loadFactor * 数组长度
 * 当HashMap中元素的数量超过threshold时，会触发数组的扩容操作。
 * 扩容是为了减少哈希冲突，保持查找效率。
 */
int threshold;

1.2 核心方法1.2.1 put1 初始化数组
如果是第一次添加元素，先初始化数组（即分配内存空间）。
计算键的哈希值并确定索引位置，然后将键值对放入对应的桶（bucket）中。

2 目标桶为空
如果计算索引后，数组中对应的桶为空，则直接将键值对放入该桶中。

3 目标桶不为空
根节点匹配：
如果桶中的根节点（第一个节点）与待插入节点的键 equals，则直接替换根节点的值。


树化节点：
如果根节点是树形节点（即红黑树节点），则调用红黑树的插入方法将节点放入树中。


链表遍历：
如果根节点是链表节点，则遍历链表：
如果找到与待插入节点键 equals 的节点，则替换其值。
如果遍历到链表末尾仍未找到匹配的节点，则将新节点插入链表末尾。
树化条件：
如果链表长度（包括待插入节点）达到 8 且数组长度大于等于 64，则将链表转换为红黑树。
如果链表长度达到 8 但数组长度小于 64，则仅进行数组扩容，不进行树化。







1.2.2 resizeHashMap 数组的长度始终为 2 的次幂，且扩容时长度加倍。这样设计的主要目的是为了方便扩容时的索引计算。以下为具体的扩容过程
1 创建新数组
先创建一个长度为原数组 2 倍的新数组。

2 迁移数据
遍历原数组中的每个桶（bucket）：

如果桶为空或只有一个元素：

直接计算该元素在新数组中的索引，并将其放入新数组。


如果桶中有链表结构：

遍历链表中的每个节点（Node），计算其在新数组中的索引。

由于新数组长度是原数组的 2 倍，且长度始终为 2 的次幂，因此新索引的计算方法为：
newIndex = (key.hashCode() &amp; (newCapacity - 1))


新索引的结果只有两种可能：

与原索引相同：如果 key 的哈希值在高一位为 0。
等于原索引加上原数组长度：如果 key 的哈希值在高一位为 1。


根据计算结果，将节点放入新数组的对应位置。






3 链表拆分
如果原桶中的链表被拆分为两个链表（一个保持原索引，另一个为原索引加上原数组长度），则分别将它们放入新数组的对应位置。

1.2.3 部分核心代码final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
             boolean evict) {
  Node&lt;K,V>[] tab; Node&lt;K,V> rootNode; int tableLength, index;
  if ((tab = table) == null || (tableLength = tab.length) == 0) // 添加第一个元素
      tableLength = (tab = resize()).length;
  if ((rootNode = tab[index = (tableLength - 1) &amp; hash]) == null) // 数组上对于的索引为空，代表这个kv可以直接放到这
      tab[index] = newNode(hash, key, value, null);
  else {
      Node&lt;K,V> e; K k;
      if (rootNode.hash == hash &amp;&amp;
          ((k = rootNode.key) == key || (key != null &amp;&amp; key.equals(k)))) // bucket上的元素equals要放进来的kv，直接覆盖
          e = rootNode;
      else if (rootNode instanceof TreeNode)  // bucket上已经是红黑树结构了，直接存放为红黑树结构
          e = ((TreeNode&lt;K,V>)rootNode).putTreeVal(this, tab, hash, key, value);
      else { // 向链表的末尾添加
          for (int binCount = 0; ; ++binCount) {
              if ((e = rootNode.next) == null) { // 到链表末尾了
                  rootNode.next = newNode(hash, key, value, null);
                  if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                  { // 链表的长度（算上bucket）已经大于等于了8，转换为红黑树
                      treeifyBin(tab, hash);
                  }
                  break;
              }
              if (e.hash == hash &amp;&amp;
                  ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { // 遍历链表时有equals，直接替换
                  break;
              }
              rootNode = e;
          }
      }
      if (e != null) { // existing mapping for key
          // e不为空，代表是覆盖的情况，不是新增
          V oldValue = e.value;
          if (!onlyIfAbsent || oldValue == null)
              e.value = value;
          afterNodeAccess(e);
          return oldValue;
      }
  }
  ++modCount;
  if (++size > threshold)
      resize();
  afterNodeInsertion(evict);
  return null;
}

/**
 * resize方法，只展示了部分核心代码
 * 数组的初始化或扩容，扩容是加倍的
 */
final Node&lt;K,V>[] resize() {
    if (oldTab != null) { // 旧数组存在元素
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V> e;
            if ((e = oldTab[j]) != null) { // bucket存在元素
                oldTab[j] = null;
                if (e.next == null) // 这个bucket没有链表，只需要将它重新计算下在新数组的索引，并放入对于的bucket中
                    newTab[e.hash &amp; (newCap - 1)] = e;
                else if (e instanceof TreeNode) // 红黑树结构
                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    /* 旧数组的桶在新数组的索引位的节点 */
                    // 索引大小没有变化
                    Node&lt;K,V> loHead = null, loTail = null;
                    // 索引扩大了旧数组的长度（即新索引位：旧索引位+旧数组长度）
                    Node&lt;K,V> hiHead = null, hiTail = null;
                    Node&lt;K,V> next;
                    do {
                        next = e.next;
                        // e.hash &amp; oldCap == 0 就代表e的hash值（转换为2进制）高一位为0，
                        // 与（新的容量-1）相与后，其在数组的索引位置不变
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else { // 这里则高一位为1，与新的容量 &amp; 后，
                             // 其在新数组的索引位置会增加新容量的扩大值（即原容量的大小）
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}

1.3 线程不安全

当两个线程同时put数据时，且被put的两个数据能定位到HashMap数组的相同那个bucket位置上，就可能产生一个覆盖掉另一个的可能，造成一个数据消失。
多个线程同时修改 HashMap的结构时（如插入、删除或扩容），可能会导致部分数据丢失。比如线程A插入，而线程B正在扩容，最终导致A线程插入的数据丢失
没有volatile或锁的同步机制，会导致一个线程的修改对另一个线程不可见


2 LinkedHashMapLinkedHashMap 是 HashMap 的子类，它不仅实现了 Map 接口，还具有排序功能。其排序行为由 accessOrder 字段控制
2.1 核心字段
head：链表的头节点，指向最早插入或访问的节点。
tail：链表的尾节点，指向最近插入或访问的节点。
accessOrder（默认 false）：
false：按照插入顺序排序，越晚插入的元素越排在链表末尾。
true：按照访问顺序排序，最近访问的元素会被移动到链表末尾。可用于实现 LRU 缓存。



2.2 排序实现原理2.2.1 双向链表// 继承了HashMap.Node的Entry内部结构
static class Entry&lt;K,V> extends HashMap.Node&lt;K,V> { // 具有链表结构的Entry
    // 前驱节点和后继节点
    Entry&lt;K,V> before, after;
    Entry(int hash, K key, V value, Node&lt;K,V> next) {
        super(hash, key, value, next);
    }
}

2.2.2 添加元素// 重写了HashMap的newNode方法，在构造新节点时将其添加到链表末尾
Node&lt;K,V> newNode(int hash, K key, V value, Node&lt;K,V> e) {
    Entry&lt;K,V> p = new Entry&lt;>(hash, key, value, e);
    // 将新节点链接到链表末尾
    linkNodeLast(p);
    return p;
}

2.2.3 访问节点移动到末尾如果 accessOrder 为 true，LinkedHashMap 会在访问节点时（如调用 get 方法）触发 afterNodeAccess 方法，将最近访问的节点移动到链表末尾，基于此可以实现LRU缓存
// 重写的HashMap#afterNodeAccess方法，
void afterNodeAccess(Node&lt;K,V> e) {
    LinkedHashMap.Entry&lt;K,V> last;
    if (accessOrder &amp;&amp; (last = tail) != e) { // accessOrder为true，e不为tail
        // 重排序当前元素，将当前节点设为新的tail（保持最近一次被访问的节点在最后面）
        LinkedHashMap.Entry&lt;K,V> p =
            (LinkedHashMap.Entry&lt;K,V>)e, b = p.before, a = p.after;
        p.after = null;
        if (b == null) // e为head，更新头节点
            head = a;
        else
            b.after = a;
        if (a != null) // e不为tail
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}

3 ConcurrentHashMapConcurrentHashMap 是一个线程安全的 Map 实现，通过 **CAS 和 分段锁 机制实现高效的并发操作。其数据结构与 HashMap 类似，采用 数组 + 链表 + 红黑树 的形式：

当链表长度超过 8 时，链表会转换为红黑树。
当红黑树节点数小于 6 时，红黑树会退化为链表。

3.1 put方法死循环put元素，直到操作成功才退出

数组还没初始化，开始数组的初始化
数组的bucket还未被占用，CAS占用（成功了就break，失败了就代表已经被其他节点占用了，进行下一次循环进入其他if分支）
当前桶为ForwardingNode，表示有线程正在进行扩容操作，则先帮助扩容，等扩容完毕在继续put
bucket被占用，锁住根节点，开始构造到链表的为尾节点。添加到尾节点后，在判断当前链表长度是否超过8，否则就转换为红黑树

3.2 扩容（重点）​		核心是通过 多线程协作 和 分段迁移 的方式进行高效的数据迁移，同时尽量减少对读写操作的影响
3.2.1 扩容触发时机
当 ConcurrentHashMap 中的元素数量超过 阈值（threshold） 时触发
阈值计算公式：阈值 = 数组长度 * 负载因子（loadFactor，默认 0.75）。

3.2.2 具体步骤
首先创建一个新的数据，为元素组大小的2倍。将其设置到nextTable字段

通过CAS设置transferIndex（初始设为旧数组的长度，即是从旧数组末尾开始向前遍历转移数据的）

每个线程通过CAS从transferIndex获取一段连续长度为stride（步长）的桶，stride计算如下

// 计算步长：即扩容时每个线程每次最小处理的数组连续长度
// cpu为1，则由这个线程全部处理；cpu数量大于1，每个核心负责的步长为 数组长度/(8 * cpu核数) ，不过如果计算出步长小于16，则会被设置为16。确保线程的工作量均衡
if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE){
  stride = MIN_TRANSFER_STRIDE;
} 




开始迁移数据，到这一步了每个线程就只会迁移自己所负责的步长索引数据，不会冲突

空桶：则放置一个 ForwardingNode，表示该桶已迁移
桶为ForwardingNode：当前桶已迁移。因为整体是从后向前迁移的，可推测当前线程负责的这段步长索引一定已处理完毕，即这段步长内这个桶后面的所有桶也都已经被处理完成了，需要重新计算它下一次该负责的新步长索引
桶未迁移：则操作加锁，对桶中的链表或红黑树进行迁移，迁移完成后，再将当前桶放置为ForwardingNode节点


当最后一个线程迁移完毕后，则更新table为新数据和sizeCtl，表示扩容完成


3.2.3 相关思考
步长计算安全嘛？

​		安全，通过CAS设置公共变量transferIndex（初始值为table.length），同时该变量为volatile，它的变化能立马被其他线程感知到，可以保证每个线程处理的步长索引不会重复和交叉


其他线程如何感知并帮助扩容？

​		通过判断桶节点为ForwardingNode，则表示正在扩容，此时这个线程则帮助扩容，计算自己需要处理的步长索引来转移数据到新数组中。每处理完一个桶也将其设为ForwardingNode节点


get方法并没有加锁，如果桶已被转移怎么获取到数据？

​		首先扩容是读写分离的，扩容时不会对桶本身做任何修改（即不会修改Node的内部指针数据），所以如果拿到原桶数据，则能直接遍历获取数据。而如果拿到的是ForwardingNode，它本身也提供了find方法，会到新数组中去找到需要的数据


扩容完成如何处理？

​		每个线程完成自己负责区间的迁移后，会更新sizeCtl字段中的扩容线程数计数，判断确定最后一个完成迁移的线程会将新数组赋值给table并重新计算sizeCtl的阈值


最后需要注意，在操作数组中的桶时，都会获取这个桶节点的锁（put和resize等等修改方法），锁是相同的，所以不必担心某一个桶的相关数据被多个线程同时处理（put，resize等）


3.2.4 核心代码private final void transfer(Node&lt;K,V>[] tab, Node&lt;K,V>[] nextTab) {
    int n = tab.length, stride;
    // 计算步长：即扩容时每个线程每次最小处理的数组连续长度
    // cpu为1，则由这个线程全部处理；cpu数量大于1，每个核心负责的步长为 数组长度/(8 * cpu核数) ，不过如何计算出步长小于16，则会被设置为16。确保线程的工作量均衡
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            // 创建新数组，2次幂便于扩容计算新索引位置
            Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        // 表示从数组末尾开始分配迁移任务
        transferIndex = n;
    }
    int nextn = nextTab.length;
    ForwardingNode&lt;K,V> fwd = new ForwardingNode&lt;K,V>(nextTab);
    // 当前线程是否需要继续在旧数组上截取一段桶来处理数据，默认是
    boolean advance = true;
    // 扩容完毕的标志
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) { // i 是当前线程正在处理的桶的索引，bound 是当前线程负责的迁移任务的起始索引（也就是在处理中则 i>bound）
        Node&lt;K,V> f; int fh;
        // 检查当前线程负责的步长内的桶是否处理完毕。处理完毕，则选取下一段当前现场该处理的步长索引段
        while (advance) {
            int nextIndex, nextBound;
            if (--i >= bound || finishing)
                advance = false;
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                // i初始化为旧数组最后一个索引位置
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i &lt; 0 || i >= n || i + n >= nextn) { // 当前线程扩容完毕处理
            int sc;
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n &lt;&lt; 1) - (n >>> 1);
                return;
            }
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        else if ((f = tabAt(tab, i)) == null) // 空桶，CAS放置ForwardingNode，让其他线程可以感知到，以帮助扩容
            advance = casTabAt(tab, i, null, fwd);
        else if ((fh = f.hash) == MOVED) // 当前桶已被处理
            // 到这了就说明这段步长索引处理完毕，需要重新计算新步长索引
            advance = true; // already processed
        else {
            synchronized (f) { // 桶加锁，开始转移当前桶的链表或红黑树到新的数组里
                if (tabAt(tab, i) == f) { // 获取成功，再次校验桶节点是否变化，未变才继续操作（避免被其他刚释放了这个锁的线程给修改了）
                    // 桶数据转移到新数组去，和HashMap类似计算新数组中的索引
                    Node&lt;K,V> ln, hn;
                    if (fh >= 0) {
                        int runBit = fh &amp; n;
                        Node&lt;K,V> lastRun = f;
                        for (Node&lt;K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node&lt;K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                ln = new Node&lt;K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V>(ph, pk, pv, hn);
                        }
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        // 转移完后，旧数组的桶放置ForwardingNode，表示当前桶已处理完毕并表示为扩容中
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin&lt;K,V> t = (TreeBin&lt;K,V>)f;
                        TreeNode&lt;K,V> lo = null, loTail = null;
                        TreeNode&lt;K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V> e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V> p = new TreeNode&lt;K,V>
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V>(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V>(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        // 转移完后，旧数组的桶放置ForwardingNode，表示当前桶已处理完毕并表示为扩容中
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}

3.4 为什么key和value不允许为null，而HashMap可以呢？
​		ConcurrentHashMap如果允许key和value为null，会产生二义性。即不能确定map里本身没有这个数据，还是说有这个数据，但这个数据存的是null值。
​		为什么HashMap可以允许呢？因为它不会产生二义性，使用HashMap设计用于单线程下，假设我们获取key为A的数据返回了null，之后还马上可以通过containsKey来判断到底是不存在A还是A就为null（因为是单线程，不用担心其他线程会修改数据）
​		但ConcurrentHashMap是线程安全的，也就是默认会在多线程下修改数据。假设ConcurrentHashMap支持设置null，这时线程A获取key为null的数据返回了null，此时我们不确定A在不在ConcurrentHashMap里，需要用containsKey来判断key为null是否存在于ConcurrentHashMap里。但多线程的情况下，B线程在A线程containsKey操作前添加了key为null的数据，导致A线程containsKey返回了true，导致和第一步预期不同（第一步可能是不存在key为null的数据）
​		综上：ConcurrentHashMap，它是为并发而生的，它是要用在并发场景中的。假如允许使用 map.get(key)返回 null ，这时是没办法通过 map.containsKey来准确的检测，因为在检测过程中可能会被其他线程锁修改，而导致检测结果并不可靠。所以直接禁用了null，好处就是返回null一定能表示key不存在，而不是有其他的含义，让语义更明确了
​		所以这个设计选择反映了并发编程的一个重要原则：通过适当的限制来换取更好的可靠性和简单性。虽然失去了存储null值的能力，但换来了更清晰的语义和更好的并发安全性。

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>Map</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-线程池</title>
    <url>/2020-05-12/java-yuan-ma-pian-xian-cheng-chi/</url>
    <content><![CDATA[​	对jdk的ThreadPoolExecutor和ScheduledThreadPoolExecutor进行了详细的源码分析
 



1 ThreadPoolExecutor1.1 重要字段//状态控制器，初始值： 1110 0000 0000 0000 0000 0000 0000 0000
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static final int COUNT_BITS = Integer.SIZE - 3; // 29位
// 0001 1111 1111 1111 1111 1111 1111 1111
// 1110 0000 0000 0000 0000 0000 0000 0000 取反后
private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;
                                                            

// 运行中：111 00000000000000000000000000000
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS; 
// 不再接受新任务的入队列，但已经入队列还未还未的任务还可以继续执行
// 000 00000000000000000000000000000
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS; 
// 不接受新任务入队列，也不处理队列中的任务，中断正在处理任务的worker
// 001 00000000000000000000000000000
private static final int STOP       =  1 &lt;&lt; COUNT_BITS; 
// 全部完成，任务终止，worker数为0
// 010 00000000000000000000000000000
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
// 011 00000000000000000000000000000
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;

// 计算线程池的状态
private static int runStateOf(int c)     { return c &amp; ~CAPACITY; } // 后29位为0，前3为跟随c
// 计算线程池有多少工作线程
private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 前3位为0，后面29为跟随 c
private static int ctlOf(int rs, int wc) { return rs | wc; }

// 任务队列
private final BlockingQueue&lt;Runnable> workQueue;
// 主锁
private final ReentrantLock mainLock = new ReentrantLock();
// 工作线程的Set
private final HashSet&lt;Worker> workers = new HashSet&lt;Worker>();

private final Condition termination = mainLock.newCondition();
// 池已经创建的线程最大数（一个动态值，线程池整个周期同时存在的最多线程数）
private int largestPoolSize;
// 完成的任务数
private long completedTaskCount;
// 创建线程的工厂
private volatile ThreadFactory threadFactory;
// 拒绝策略
private volatile RejectedExecutionHandler handler;
// 非核心线程数的保持时间
private volatile long keepAliveTime;
// 是否允许核心线程过期
private volatile boolean allowCoreThreadTimeOut;
// 核心线程数
private volatile int corePoolSize;
// 最大线程数
private volatile int maximumPoolSize;


 ​	ThreadPoolExecutor利用一个int类型的数来同时保存当前线程池状态和工作线程的数量，高3为用来表示当前线程的状态，低29为用来保存工作线程的数量。通过位运算实现状态和数量的原子性操作，避免单独维护两个变量时的竞态条件
​	ThreadPoolExecutor内部的Worker就是工作线程的抽象，每一个Worker都是一个工作线程。同时，Worker又继承了AQS可以充当锁的角色，目的是更好的让外部知道当前worker是否正在运行，以帮助回收或中断Worker。worker运行时（获取到任务后开始运行）会加锁，通过测试当前worker是否加上锁或者是否可以获得当前worker的锁，便可知道worker是否繁忙，有助于worker的清理

1.2 核心方法1.2.1 shutdown（平滑关闭）​	将当前线程池状态设为SHUTDOWN状态，再中断空闲的Worker（判断Worker是否空闲就通过它的锁方法）。所以，执行了这个方法后，正在执行的任务不会被中断，且已经存在workQueue中的Runnable也可以被执行，但是不能放入新的Runnable
1.2.2 shutdownNow（立即关闭）​	将当前线程池状态设为STOP状态，将所有Worker设置为中断位，且倒出workQueue中的所有Runnable。所以，执行了这个方法后，正在运行的任务如果检测了中断位就会立即退出，如果没检测就还是会执行完，而已经存在workQueue中的Runnable将不会被执行，会将这些Runnable返回给调用者，让调用者处理
/**
 * 平滑关闭线程池：
 * 1. 将线程池状态设为SHUTDOWN，此时：
 *    - 继续执行已提交的任务（包括正在执行的和队列中的）
 *    - 拒绝新任务提交（execute()会抛出RejectedExecutionException）
 * 2. 仅中断空闲Worker（通过tryLock()判断）
 * 
 * 注意：正在执行的任务不会被中断，调用者需确保任务有合理的终止逻辑
 */
public void shutdown() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();// 检查每个worker线程是否可以修改
        advanceRunState(SHUTDOWN); // CAS操作更新状态为SHUTDOWN
        interruptIdleWorkers(); // interrupt所有空闲的worker
    onShutdown(); // hook for ScheduledThreadPoolExecutor
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
}
/**
 * 立即关闭线程池：
 * 1. 将线程池状态设为STOP，此时：
 *    - 中断所有Worker（无论是否在执行任务）
 *    - 丢弃队列中未执行的任务
 *    - 拒绝新任务提交
 * 2. 返回被丢弃的任务列表供调用者处理
 * 
 * 注意：
 * - 正在执行的任务是否停止取决于任务是否响应中断
 * - 典型使用场景：需要快速释放资源的紧急关闭
 */
public List&lt;Runnable> shutdownNow() {
    List&lt;Runnable> tasks;
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();
        advanceRunState(STOP);// 设置当前线程池状态为STOP
        interruptWorkers();// interrupt所有Worker
        tasks = drainQueue(); // 将任务队列中的task全部丢弃给方法调用者
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
    return tasks;
}
/**
 * 尝试终止线程池的最终状态转换：
 * 1. 检查是否满足终止条件（3种直接返回的情况）：
 *    - RUNNING状态：还有任务在执行
 *    - 已经是TIDYING/TERMINATED状态：避免重复操作
 *    - SHUTDOWN状态但队列不空：等待任务处理完成
 * 2. 如果仍有活跃Worker，尝试中断单个空闲Worker
 * 3. 最终状态转换：
 *    SHUTDOWN/STOP -> TIDYING -> TERMINATED
 */
final void tryTerminate() {
    for (;;) {
        int c = ctl.get();
        // 三种情况下直接退出
        // 1.线程池处于Running状态，还在运行
        // 2.线程池状态大于TIDYING，代表当前线程池已经终结
        // 3.shutdown状态，并且任务队列不为空，代表需等待这些任务完成
        if (isRunning(c) ||
            runStateAtLeast(c, TIDYING) ||
            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
            return;
        if (workerCountOf(c) != 0) { // Eligible to terminate
            interruptIdleWorkers(ONLY_ONE);
            return;
        }

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {
                try {
                    terminated(); // hook方法
                } finally {
                    ctl.set(ctlOf(TERMINATED, 0));
                    termination.signalAll();
                }
                return;
            }
        } finally {
            mainLock.unlock();
        }
        // else retry on failed CAS
    }
}

1.2.3 setCorePoolSize设置核心线程数 corePoolSize，并根据变化动态调整 worker 数量

若变小：中断多余的空闲线程
若变大：启动新的 worker 以尽快处理等待队列中的任务

public void setCorePoolSize(int corePoolSize) {
    if (corePoolSize &lt; 0 || maximumPoolSize &lt; corePoolSize) {
        throw new IllegalArgumentException();
    }
    int delta = corePoolSize - this.corePoolSize;
    this.corePoolSize = corePoolSize;
    if (workerCountOf(ctl.get()) > corePoolSize) { // 需要减少
        // 内部会对所有空闲线程发出中断信号，使其从阻塞中退出，从而在 getTask 时主动终结
        interruptIdleWorkers();
    } else if (delta > 0) { // 需要增加

        // 最多不超过delta个线程
        int k = Math.min(delta, workQueue.size());
        // 动态增加worker数量，直至任务队列为空
        while (k-- > 0 &amp;&amp; addWorker(null, true)) {
            if (workQueue.isEmpty()) {
                break;
            }
        }
    }
}

1.2.4 execute（投递任务）核心流程：

先判断线程池的工作线程数量是否小于核心线程数，小于核心线程数直接新建线程来执行
如果核心线程数满了，则将Runnable投入到workQueue中
如果workQueue满了，则创建非核心线程来继续执行任务
如果线程池中的工作现场数量到达了maximumPoolSize的值，则使用拒绝策略来执行任务

// 执行execute的方法
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    // 获取当前线程池状态
    int c = ctl.get();
    // 判断是否小于核心线程数，是则新建线程运行任务
    if (workerCountOf(c) &lt; corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 核心数满了，并且当前线程池状态为Running，加到等待队列中
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        if (! isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 等待队列满了，新建线程，但不能大于最大线程数
    else if (!addWorker(command, false))
        // 创建失败，直接调用拒绝策略
        reject(command);
}

1.2.5 worker#run/ Worker的Runnable方法
public void run() {
    runWorker(this);
}

final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        // 利用阻塞队列，一直循环取任务执行（阻塞队列为空时会阻塞当前想取出元素的线程）
        // 如果getTask为null，就代表会终结当前工作线程
        while (task != null || (task = getTask()) != null) {
            // worker加锁。表示worker正在运行Runnable
            w.lock();
            if ((runStateAtLeast(ctl.get(), STOP) ||
                    (Thread.interrupted() &amp;&amp;
                            runStateAtLeast(ctl.get(), STOP)))
                    &amp;&amp;
                    !wt.isInterrupted())
                wt.interrupt();
            try {
                beforeExecute(wt, task); // hook before
                Throwable thrown = null;
                try {
                    task.run(); // 真正的运行Runnable
                } catch (RuntimeException x) {
                    thrown = x;
                    throw x;
                } catch (Error x) {
                    thrown = x;
                    throw x;
                } catch (Throwable x) {
                    thrown = x;
                    throw new Error(x);
                } finally {
                    afterExecute(task, thrown); // hook after
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}

/**
 * 核心方法之一：从工作队列中获取一个任务
 * 如果线程需要被回收（根据线程池状态、是否超时等判断），会返回 null来退出线程
 */
private Runnable getTask() {
    // 上一次循环的poll()是否超时
    boolean timedOut = false;
    // 死循环取任务
    for (;;) {
        int c = ctl.get();
        // 获取当前线程池状态
        int rs = runStateOf(c);

        // 状态校验
        if (rs >= SHUTDOWN &amp;&amp; (rs >= STOP || workQueue.isEmpty())) {
            decrementWorkerCount();
            return null;
        }

        int wc = workerCountOf(c);

        // 是否允许超时：开启核心线程超时，或该线程为非核心线程
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

        // 判断当前线程是否该终结：
        if ((wc > maximumPoolSize || (timed &amp;&amp; timedOut))
                &amp;&amp; (wc > 1 || workQueue.isEmpty())) {
            // 原子性的尝试减少一个工作线程，减少成功才返回结束线程
            if (compareAndDecrementWorkerCount(c))
                return null;
            continue;
        }

        try {
            // 根据timed选择超时（poll）还是阻塞（take）等待
            Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take();
            if (r != null)
                return r; // 取到了任务，可以返回了

            // 到这说明poll()超时了，没取到任务。设置timeOut，让下次循环可触发终止判断
            timedOut = true;
        } catch (InterruptedException retry) {
            // poll或take阻塞时触发了中断（相当于唤醒），再次进行重试
            timedOut = false;
        }
    }
}

总体工作流程​		调用getTask取任务来执行，如果取出的任务为空，则这个Worker也就结束了（终结了）。getTask不为空的话，还是先进性一系列的线程池状态校验，在执行hook函数（beforeExecute），在真正的执行这个Runnable，再执行hook函数（afterExecute），最后再将completedTasks加1，表示当前Worker完成的任务总数
getTask（实现线程超时回收的关键）
先进行一系列的状态校验
判断是否允许超时（满足任意一个就行）
allowCoreThreadTimeOut为true（都允许核心线程超时了，那没任务的情况下线程池就不该有worker线程）
当前线程池的工作线程数量大于核心线程数量就允许超时


判断是否触发减少工作线程数量的机制，然后使用CAS减少工作线程数量，减少成功才返回null，结束当前工作线程
通过阻塞队列取Runnable，如果不允许超时，则会一直阻塞到这。如果允许超时，则会超时等待keepAliveTime纳秒取Runnable，如果取不出来，则设置一次已经超时，再来循环一次，来判断是否该减少工作线程

2 ScheduledThreadPoolExecutor2.1 ScheduledExecutorServicepublic interface ScheduledExecutorService extends ExecutorService {
    /**
     * 创建一个一次性的延迟（定时）任务。
     * 框架中cron表达式就是通过此接口实现（只需要在任务完成后，在计算下一次的执行时间，再用此方法定时执行，以此类推）
     */
    public ScheduledFuture&lt;?> schedule(Runnable command,
                                       long delay, TimeUnit unit);

    /**
    * 执行Callable接口的任务，也是一个一次性的定时任务
    */
    public &lt;V> ScheduledFuture&lt;V> schedule(Callable&lt;V> callable,
                                           long delay, TimeUnit unit);
    /**
     * 基于固定的频率执行定时任务 
     * 例：初始执行任务的时间戳：当前时间戳（调用时）+ initialDelay 
     * 第二次执行：初始执行任务开始时的时间戳 + period 
     * 第三次执行：第二次执行任务开始时的时间戳 + period
     *
     * 典型场景：严格周期性的任务，如：
     * - 每分钟采集一次系统指标
     * - 每5秒发送心跳包
     */
    public ScheduledFuture&lt;?> scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit);
    /**
     * 基于固定的周期执行定时任务 
     * 例：初始执行任务的时间戳：当前时间戳（调用时）+ initialDelay
     *  第二次执行：初始任务执行完结时的时间戳 + delay
     *  第三次执行：第二次任务执行完结时的时间戳 + delay
     *
     * 典型场景：需要冷却时间的任务，如：
     * - 数据库批量处理（保证每次处理完成后再间隔）
     * - 异步结果轮询（避免密集请求）
     */
    public ScheduledFuture&lt;?> scheduleWithFixedDelay(Runnable command,
                                                     long initialDelay,
                                                     long delay,
                                                     TimeUnit unit);
}

2.2 DelayedWorkQueue​	为ScheduledThreadPoolExecutor内部固定的阻塞队列，基于小顶堆数据结构实现。
​	投递的每个任务被封装后都扔进DelayedWorkQueue中，按照任务被执行的时间戳进行小顶堆排序，堆顶就刚好是队列中下个需要执行的任务。同时基于Leader-Follower 模式进行线程调度的优化，只有leader进行延时等待堆首任务，其余线程直接阻塞等待
​	核心字段和方法如下
static class DelayedWorkQueue extends AbstractQueue&lt;Runnable>
        implements BlockingQueue&lt;Runnable> {
        // 数组初始容量
        private static final int INITIAL_CAPACITY = 16;
        // 数组实现的最小顶堆结构，queue[0]始终都是最快需要被执行的那个任务
        private RunnableScheduledFuture&lt;?>[] queue =
            new RunnableScheduledFuture&lt;?>[INITIAL_CAPACITY];
        private final ReentrantLock lock = new ReentrantLock();
        private int size = 0;
        // leader线程，定时等待queue[0]任务的那个线程
        private Thread leader = null;

        private final Condition available = lock.newCondition();
        // 向堆尾新加入任务，进行上移（和父节点换个位置）调整位置
        private void siftUp(int k, RunnableScheduledFuture&lt;?> key) {
            while (k > 0) {
                int parent = (k - 1) >>> 1; // 父节点的索引
                RunnableScheduledFuture&lt;?> e = queue[parent];
                if (key.compareTo(e) >= 0) // 调整完毕，直接break
                    break;
                // 当前节点的下次执行时间更快，继续递归向上遍历，直到放到合适的位置
                queue[k] = e;
                setIndex(e, k);
                k = parent;
            }
            queue[k] = key;
            setIndex(key, k);
        }
              /**
         * Sifts element added at top down to its heap-ordered spot.
         * Call only when holding lock.&lt;p/>
         * 元素下移操作（弹出堆顶元素后，将堆尾元素放置到堆顶再重新调整下移）
         */
        private void siftDown(int k, RunnableScheduledFuture&lt;?> key) {
            int half = size >>> 1;
            while (k &lt; half) {
                // 较小值节点的索引（初始为左子节点）
                int child = (k &lt;&lt; 1) + 1;
                // 小值，初始为左子节点
                RunnableScheduledFuture&lt;?> c = queue[child];
                // 右子节点索引
                int right = child + 1;
                if (right &lt; size &amp;&amp; c.compareTo(queue[right]) > 0) // 如果右子节点更小，则将c替换为右子节点，同时替换child为右子节点索引
                    c = queue[child = right];
                if (key.compareTo(c) &lt;= 0) // 目标元素比最小的子节点元素还小，目的就达成了，直接break
                    break;
                // 左右子节点中较小的节点和父节点交换
                queue[k] = c;
                setIndex(c, k);
                // 替换目标索引，继续将参数k向下比较
                k = child;
            }
            queue[k] = key;
            setIndex(key, k);
        }
        /**
          重写的offer方法（该方法就是线程池投递任务的方法）
         */
        public boolean offer(Runnable x) {
            if (x == null)
                throw new NullPointerException();
            RunnableScheduledFuture&lt;?> e = (RunnableScheduledFuture&lt;?>)x;
            final ReentrantLock lock = this.lock;
            lock.lock();
            try {
                int i = size;
                if (i >= queue.length)
                    grow();
                size = i + 1;
                if (i == 0) { // 数组中还没有任务，直接放在首位
                    queue[0] = e;
                    setIndex(e, 0);
                } else { // 已存在定时任务，看是否需要调整位置
                    siftUp(i, e);
                }
                 if (queue[0] == e) {// 代表向队列添加了一个需要最快执行的任务
                    // 需要重置leader线程，并唤醒一个阻塞的线程（可能为无限阻塞的，也可能为上个定时等待的leader线程）来定时等待这个任务
                    // 换种角度，如果唤醒的是上个定时等待的leader线程，那肯定是很赚的，因为不需要启动多个定时等待的线程了
                    // 如果唤醒的不是上个leader线程，那就会存在多个定时等待的线程，这是没法避免的
                    leader = null;
                    available.signal(); // 将阻塞的线程从等待队列转移到同步队列，当下面的unlock后再唤醒阻塞线程
                }
            } finally {
                lock.unlock();
            }
            return true;
        }
        
        /*
        重写的take方法
        
        所以，多线程多任务且没有任务需要立即执行造成的结果就是：
            1、1个leader线程定时等待队首任务（实时的向线程池添加最快需要执行的任务，可能存在多个定时等待的线程，且至少他们曾经是leader线程）
            2、其余全部线程无限期等待，最大程度的减少资源损耗（因为任务都有顺序，没必要同时让所有线程都定时等待，给底层的通知增加压力）
        总结：
        1、当没有任务时：所有线程都无限等待，没有leader线程，等待任务入队列的唤醒
        2、当有任务时：唤醒的线程成为leader线程，当这个leader线程等待到期时，
            取消自己为leader线程（另一种说法就是自己变成了follower线程），
            唤醒一个无限期等待的线程，然后自己就去执行这个到期的任务，被唤醒的线程就会变成新的leader线程。一直这么循环下去
        3、当实时向线程池添加最快需要执行的任务时：会取消当前leader线程，并唤醒一个阻塞的线程，让其成为新的leader线程

         */
        public RunnableScheduledFuture&lt;?> take() throws InterruptedException {
            final ReentrantLock lock = this.lock;
            lock.lockInterruptibly();
            try {
                for (;;) {
                    RunnableScheduledFuture&lt;?> first = queue[0];
                    if (first == null) // 不存在定时任务，所有线程都在这等待
                        available.await();
                    else {
                        long delay = first.getDelay(NANOSECONDS);
                        if (delay &lt;= 0) // 时间已过，弹出队首任务去执行它
                            return finishPoll(first);
                        // 进入下面，无论怎样都要等待，所以直接把first置为null，下次循环再获取
                        // 因为可能多个线程走到下面，都持有了队首的引用。避免出现RunnableScheduledFuture运行完了但不能及时回收的情况
                        // 当然，也只有一次性的RunnableScheduledFuture才会回收，定时任务都是循环使用这个RunnableScheduledFuture的
                        first = null; // don't retain ref while waiting
                        if (leader != null) // 由leader存在，其他线程只需要无限期等待就行
                            available.await();
                        else { // 没有leader存在，设置当前线程为leader，并定时等待（时间就为最近待执行的那个任务的距离下次执行时间间隔）
                            Thread thisThread = Thread.currentThread();
                            leader = thisThread;
                            try {
                                available.awaitNanos(delay); // 定时等待
                            } finally { // 时间一到，说明队首任务可执行了，但当前线程可能不是leader线程了，需要判断一下再置空
                                if (leader == thisThread) // 必须判断，有可能实时的添加了一个最快需要执行的线程，导致当前线程被取消了leader
                                    leader = null;
                            }
                        }
                    }
                }
            } finally {
                if (leader == null &amp;&amp; queue[0] != null)
                    // 任务取出来了，leader为空且存在队首任务，需要唤醒一个无限等待的线程
                    // 让其成为leader线程并继续定时等待
                    available.signal();
                lock.unlock();
            }
        }
}

2.3 总结​	ScheduledThreadPoolExecutor本质还是个线程池，内部的DelayedWorkQueue就是工作队列。投递的定时任务和普通任务都会封装为ScheduledFutureTask，并最终放入DelayedWorkQueue里的那个数组（只不过定时任务有延时，可能会放在队列中的任何位置。而普通任务封装的ScheduledFutureTask执行时间就是当前而已，始终会放到队列的队首并立马执行）
​		DelayedWorkQueue实现了BlockingQueue，是基于数组的最小顶堆的数据结构实现，以此保证数组的第一个位置就是最近需要被执行的任务。结构图和特点如下
​		ScheduledThreadPoolExecutor还使用了Leader-Follower模式，leader线程定时等待工作队列中第一个任务，其余线程一般就都无限期等待（如果向工作队列添加的是一个最快需要被执行的任务，可能就有多个定时等待的线程，但leader线程始终都会是最快需要被执行任务的线程）。
为什么使用Leader-Follower模式：

​		避免资源的浪费。定时任务再怎么排序，也只会有一个是最快需要执行的任务（时间相同会根据sequenceNumber排序），只需要设计一个定时等待线程等待这个最快需要执行的任务。当这个最快需要执行的任务触发后，再设计一个新的leader线程等待下一个最近的定时任务。理想的情况下，定时任务线程池只会有一个定时等待的线程（Leader线程），其余线程要么正在运行定时任务，要么全部无限期阻塞（Follower线程），最大程度的避免资源浪费（无限期等待的线程不用想其它的，乖乖等待被其他线程唤醒就行。而定时等待的线程需要在时间到达后被唤醒，至少需要被定时器监视以用来执行唤醒操作）


固定周期：受执行时常影响，只有当任务结束后才相对于结束时间来计算任务的下次执行时间
固定频率：不受任务的执行时常所影响，当任务投递到队列时就可以预判到以后任何执行该任务的时间

​	一个被投递的周期任务首先会封装成ScheduledFutureTask，再根据其下次执行时间放在DelayedWorkQueue的某个位置。如果放在了DelayedWorkQueue的队首，则使用定时任务线程池里的线程超时等待，以便时间到达后开始执行。正常执行完毕则会先根据其是固定周期任务还是固定频率的任务来计算下次执行时间并修赋值到ScheduledFutureTask的time字段，再将这个任务再次入队列，这样递归去执行。执行中如果抛出了异常，则会将ScheduledFutureTask的state修改为异常，之后就不再执行这个任务了
]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-锁</title>
    <url>/2020-04-18/java-yuan-ma-pian-suo/</url>
    <content><![CDATA[​	jdk中AQS实现类相关源码解析。包括 ReentrantLock，Condition，CountDownLatch，Semaphore，ReentrantReadWriteLock




1 ReentrantLock​		基于AQS实现的一种可重入互斥锁，所以只允许一个线程获取到锁。获取到锁时state设为1，当获取到锁的线程尝试重入时，便会增加state，同理需要将state减到0才会释放锁
1.1 非公平锁（NonfairSync）lock

java.util.concurrent.locks.ReentrantLock.Sync#nonfairTryAcquire：利用CAS尝试设置state，能设置成功，代表获取到锁，成功返回。设置失败，代表已经被其他线程获取了锁，返回失败
返回失败后将当前线程构造为Node节点，设置到同步队列的链表中进入到java.util.concurrent.locks.AbstractQueuedSynchronizer#acquireQueued方法：死循环获取当前Node的前一个节点（同步队列的首节点是成功获取到锁的节点），如果前驱结点为首节点，当前Node才有资格获取锁。如果还是获取不到，就调用java.util.concurrent.locks.LockSupport#park(java.lang.Object)方法阻塞当前线程，等待其他线程唤醒再去竞争锁


unlock

java.util.concurrent.locks.ReentrantLock.Sync#tryRelease：复原state（将其归0），exclusiveOwnerThread设为null
java.util.concurrent.locks.AbstractQueuedSynchronizer#release：在tryRelease成功后，使用java.util.concurrent.locks.LockSupport#unpark方法唤醒同步队列首节点的下一个节点里的线程，让他再去尝试获取锁


1.2 公平锁（FairSync）lock
​		和非公平锁很像，不同的部分就在覆盖了java.util.concurrent.locks.AbstractQueuedSynchronizer#tryAcquire这个方法和非公平锁略有不同。在新的线程获取锁失败，并将自己构造为Node节点并放入同步队列链表后，还会通过调用java.util.concurrent.locks.AbstractQueuedSynchronizer#hasQueuedPredecessors方法

unlock：和非公平锁一样核心代码
// ReentrantLock的公平锁第一次尝试获取锁
protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &amp;&amp; // 测试当前线程是否是等待最久的线程
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
} 

/** 
 * 查询是否有线程等待获取的时间长于当前线程
 * 判断是否存在队列中第二个Node(因为首节点是个空节点)，且第二个节点中的线程是否是当前线程
 * 也就是说：判断同步队列中当前节点是否有前驱结点
 * true:代表当前线程不是等待最久的线程或压根就没有等待的线程
 * false:在代表当前线程已经是等待最久的线程（毕竟队列越前面，则代表进去的越久）&lt;p/>
 * 只有公平锁才需要用到这个方法，来判断当前线程是否等待时间最长
 */
public final boolean hasQueuedPredecessors() {
    Node t = tail; 
    Node h = head;
    Node s;
    // 用 h != t 来做判断是因为调用这个方法的线程此时还没有进入等待队列
    // 如果 h != t，则代表队列中有线程在等待获取锁
    return h != t &amp;&amp;
        ((s = h.next) == null || s.thread != Thread.currentThread());
}

1.3 总结1.3.1 为什么叫公平锁和非公平锁​	根据上面的分析，公平锁在获取锁是总是会先判断当前线程是否是等待最久的线程。所以，就算是同步队列存在大量Node，且有线程第一次在获取锁，那么，下一次获取到锁的线程也一定是同步队列的首节点的下一个节点，即必须排队。（首节点就是当前获取到锁的节点，只有获取成功了，同步才会更新首节点）
​	非公平锁中：对于已经进入同步队列的线程来说，也只能首节点的下一个节点里的线程能尝试获取锁。但对于还未构造成Node加入到同步队列的线程来说，这个线程和首节点的下一个节点里的线程能竞争获取锁，所以非公平。但对于已经进入同步队列的线程来说，前驱结点是一定比后面的节点先获取到锁的
1.3.2 各自优势
公平锁：防止线程饥饿，分散性很好，适合线程等待时间敏感的场景
非公平锁：更快。一是获取锁是不用判断当前线程是否是等待最久的线程。二是上下文交换没有公平锁频繁。在存在大量锁竞争的前提下，可以肯定，公平锁上下文切换很频繁，获取锁后的线程再次获取锁时是一定会阻塞的。而非公平锁则不一样，下一次获取到锁的线程仍可能是上一次获取到锁的线程，没有上下文切换

2 Condition等待通知接口，代替Object原生的wait和notify，其具体实现为AQS里的ConditionObject（定义在AQS里的非静态内部类，所以使用了AQS部分方法来实现其功能）。只有获取到锁的线程才能调用Condition的阻塞和唤醒方法。三个核心组件如下

等待队列：使用 Node 节点串联，与 AQS 同步队列共用 Node 结构 
状态转换：Node 在等待队列和同步队列之间的转换 
线程控制：包括阻塞、唤醒、中断处理等机制

主要字段
// 等待队列中的首节点
private transient Node firstWaiter;
// 等待队列中的尾节点
private transient Node lastWaiter;

2.1 Condition#await流程

首先将当前线程构造为等待节点，并加入到等待队列的末尾
其次释放锁资源（能够await的线程一定是获取到锁的），同时唤醒同步队列的第二个节点，让其尝试获取锁
死循环判断当前节点是否为同步节点（等待节点在等待队列里，是一定要阻塞的。同步节点在同步队列里，是可以并被唤醒并尝试获取锁的），await到这里线程就阻塞了
当被唤醒后，当前节点一定被加入了同步队列，再尝试获取锁，如果能获取到，代表就可以返回了。如果获取不到，就表示当前同步块被其他线程暂用了，也还是阻塞。不过下一次被唤醒后就会通过同步队列的唤醒方式来尝试获取锁


代码public final void await() throws InterruptedException {
    if (Thread.interrupted()) // 响应中断
        throw new InterruptedException();
    // 构建等待节点并加入等待队列
    Node node = addConditionWaiter();
    // 先检查当前线程是否已获取到锁，否则抛异常。然后完全释放锁并且唤醒同步队列中的第二个节点
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    // 死循环判断当前节点是否在等待队列中
    // 等待队列中的节点一定要阻塞，而同步队列中的节点是可以被唤醒的
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 当signal后，需要重新获取锁，要复原现场，需要重新持有上一次所持有的所有的state值
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0) // 当前节点有中断
        reportInterruptAfterWait(interruptMode);
}
/**
 *   将当前线程构造为一个等待节点，并加入到等待队列的尾部，并通过nextWaiter字段建立联系 &lt;br/>
 *  注意：等待队列建立关联用的是nextWaiter字段，不是prev和next字段
 */
private Node addConditionWaiter() {
    Node lastW = lastWaiter; // 尾节点
    // If lastWaiter is cancelled, clean out.
    if (lastW != null &amp;&amp; lastW.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        lastW = lastWaiter;
    }
    Node node = new Node(Thread.currentThread(), Node.CONDITION);
    if (lastW == null)
        firstWaiter = node;
    else
        lastW.nextWaiter = node;
    lastWaiter = node;
    return node;
}

// ====================以下为AQS中的方法===================
// 判断这个节点是否在同步队列上
// false -> 这个节点在等待队列上
// true -> 这个节点在同步队列上
final boolean isOnSyncQueue(Node node) {
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    if (node.next != null) // If has successor, it must be on queue
        return true;
    return findNodeFromTail(node);
}
/**
* 当前节点尝试获取锁
* 返回true -> 获取锁的过程有中断
*/
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node prevNode = node.predecessor();
            // 只有当前节点的前驱结点为首节点，当前节点里的线程才有资格获取锁
            // 只可能有一个线程获取成功（即获取锁），所以设置首节点不需要同步了
            if (prevNode == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                prevNode.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(prevNode, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

2.2 Condition#signal和signalAll分析singal的目的很简单，就是将等待队列的首节点转移到同步队列的尾节点，signalAll则是将等待队列中的所有节点都转移到同步节点。signal方法本身不能唤醒线程，只是让这些节点里的线程有资格被唤醒，可以将signal和排队买票做类比

等待队列相当于候补区
signal 相当于叫号，让候补区的人去正式排队区（同步队列）
但叫号本身并不会直接让人拿到票，还需要排队区的人按顺序获取票（锁）

代码private void doSignal(Node first) {
    do {
        // 将首节点的nextWaiter转移到首节点，如果nextWaiter为空，则表示队列中只有一个节点，且首尾相同
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null; // gc处理
    } while (!transferForSignal(first) &amp;&amp;
             (first = firstWaiter) != null);
}
// 将当前的等待节点转换为同步节点，并加入到同步队列的末尾
final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;
    Node p = enq(node);
    int ws = p.waitStatus;
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        LockSupport.unpark(node.thread); // 前驱节点被取消了，或者设置为SIGNAL失败
    return true;
}

2.3 总结​		Condition实现了等待通知，当一个线程进入同步块后，就可以调用await，释放自己获取的锁资源，将自己阻塞。内部实现是首先将当前线程构造成一个等待节点，加入ConditionObject的等待队列的末尾，再释放锁资源，之后唤醒同步队列的第二个节点让其尝试获取锁。而当其他进入同步块的线程调用signal后，会将等待队列的首节点转移到同步队列，并将其变成同步节点，最后再使用同步队列的唤醒机制等待被唤醒。
​		所以signal并不能直接唤醒一个await的线程，最佳使用案例就是消费者发送者机制，比如阻塞队列。
3 CountDownLatchCountDownLatch为共享锁实现，只能使用一次。用来“卡点”，阻塞的线程需要等待其他线程准备好了后（countDown直到AQS里的state为0），才继续被唤醒执行后面的代码。
在CountDownLatch中，AQS里的state值并不表示可获取到锁的次数，而是java.util.concurrent.CountDownLatch#countDown state值的次数后会释放所有调用了**java.util.concurrent.CountDownLatch#await()**的线程
内部的同步器Sync主要方法
/**
    获取共享锁，只有AQS的state为0才能获取到
    通过这个接口就可以猜到，当state为0时（拉下了所有门闩），总会返回1，代表获取锁成功。
    并依次传播下去递归调用这个方法，直到同步队列的所有Node里的线程全部唤醒，这就是CountDownLatch的原理
*/
protected int tryAcquireShared(int acquires) {
    return (getState() == 0) ? 1 : -1;
}

// 释放共享锁，state第一次被减为0才释放成功，也就表示了CountDownLatch只能用一次
protected boolean tryReleaseShared(int releases) {
    // Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}

await方法会阻塞当前线程，直到其他线程“拉下所有门闩”。阻塞的线程会构造为共享节点加入同步队列，只有队首节点的下一个节点才有资格尝试获取锁，获取不到就LockSupport#park
countDown会将state值减小1，当state将为0时，释放同步队列里的第二个共享节点里的线程。当这个线程释放后，就能成功获取到锁了，将这个事件传播下去，一次唤醒同步队列里的所有共享节点。至此，所有被阻塞的线程都被唤醒且会成功获取到锁，最终从await方法里返回
4 Semaphore信号量，共享锁实现。可以利用构造器指定令牌（permits）的数量。当线程到达时，获取（acquire）指定数量的令牌，当没有可用令牌（premits为0）时，阻塞线程，等待令牌的释放（release）再被唤醒后继续执行。基于此，即可实现共享锁（permits大于1），也可实现不可重入的互斥锁（permits为1）
也分为公平锁和分公平锁，其判断方式完全和ReentrantLock一致。
​		非公平锁允许准备进入同步块的线程（还未加入同步队列）和同步队列中的第二个节点竞争获取锁。而公平锁则只允许同步队列中第二个节点里的线程能尝试获取锁。
​		其实现方式就是将state设为我们允许并发运行的线程数量，每当一个线程获取到锁后，将state - 1，如果state为0则阻塞所有准备进入同步块的线程，并将其构造为共享节点加入同步队列。每当有线程从同步块退出时，将state + 1，并根据是否非公平来唤醒同步队列的第二个节点来尝试获取锁
5 ReentrantReadWriteLock​		读写锁，支持并发的读或互斥的写。读写锁分别各自实现，读锁使用共享锁，写锁使用互斥锁。ReentrantReadWriteLock内部的ReadLock和WriteLock都使用了内部同一个Sync对象来实现读写加锁的功能，在Sync内，他将AQS的state转换为二进制，高十六位表示读状态位，低十六位表示写状态位。由于读是共享的，所以state的高十六位表示了当前有多少个线程在读，在此期间写锁是禁用的。而低十六位是写锁，所以只可能有一个线程，但可能数字大于1（这是就表示写锁重入了）。当写锁被占用是，读是不允许的
static final int SHARED_SHIFT= 16;                     //   读状态位            写状态位
static final int SHARED_UNIT  = (1 &lt;&lt; SHARED_SHIFT); // 0000000000000001 0000000000000000
static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;//0000000000000000 1111111111111111
static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;//0000000000000000 1111111111111111
// 获取共享锁冲入次数（读锁专用）
static int sharedCount(int c)    { return c >>> SHARED_SHIFT; }
// 获取排他锁冲入次数（写锁专用）
static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; }


读写锁都支持重入，但写锁只能让当前线程重入，并且要解锁时需要unlock重入的次数。

支持锁降级但不支持锁升级

 锁降级：即一个线程在持有写锁的情况下，可以继续获取读锁，然后释放写锁，从而将写锁降级为读锁。在某些场景下很有用，比如

在写操作完成后，仍然需要保持对数据的读访问权限
避免其他线程在写锁释放后立即获取写锁，导致数据不一致




]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>AQS实现类</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-@Resource和@Autowired的分析</title>
    <url>/2021-01-18/spring-resource-he-autowired-de-fen-xi/</url>
    <content><![CDATA[
​	从源码分析了@Resource和@Autowired的依赖创建流程和这两个注解的的异同




紧接上篇文章Spring-Bean的字段填充阶段相关处理器
@Resource​	CommonAnnotationBeanPostProcessor#autowireResource部分核心源码
if (factory instanceof AutowireCapableBeanFactory) {
  AutowireCapableBeanFactory beanFactory = (AutowireCapableBeanFactory) factory;
  // field依赖会构建成LookupDependencyDescriptor，required只能为true
  DependencyDescriptor descriptor = element.getDependencyDescriptor();
  // byType
  // 当不设置@Resource.name字段值，以字段名作为beanName的Bean不在容器中
  if (this.fallbackToDefaultTypeMatch &amp;&amp; element.isDefaultName &amp;&amp; !factory.containsBean(name)) {
    autowiredBeanNames = new LinkedHashSet&lt;>();
    // 解析依赖bean
    resource = beanFactory.resolveDependency(descriptor, requestingBeanName, autowiredBeanNames, null);
    if (resource == null) {
      throw new NoSuchBeanDefinitionException(element.getLookupType(), "No resolvable resource object");
    }
  } else { // byName
    resource = beanFactory.resolveBeanByName(name, descriptor);
    autowiredBeanNames = Collections.singleton(name);
  }
}

@Autowired​	AutowiredFieldElement#resolveFieldValue部分核心源码
// 此时required可由我们定义，表示这个bean不再是必须存在的
DependencyDescriptor desc = new DependencyDescriptor(field, this.required);
desc.setContainingClass(bean.getClass());
Set&lt;String> autowiredBeanNames = new LinkedHashSet&lt;>(1);
Assert.state(beanFactory != null, "No BeanFactory available");
TypeConverter typeConverter = beanFactory.getTypeConverter();
Object value;
try {
  // 解析依赖bean，只有byType
  value = beanFactory.resolveDependency(desc, beanName, autowiredBeanNames, typeConverter);
}
catch (BeansException ex) {
  throw new UnsatisfiedDependencyException(null, beanName, new InjectionPoint(field), ex);
}

公共的解析源码AutowireCapableBeanFactory#resolveDependency主要流程：


判断注入点是否标注了 @Lazy，如有，则返回懒加载代理对象；
若标注了 @Value，解析其占位符表达式并进行类型转换；
判断依赖类型，若是集合类型（如 List、Map、Stream 、数组等），则调用 resolveMultipleBeans 获取所有候选
若为单个 Bean 类型，则根据类型查找候选 Bean，结合 @Qualifier、@Primary、@Priority 等注解进行筛选；
若无匹配 Bean，是否抛出异常由 required 属性决定。


public Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName,
    @Nullable Set&lt;String> autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException {

  descriptor.initParameterNameDiscovery(getParameterNameDiscoverer());
  if (Optional.class == descriptor.getDependencyType()) { // 处理类型为Optional
    return createOptionalDependency(descriptor, requestingBeanName);
  }
  else if (ObjectFactory.class == descriptor.getDependencyType() ||
      ObjectProvider.class == descriptor.getDependencyType()) {
    return new DependencyObjectProvider(descriptor, requestingBeanName);
  }
  else if (javaxInjectProviderClass == descriptor.getDependencyType()) {
    return new Jsr330Factory().createDependencyProvider(descriptor, requestingBeanName);
  }
  else {
    // 判断是否有@Lazy注解。使用了@Lazy则在这里直接创建了代理对象并返回
    Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary(
        descriptor, requestingBeanName);
    if (result == null) {
      // 开始获取依赖bean
      result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter);
    }
    return result;
  }
}

public Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName,
    @Nullable Set&lt;String> autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException {

  InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor);
  try {
    Object shortcut = descriptor.resolveShortcut(this);
    if (shortcut != null) {
      return shortcut;
    }

    Class&lt;?> type = descriptor.getDependencyType();
    // 解析@Value注解
    Object value = getAutowireCandidateResolver().getSuggestedValue(descriptor);
    if (value != null) {
      if (value instanceof String) {
        String strVal = resolveEmbeddedValue((String) value);
        BeanDefinition bd = (beanName != null &amp;&amp; containsBean(beanName) ?
            getMergedBeanDefinition(beanName) : null);
        value = evaluateBeanDefinitionString(strVal, bd);
      }
      TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter());
      try {
        return converter.convertIfNecessary(value, type, descriptor.getTypeDescriptor());
      }
      catch (UnsupportedOperationException ex) {
        // A custom TypeConverter which does not support TypeDescriptor resolution...
        return (descriptor.getField() != null ?
            converter.convertIfNecessary(value, type, descriptor.getField()) :
            converter.convertIfNecessary(value, type, descriptor.getMethodParameter()));
      }
    }
    // 先进行多bean解析
    Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter);
    if (multipleBeans != null) { // 多bean解析出来了则直接返回
      return multipleBeans;
    }
    // 将这个type所有的可能bean都解析出来
    Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, type, descriptor);
    if (matchingBeans.isEmpty()) { // 没找到
      if (isRequired(descriptor)) { 
        // 如过required为true，会直接跑异常
        // 只有@Autowired才可设置required为false
        raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor);
      }
      return null;
    }

    // ====== 走到这表示这个bean是单个的，需要再根据其他注解来返回一个优先级最高的bean ======

    // 最终的依赖beanName
    String autowiredBeanName;
    // 最终的依赖bean实例
    Object instanceCandidate;

    if (matchingBeans.size() > 1) { // 存在多个候选bean
      // 会先根据@Primary注解筛选，否则根据@Priority筛选出优先级最高的bean
      autowiredBeanName = determineAutowireCandidate(matchingBeans, descriptor);
      if (autowiredBeanName == null) { // 异常处理，根据required选择是否跑异常
        if (isRequired(descriptor) || !indicatesMultipleBeans(type)) {
          return descriptor.resolveNotUnique(descriptor.getResolvableType(), matchingBeans);
        }
        else {
          return null;
        }
      }
      instanceCandidate = matchingBeans.get(autowiredBeanName);
    }
    else { // 只有1个候选bean
      Map.Entry&lt;String, Object> entry = matchingBeans.entrySet().iterator().next();
      autowiredBeanName = entry.getKey();
      instanceCandidate = entry.getValue();
    }

    if (autowiredBeanNames != null) {
      autowiredBeanNames.add(autowiredBeanName);
    }
    if (instanceCandidate instanceof Class) {
      instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this);
    }
    Object result = instanceCandidate;
    if (result instanceof NullBean) {
      if (isRequired(descriptor)) {
        raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor);
      }
      result = null;
    }
    if (!ClassUtils.isAssignableValue(type, result)) {
      throw new BeanNotOfRequiredTypeException(autowiredBeanName, type, instanceCandidate.getClass());
    }
    return result;
  }
  finally {
    ConstructorResolver.setCurrentInjectionPoint(previousInjectionPoint);
  }
}

DefaultListableBeanFactory#resolveMultipleBeans​	支持注入类型为 Collection&lt;T&gt;、Map&lt;String, T&gt;、T[] 和 Stream&lt;T&gt; 的多 Bean 依赖。该方法会查找所有匹配的候选 Bean，按类型筛选、处理限定符（如 @Qualifier），并封装成目标集合类型返回。
/**
处理依赖bean的type是一个容器的情况。可能为 数组、集合、Map甚至Stream
*/
private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName,
    @Nullable Set&lt;String> autowiredBeanNames, @Nullable TypeConverter typeConverter) {

  Class&lt;?> type = descriptor.getDependencyType();

  if (descriptor instanceof StreamDependencyDescriptor) { // type = Stream
    Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, type, descriptor);
    if (autowiredBeanNames != null) {
      autowiredBeanNames.addAll(matchingBeans.keySet());
    }
    Stream&lt;Object> stream = matchingBeans.keySet().stream()
        .map(name -> descriptor.resolveCandidate(name, type, this))
        .filter(bean -> !(bean instanceof NullBean));
    if (((StreamDependencyDescriptor) descriptor).isOrdered()) {
      stream = stream.sorted(adaptOrderComparator(matchingBeans));
    }
    return stream;
  }
  else if (type.isArray()) { // type = 数组
    Class&lt;?> componentType = type.getComponentType();
    ResolvableType resolvableType = descriptor.getResolvableType();
    Class&lt;?> resolvedArrayType = resolvableType.resolve(type);
    if (resolvedArrayType != type) {
      componentType = resolvableType.getComponentType().resolve();
    }
    if (componentType == null) {
      return null;
    }
    Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, componentType,
        new MultiElementDescriptor(descriptor));
    if (matchingBeans.isEmpty()) {
      return null;
    }
    if (autowiredBeanNames != null) {
      autowiredBeanNames.addAll(matchingBeans.keySet());
    }
    TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter());
    Object result = converter.convertIfNecessary(matchingBeans.values(), resolvedArrayType);
    if (result instanceof Object[]) {
      Comparator&lt;Object> comparator = adaptDependencyComparator(matchingBeans);
      if (comparator != null) {
        Arrays.sort((Object[]) result, comparator);
      }
    }
    return result;
  }
  else if (Collection.class.isAssignableFrom(type) &amp;&amp; type.isInterface()) { // type = 集合
    // 解析出这个bean的范型type
    Class&lt;?> elementType = descriptor.getResolvableType().asCollection().resolveGeneric();
    if (elementType == null) {
      return null;
    }
    // 找出匹配范型type的候选bean
    Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, elementType,
        new MultiElementDescriptor(descriptor));
    if (matchingBeans.isEmpty()) {
      return null;
    }
    if (autowiredBeanNames != null) {
      autowiredBeanNames.addAll(matchingBeans.keySet());
    }
    TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter());
    Object result = converter.convertIfNecessary(matchingBeans.values(), type);
    if (result instanceof List) {
      if (((List&lt;?>) result).size() > 1) {
        Comparator&lt;Object> comparator = adaptDependencyComparator(matchingBeans);
        if (comparator != null) {
          ((List&lt;?>) result).sort(comparator);
        }
      }
    }
    return result;
  }
  else if (Map.class == type) {  // type = Map
    ResolvableType mapType = descriptor.getResolvableType().asMap();
    Class&lt;?> keyType = mapType.resolveGeneric(0);
    if (String.class != keyType) {
      return null;
    }
    // 解析出Map中value的type
    Class&lt;?> valueType = mapType.resolveGeneric(1);
    if (valueType == null) {
      return null;
    }
    // 对value type进行bean搜索，返回
    Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, valueType,
        new MultiElementDescriptor(descriptor));
    if (matchingBeans.isEmpty()) {
      return null;
    }
    if (autowiredBeanNames != null) {
      autowiredBeanNames.addAll(matchingBeans.keySet());
    }
    return matchingBeans;
  }
  else {
    return null;
  }
}

DefaultListableBeanFactory#findAutowireCandidates​	DefaultListableBeanFactory#findAutowireCandidates 用于查找参数中 beanName（如 Bean A）所依赖的、类型为 requiredType 的所有候选 Bean（如 Bean B）。返回结果为一个 Map&lt;String, Object&gt;，其中 key 是候选 Bean 的名称，value 是对应的实例。
​		方法内部会先在 BeanFactory 中找出所有类型匹配 requiredType 的 Bean 名称，然后根据限定注解（如 @Qualifier）等条件进行筛选。筛选通过的候选 Bean 会被递归创建并作为依赖返回。
protected Map&lt;String, Object> findAutowireCandidates(
    @Nullable String beanName, Class&lt;?> requiredType, DependencyDescriptor descriptor) {
  // 找出这个type所有的beanName
  // 内部就是遍历BeanFactory中所有的BeanDefinition，依次进行type匹配判断，在收集结果并缓存
  String[] candidateNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(
      this, requiredType, true, descriptor.isEager());
  Map&lt;String, Object> result = new LinkedHashMap&lt;>(candidateNames.length);
  // 一些特殊bean的处理，比如ApplicationContext之类的bean
  for (Map.Entry&lt;Class&lt;?>, Object> classObjectEntry : this.resolvableDependencies.entrySet()) {
    Class&lt;?> autowiringType = classObjectEntry.getKey();
    if (autowiringType.isAssignableFrom(requiredType)) {
      Object autowiringValue = classObjectEntry.getValue();
      autowiringValue = AutowireUtils.resolveAutowiringValue(autowiringValue, requiredType);
      if (requiredType.isInstance(autowiringValue)) {
        result.put(ObjectUtils.identityToString(autowiringValue), autowiringValue);
        break;
      }
    }
  }
  // 依次判断每个候选beanName，看其是否有资格成为真正的目标bean
  for (String candidate : candidateNames) {
    // 非自引用，isAutowireCandidate最终会调用到QualifierAnnotationAutowireCandidateResolver#isAutowireCandidate方法，根据@Qualifier注解来判断是否是目标bean
    if (!isSelfReference(beanName, candidate) &amp;&amp; isAutowireCandidate(candidate, descriptor)) { 
      // 目标bean，会使用BeanFactory来获取这个bean。实现递归创建bean
      addCandidateEntry(result, candidate, descriptor, requiredType);
    }
  }
  if (result.isEmpty()) { // 上面的流程没找到，则进行fallback放宽条件继续找
    boolean multiple = indicatesMultipleBeans(requiredType);
    DependencyDescriptor fallbackDescriptor = descriptor.forFallbackMatch();
    for (String candidate : candidateNames) {
      if (!isSelfReference(beanName, candidate) &amp;&amp; isAutowireCandidate(candidate, fallbackDescriptor) &amp;&amp;
          (!multiple || getAutowireCandidateResolver().hasQualifier(descriptor))) {
        addCandidateEntry(result, candidate, descriptor, requiredType);
      }
    }
    if (result.isEmpty() &amp;&amp; !multiple) { // 继续放宽条件
      for (String candidate : candidateNames) {
        if (isSelfReference(beanName, candidate) &amp;&amp;
            (!(descriptor instanceof MultiElementDescriptor) || !beanName.equals(candidate)) &amp;&amp;
            isAutowireCandidate(candidate, fallbackDescriptor)) {
          addCandidateEntry(result, candidate, descriptor, requiredType);
        }
      }
    }
  }
  return result;
}

两个注解总结共同点
都支持容器类型的Bean解析（比如Stream，数组，集合，Map）
都支持@Lazy，@Qualifier，@Value等注解
都支持字段、方法参数

不同点
@Autowired可以设置required为false，即不强制需要这个bean。而@Resource则必须要对应的bean存在
@Resource由javax提供，是集byName和byType为一体的注解。框架无关，属于 Java 官方对 IOC 容器的通用约定。在Spring中，当没设置@Resource的name，并且由框架解析出来的name（字段名or去掉set的方法名）不在容器中才会使用byType
@Autowired本身只能byType，搭配@Qualifier才可实现byName

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-AbstractAdvisingBeanPostProcessor</title>
    <url>/2021-02-17/spring-abstractadvisingbeanpostprocessor/</url>
    <content><![CDATA[
​	从源码分析了AbstractAdvisingBeanPostProcessor的作用，以及和直接将Advisor注入到容器中使用的区别




​	上一篇注解的切面自动代理
​	简单来说这是一个用于将固定 Advisor 应用于 Bean 的通用基类，常用于实现基于注解的 AOP 功能（如异步、Validate）。核心子类有

AsyncAnnotationBeanPostProcessor：处理标注了 @Async 的方法，将其在调用时提交到线程池异步执行
MethodValidationPostProcessor：支持 @Validated 注解，拦截方法调用并对方法参数和返回值执行 JSR-303 Bean Validation

核心作用
该类允许你通过定义一个固定的 Advisor（通过其 advisor 字段）来对目标 Bean 进行增强。
并不主动创建代理（因为AnnotationAwareAspectJAutoProxyCreator具有最高的优先级，会最先对bean进行代理），而是在 Bean 已被代理的情况下，将该 Advisor 添加到现有的代理中，从而实现功能增强。

​	不主动创建代理是很好理解的，Spring 不希望对同一个 Bean 多次生成代理类（多个 CGLIB class 文件或多个 JDK proxy 实例），这不仅浪费资源，还会引发增强混乱。因此：

Spring 通过设置 AnnotationAwareAspectJAutoProxyCreator 的最高优先级，统一负责生成代理对象。
后续如 AsyncAnnotationBeanPostProcessor、MethodValidationPostProcessor 等，只需向已创建的代理对象添加 Advisor，即向其 AdvisedSupport#advisors 中追加增强逻辑。
最终所有增强统一挂载在一个代理对象上，避免了重复代理、类污染与不必要的性能开销。

核心源码public abstract class AbstractAdvisingBeanPostProcessor extends ProxyProcessorSupport implements BeanPostProcessor {
    // 由子类设置的Advisot
    protected Advisor advisor;
    // 是否需要将advisor放在整个代理链的最前，以达到最先执行的目的
    // 很有用，@Async会设置成true，从而让异步在第一个切面就开启，避免代理链在不同线程间切换
    protected boolean beforeExistingAdvisors = false;

    // bean 初始化后的hook
    public Object postProcessAfterInitialization(Object bean, String beanName) {
        if (this.advisor == null || bean instanceof AopInfrastructureBean) {
            // Ignore AOP infrastructure such as scoped proxies.
            return bean;
        }

        // 判断当前的bean是否已经是个代理类了
        // 已经是代理类的bean，就不需要再重新创建proxy，直接用现有的，把advisor加入到list中就行
        if (bean instanceof Advised) {
            Advised advised = (Advised) bean;
            // 只有再当前proxy未frozen的情况下，且原始bean支持被代理才需要增强
            if (!advised.isFrozen() &amp;&amp; isEligible(AopUtils.getTargetClass(bean))) {
                if (this.beforeExistingAdvisors) { // 放最前面，最先执行
                    advised.addAdvisor(0, this.advisor);
                }
                else { // 否则放最后
                    advised.addAdvisor(this.advisor);
                }
                return bean;
            }
        }
        // ======== 走到这表示这个bean没被代理或代理已被冻结，新开一个代理再包装这个bean，可能造成层层代理 =============

        // 判断当前的advisor能否对这个bean增强
        if (isEligible(bean, beanName)) {
            ProxyFactory proxyFactory = prepareProxyFactory(bean, beanName);
            if (!proxyFactory.isProxyTargetClass()) {
                evaluateProxyInterfaces(bean.getClass(), proxyFactory);
            }
            proxyFactory.addAdvisor(this.advisor);
            customizeProxyFactory(proxyFactory);
            return proxyFactory.getProxy(getProxyClassLoader());
        }

        // No proxy needed.
        return bean;
    }

    // 也很重要，它默认还是用AopUtils#canApply来判断能否代理这个bean
    // 但子类可以实现它，自定义的来判断能否代理bean
    protected boolean isEligible(Object bean, String beanName) {
        return isEligible(bean.getClass());
    }
}

一点思考​	其实向容器中注册一个Advisor也能达到和AbstractAdvisingBeanPostProcessor一样的目的，还更简单点。那为什么还要有AbstractAdvisingBeanPostProcessor呢？
​	因为向容器中注册一个Advisor需要依赖自动代理，即AnnotationAwareAspectJAutoProxyCreator。这个BeanPostProcessor是比较重的，功能更强也意味着更复杂。如果我们完全不需要注解式的自动代理，而只需要对某个注解（如@Async）进行代理，那实现AbstractAdvisingBeanPostProcessor是更好的选择，它不依赖自动代理，独自就能完成指定Advisor的代理，更轻
​	所以，总结AbstractAdvisingBeanPostProcessor的优势：

不依赖自动代理器：它本身就是一个 BeanPostProcessor，可以独立完成代理创建
只处理特定目标：可以通过内部的 isEligible() 方法自定义增强对象的筛选逻辑
避免过度代理：避免引入全局自动代理，减少对容器中其他 bean 的干扰
具备顺序控制能力：如 @Async 会将自身的 Advisor 放到代理链最前面，确保异步逻辑在最早执行。

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-Bean的Scope</title>
    <url>/2021-06-28/spring-bean-de-scope/</url>
    <content><![CDATA[
​	分析了Spring Scope的作用和实现类。并从源码分析了其Scoped Proxy作用和实现，并在最后用arthas进行了简单的验证。重点应该关注基于代理的其他作用域Bean注册的两个BeanDefinition异同点，以及为何会注册两个BeanDefinition




​	在 Spring 中，所有组件本质上都是 Bean，虽然它们的创建方式一致，但生命周期和缓存策略并不统一。为了支持不同的使用场景，Spring 设计了 Scope（作用域）机制，来决定 Bean 实例在容器中的缓存行为。
常见的 Scope
通用环境



singleton：默认作用域。单例bean，由Spring进行全局缓存
prototype：很多博客翻译为多例，其实容易误导，因为session和request中的bean也算多例。翻译为原型bean更好，因为它是基于 Bean 定义模板进行实例化 的原型模式，每次获取Bean时都会创建一个新的实例（即取即创建）。因此，它不能被缓存，也不能被循环依赖





web环境


session：web环境下的缓存在Session里的bean

request：web环境下的缓存在Request里的bean。意味着每次新的Request，都需要创建新的bean
application：web环境下缓存在ServletContext里的bean。是存在于另一个容器里单例bean





cloud环境


 refresh：spring colud环境下的一种作用域，在这个作用域里的bean意味着每次环境刷新后（RefreshEvent事件触发），都需要创建新的bean，并destory以前bean。例如cloud环境下如果配置中心支持动态更改kv，每次修改kv后就出触发RefreshEvent事件





Scope实现​	在 AbstractBeanFactory#doGetBean 方法中，所有非默认作用域（非 singleton&#x2F;prototype）的 Bean 获取，均通过 Scope 接口实现支持。每种运行环境对应一个 Scope 实例，由它统一负责该环境下 Bean 的 创建、缓存与销毁。Spring提供的常见Scope实现如下

SessionScope：session域的实现

RequestScope：request域的实现

ServletContextScope：application域的实现

RefreshScope：refresh域的实现

SimpleThreadScope：用ThreadLocal实现的Bean的缓存域。即线程可见Bean

SimpleTransactionScope：事务作用域，将 Bean 缓存绑定到当前事务，内部存储在 TransactionSynchronizationManager.resources 中


session域主要逻辑为获取当前request的HttpSession，从内部中获取bean，没有则再实例化bean并缓存到当前Session里
public class SessionScope extends AbstractRequestAttributesScope {

    @Override
    public Object get(String name, ObjectFactory&lt;?> objectFactory) {
        Object mutex = RequestContextHolder.currentRequestAttributes().getSessionMutex();
        synchronized (mutex) { // 加锁，避免多线程同时创建bean
            return super.get(name, objectFactory);
        }
    }

    // 父类中的AbstractRequestAttributesScope方法
    public Object get(String name, ObjectFactory&lt;?> objectFactory) {
        RequestAttributes attributes = RequestContextHolder.currentRequestAttributes();
        // 对于session域，是通过HttpSession#getAttribute方法操作的
        Object scopedObject = attributes.getAttribute(name, getScope());
        if (scopedObject == null) {
            // 创建bean
            scopedObject = objectFactory.getObject();
            attributes.setAttribute(name, scopedObject, getScope());
            Object retrievedObject = attributes.getAttribute(name, getScope());
            if (retrievedObject != null) {
                scopedObject = retrievedObject;
            }
        }
        return scopedObject;
    }

}

@Scope注解用于定义 Spring 容器中 Bean 的作用域（Scope）。该注解通常配合 @Component 或 @Bean 使用，控制 Bean 在容器中的生命周期及缓存策略

value：指定当前 Bean 的作用域名称，可以使用我们自定义的scope。Spring解析时不会校验
scopeName：同value
proxyMode：指定当前 Bean 是否需要通过代理方式注入。枚举类型为 ScopedProxyMode，常用值包括：
DEFAULT（默认值）：等价于 NO
NO：不使用代理。意味着当前Bean不能被其他singleton bean给依赖注入
INTERFACES：JDK 动态代理，即接口代理
TARGET_CLASS：CGLIB 代理，即继承代理



Scope代理​	还有个重要的问题，Spring 中非 singleton 作用域的 Bean 无法直接注入到 singleton Bean 中，原因在于singleton Bean一旦被创建，其内部的依赖也随之固定。而诸如 request、session 等作用域下的 Bean 生命周期较短，其实例在运行时可能会动态变化。
​	所以为了解决这种作用域不一致带来的注入问题，Spring 提供了 作用域代理机制（Scoped Proxy）。核心思想为将实际的Scope Bean 包装成一个代理对象，注入到 singleton Bean 中；每次通过该代理访问时，都会根据当前上下文（如当前request或session）动态获取真实的目标 Bean。这样，从开发者视角来看，这个 Bean 就像是 singleton 一样稳定可用，但实际底层访问的却是随作用域动态变化的目标实例。
ScopedProxyUtils​	是 Spring 在注册特定作用域（如 request、session）BeanDefinition 之前，用于创建作用域代理的工具类。它的核心作用是：在注册 BeanDefinition 前，将其包装成作用域代理，从而允许非 singleton Bean 被注入到 singleton Bean 中。其最终会在容器中注册一下两个 Bean

代理 Bean（Scoped Proxy）

类型为 ScopedProxyFactoryBean，作用域为 singleton
Bean 名为原始 Bean 的名称（例如 userService）
负责在运行时根据当前作用域动态获取实际 Bean 实例
保留原始 Bean 的自动注入相关属性（如 @Primary、限定符），因此它才是被注入到其他 Bean 中的“主 Bean”

  目标 Bean（Target Bean）

Bean 名为 &quot;scopedTarget.&quot; + 原始名称（如 scopedTarget.userService）
保持原有的作用域定义（如 request、session 等）
被设置为不可自动注入（autowireCandidate = false）。都注入代理bean



核心源码public abstract class ScopedProxyUtils {

    // 代理目标 Bean 的命名前缀
    private static final String TARGET_NAME_PREFIX = "scopedTarget.";

    private static final int TARGET_NAME_PREFIX_LENGTH = TARGET_NAME_PREFIX.length();

    /**
     * 创建作用域代理：将一个具有非单例作用域的 Bean 包装为一个 ScopedProxyFactoryBean，
     * 用于在注入到 singleton Bean 时仍保持作用域语义。
     *
     * 实现原理：将原始 Bean 注册为一个带前缀的新 Bean，然后为原始 Bean 名称注册一个代理 Bean，
     * 每次访问这个代理 Bean 时，都会动态地从容器中获取当前作用域下的真实 Bean。
     */
    public static BeanDefinitionHolder createScopedProxy(BeanDefinitionHolder definition,
            BeanDefinitionRegistry registry, boolean proxyTargetClass) {

        String originalBeanName = definition.getBeanName();
        BeanDefinition targetDefinition = definition.getBeanDefinition();
        // 原bean修改后的目标beanName： scopedTarget. + 原beanName
        String targetBeanName = getTargetBeanName(originalBeanName);

        // 创建 ScopedProxyFactoryBean 的定义，用于代理原始 Bean
        RootBeanDefinition proxyDefinition = new RootBeanDefinition(ScopedProxyFactoryBean.class);
        proxyDefinition.setDecoratedDefinition(new BeanDefinitionHolder(targetDefinition, targetBeanName));
        proxyDefinition.setOriginatingBeanDefinition(targetDefinition);
        proxyDefinition.setSource(definition.getSource());
        proxyDefinition.setRole(targetDefinition.getRole());

        // 设置代理bean中targetBeanName（用来在BeanFactory中原始bean）
        proxyDefinition.getPropertyValues().add("targetBeanName", targetBeanName);
        if (proxyTargetClass) { // cglib proxy
            targetDefinition.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE);
        } else { // jdk proxy
            proxyDefinition.getPropertyValues().add("proxyTargetClass", Boolean.FALSE);
        }

        // 复制原始 Bean 的自动注入相关属性
        proxyDefinition.setAutowireCandidate(targetDefinition.isAutowireCandidate());
        proxyDefinition.setPrimary(targetDefinition.isPrimary());
        if (targetDefinition instanceof AbstractBeanDefinition) {
            proxyDefinition.copyQualifiersFrom((AbstractBeanDefinition) targetDefinition);
        }

        // 将原始 Bean 设为非primary且不可自动注入（避免与代理冲突，这样Spring注册的这个bean始终是代理bean）
        targetDefinition.setAutowireCandidate(false);
        targetDefinition.setPrimary(false);

        // 注册原bean到容器中，此时beanName已被替换
        registry.registerBeanDefinition(targetBeanName, targetDefinition);

        // 返回代理 Bean 的定义（仍然使用原始Bean的beanName）
        return new BeanDefinitionHolder(proxyDefinition, originalBeanName, definition.getAliases());
    }

}

ScopedProxyFactoryBean​	它构建了一个用于作用域代理的单例增强 Bean，这个bean具有如下特点

**TargetSource 为 SimpleBeanTargetSource**：每次方法调用时，动态从 BeanFactory 获取目标 bean 实例（不做任何缓存）
代理类实现了目标 bean 的所有接口和类：对外表现为原始 bean，可被其他 bean 正常依赖和注入（作为主 bean 使用）。
实现了 AopInfrastructureBean 接口：标记为基础设施类，避免再次被 AOP、事务、异步等机制增强。
**仅使用一个拦截器：DelegatingIntroductionInterceptor**：
对被“引入”的接口方法（如 ScopedObject#getTargetObject()）进行特殊处理；
对其他方法则调用 MethodInvocation#proceed()，由原始 bean 执行具体逻辑。



核心源码public class ScopedProxyFactoryBean extends ProxyConfig
        implements FactoryBean&lt;Object>, BeanFactoryAware, AopInfrastructureBean {
    public void setBeanFactory(BeanFactory beanFactory) {
        if (!(beanFactory instanceof ConfigurableBeanFactory)) {
            throw new IllegalStateException("Not running in a ConfigurableBeanFactory: " + beanFactory);
        }
        ConfigurableBeanFactory cbf = (ConfigurableBeanFactory) beanFactory;

        // 将 BeanFactory 注入目标作用域对象（这样才有能力从BeanFactory中获取目标作用域对象）
        this.scopedTargetSource.setBeanFactory(beanFactory);

        ProxyFactory pf = new ProxyFactory();
        pf.copyFrom(this);
        // 设置代理目标为 scopedTargetSource（默认为SimpleBeanTargetSource，其获取目标对象每次都调用BeanFactory#getBean）
        // 且scopedTargetSource的getTargetClass()方法会解析并返回原始bean的class，用于代理增强
        pf.setTargetSource(this.scopedTargetSource);

        Assert.notNull(this.targetBeanName, "Property 'targetBeanName' is required");
        Class&lt;?> beanType = beanFactory.getType(this.targetBeanName);
        if (beanType == null) {
            throw new IllegalStateException("Cannot create scoped proxy for bean '" + this.targetBeanName +
                    "': Target type could not be determined at the time of proxy creation.");
        }
        // jdk代理判断
        if (!isProxyTargetClass() || beanType.isInterface() || Modifier.isPrivate(beanType.getModifiers())) {
            pf.setInterfaces(ClassUtils.getAllInterfacesForClass(beanType, cbf.getBeanClassLoader()));
        }

        // Add an introduction that implements only the methods on ScopedObject.
        ScopedObject scopedObject = new DefaultScopedObject(cbf, this.scopedTargetSource.getTargetBeanName());
        pf.addAdvice(new DelegatingIntroductionInterceptor(scopedObject));

        // 设置该bean不会被其他自动代理 代理了
        /*
         * 为什么会这么设置？
         * 这个bean以及是个代理增强bean了，它所需要增强的地方也是唯一的地方就是找到目标scope里真实的bean，并将方法的调用行为转移到目标作用域的真实的bean中去
         *
         * 例：session域的bean，该bean被自动注入的就应该是这个代理bean，这个bean存在的目的也只是找到session域
         * 里对应的真实bean，然后调用该bean的方法全走session域的真实bean的方法，且由这个真实bean来进行其他自动代理的增强
         */
        pf.addInterface(AopInfrastructureBean.class);

        // 创建好代理对象
        this.proxy = pf.getProxy(cbf.getBeanClassLoader());
    }

    /**
     * 单例
     */
    public boolean isSingleton() {
        return true;
    }
}

arthas验证测试类package site.shanzhao.config;

@Component
@SessionScope
public class SessionScopeDemo {
    
}

class信息查询用sc -d site.shanzhao.config.SessionScopeDemo命令，我这里只展示了增强的class，重点观察到

父类为site.shanzhao.config.SessionScopeDemo
相比普通AOP，多增加的接口有：
org.springframework.aop.scope.ScopedObject
org.springframework.aop.framework.AopInfrastructureBean



 class-info        site.shanzhao.config.SessionScopeDemo$$EnhancerBySpringCGLIB$$9851f0cb
 code-source       /Users/reef/IdeaProjects/soil/target/classes/
 name              site.shanzhao.config.SessionScopeDemo$$EnhancerBySpringCGLIB$$9851f0cb
 isInterface       false
 isAnnotation      false
 isEnum            false
 isAnonymousClass  false
 isArray           false
 isLocalClass      false
 isMemberClass     false
 isPrimitive       false
 isSynthetic       false
 simple-name       SessionScopeDemo$$EnhancerBySpringCGLIB$$9851f0cb
 modifier          public
 annotation
 interfaces        org.springframework.aop.scope.ScopedObject,java.io.Serializable,org.springframework.aop.framework.AopInfrastructureBean,org.springframework.aop.SpringProxy,org.springframework.aop.framework.
                   Advised,org.springframework.cglib.proxy.Factory
 super-class       +-site.shanzhao.config.SessionScopeDemo
                     +-java.lang.Object
 class-loader      +-jdk.internal.loader.ClassLoaders$AppClassLoader@311d617d
                     +-jdk.internal.loader.ClassLoaders$PlatformClassLoader@1b4ae4e0
 classLoaderHash   311d617d

ognl查询beanName# 使用ApplicationContext.getBeanNamesForType()方法，可知有两个SessionScopeDemo class的BeanDefinition
[arthas@35578]$ ognl "@site.shanzhao.util.ApplicationContextUtils@applicationContext.getBeanNamesForType(@site.shanzhao.config.SessionScopeDemo@class)"
@String[][
    @String[scopedTarget.sessionScopeDemo],
    @String[sessionScopeDemo],
]

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title>Spring-Bean初始化</title>
    <url>/2021-01-08/spring-bean-de-chu-shi-hua/</url>
    <content><![CDATA[
​	整体分析了BeanFactory和ApplicationContext的区别。并从Spring Bean创建流程源码分析了bean的创建流程并对其进行总结，并分析了三级缓存的作用




BeanFactory​	BeanFactory 是 Spring 最基础的 IoC 容器接口，仅提供了 Bean 的获取与管理能力。而 DefaultListableBeanFactory 是其默认实现类，它通过实现多个关键接口，构建出完整的 IoC 容器功能体系。
以下是 DefaultListableBeanFactory 实现的主要接口以及其对应的职责：



主要接口
主要功能



AliasRegistry
提供 Bean 的别名注册和解析能力。允许一个 Bean 在容器中有多个名字，是 Spring IoC 容器灵活命名机制的基础。


BeanDefinitionRegistry
管理 Bean 的定义信息（BeanDefinition），提供注册、删除、查询等能力。是容器启动期间加载和维护元数据的关键接口。


SingletonBeanRegistry
管理单例 Bean 的注册与缓存机制，控制 Bean 的生命周期。所有单例 Bean 都存储在 singletonObjects 缓存中。


AutowireCapableBeanFactory
提供创建 Bean 实例、属性注入、初始化回调、AOP 代理等高级功能。通常用于手动创建并管理 Bean 的生命周期，比如调用 createBean()、autowireBean() 等。


ConfigurableListableBeanFactory
是 BeanFactory 的高级配置接口，支持访问所有已注册的 BeanDefinition，还可以注册 BeanPostProcessor组件。常用于容器初始化后对 BeanFactory 进行增强或定制。


HierarchicalBeanFactory
支持父子容器结构，允许子容器从父容器中查找 Bean，提升模块化和隔离能力。 是实现 ApplicationContext 之间嵌套结构的基础。


FactoryBeanRegistrySupport  （继承自 AbstractAutowireCapableBeanFactory）
支持 FactoryBean 机制的关键实现类，负责识别并缓存 FactoryBean 创建的产品对象。 比如，当你定义了一个实现 FactoryBean&lt;T&gt; 的类时，容器最终会获取到 T 类型的对象，而不是工厂本身。


ApplicationContextApplicationContext不仅实现了BeanFactory接口，还多了许多拓展接口，其余接口如下



其他接口
主要功能



EnvironmentCapable
获取Environment，可读取各种配置


MessageSource
国际化消息解析


ApplicationEventPublisher
支持事件发布&#x2F;监听机制


ResourcePatternResolver
支持资源加载，比如 classpath 等路径资源


​	在注解驱动的环境下，常用的 ApplicationContext 实现类为 AnnotationConfigApplicationContext。该类内部封装了一个 DefaultListableBeanFactory 实例，作为底层的 Bean 注册与管理中心，从而继承了 BeanFactory 的全部能力。
​	而其refresh方法更是容器启动流程的核心。Bean的解析、注册，各种后置处理器的准备、使用，国际化和事件发布、各种监听器均在这个方法中完成，可以说是整个Spring的核心
bean创建流程源码（只保留了重要的部分）AbstractBeanFactory#doGetBeanorg.springframework.beans.factory.support.AbstractBeanFactory#doGetBean方法部分关键代码
// 获取真实的beanName，参数name可能是bean的别名和FactoryBean格式（前面有&amp;）
String beanName = transformedBeanName(name);
Object bean;

// Eagerly check singleton cache for manually registered singletons.
// 为了解决循环引用，在这里就必须可以从二级或三级缓存中拿bean（尽管此时这个bean实例化了，还未填充数据和初始化）
Object sharedInstance = getSingleton(beanName);
if (sharedInstance != null &amp;&amp; args == null) {
  bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);
}

else {
  // 循环创建多例bean抛出异常
  if (isPrototypeCurrentlyInCreation(beanName)) {
    throw new BeanCurrentlyInCreationException(beanName);
  }

  // 先获取父容器
  BeanFactory parentBeanFactory = getParentBeanFactory();
  // 父BeanFactory存在且当前的BeanFactory不存在BeanDefinition，就会去父BeanFactory递归查找
  if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) {
    // 在父容器中获取bean，能获取到就直接返回了
    ...
  }

  if (!typeCheckOnly) {
    // 标记bean为已创建
    markBeanAsCreated(beanName);
  }

  try {
    RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);
    checkMergedBeanDefinition(mbd, beanName, args);

    String[] dependsOn = mbd.getDependsOn();
    if (dependsOn != null) {
      // 有dependsOn的bean，则优先创建这些bean
      ...
    }

    // Create bean instance.
    if (mbd.isSingleton()) { // 单例bean的创建
      sharedInstance = getSingleton(beanName, () -> {
        try {
          return createBean(beanName, mbd, args);
        }
        catch (BeansException ex) {
                    // bean创建失败，执行destory相关方法并直接抛出异常
          destroySingleton(beanName);
          throw ex;
        }
      });
      bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);
    }
    else if (mbd.isPrototype()) { // 创建多例bean
      Object prototypeInstance = null;
      try {
        beforePrototypeCreation(beanName);
        prototypeInstance = createBean(beanName, mbd, args);
      }
      finally {
        afterPrototypeCreation(beanName);
      }
      bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);
    }

    else { // 特殊的scope里bean的创建。创建在session，request等scope里面的bean
      String scopeName = mbd.getScope();
      Scope scope = this.scopes.get(scopeName);
      }
      // 获取并放入对应的Scope中，在返回bean
      Object scopedInstance = scope.get(beanName, () -> {
        beforePrototypeCreation(beanName);
        try {
          return createBean(beanName, mbd, args);
        }
        finally {
          afterPrototypeCreation(beanName);
        }
      });
      bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);
    }
  }
  catch (BeansException ex) {
    cleanupAfterBeanCreationFailure(beanName);
    throw ex;
  }
}

// Check if required type matches the type of the actual bean instance.
if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) {
    T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType);
    if (convertedBean == null) {
      throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());
    }
    return convertedBean;
}
return (T) bean;

DefaultSingletonBeanRegistry#getSingleton从三级缓存中获取bean
protected Object getSingleton(String beanName, boolean allowEarlyReference) {
        // 先从一级缓存中直接获取
        Object singletonObject = this.singletonObjects.get(beanName);
        // 单例bean还没创建好但是正在创建的情况（说明已经有循环引用了）
        if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {
            // 二级缓存中获取
            singletonObject = this.earlySingletonObjects.get(beanName);
            if (singletonObject == null &amp;&amp; allowEarlyReference) {
                synchronized (this.singletonObjects) {
                    singletonObject = this.singletonObjects.get(beanName);
                    if (singletonObject == null) { // 一级缓存为空，从二级中取
                        singletonObject = this.earlySingletonObjects.get(beanName);
                        if (singletonObject == null) { // 二级缓存为空，再从三级缓存中获取
                            ObjectFactory&lt;?> singletonFactory = this.singletonFactories.get(beanName);
                            if (singletonFactory != null) {
                                // 三级缓存不为空，取出该bean，放入二级缓存，同时从三级缓存中删除
                                singletonObject = singletonFactory.getObject();
                                this.earlySingletonObjects.put(beanName, singletonObject);
                                this.singletonFactories.remove(beanName);
                            }
                        }
                    }
                }
            }
        }
        return singletonObject;
    }

AbstractAutowireCapableBeanFactory#doCreateBean// 实例化bean。先创建出一个空壳的bean，各种field和方法都没有填充和调用
BeanWrapper instanceWrapper = null;
if (mbd.isSingleton()) {
  instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);
}
if (instanceWrapper == null) {
  instanceWrapper = createBeanInstance(beanName, mbd, args);
}
// 已实例化的bean
Object bean = instanceWrapper.getWrappedInstance();
// bean 的class type
Class&lt;?> beanType = instanceWrapper.getWrappedClass();
if (beanType != NullBean.class) {
  mbd.resolvedTargetType = beanType;
}

// 单例+允许循环引用+当前bean正在创建。就需要将bean包装后放入三级缓存中
boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;
    isSingletonCurrentlyInCreation(beanName));
if (earlySingletonExposure) {
  // 将已实例化但还未填充属性的bean放入三级缓存，供其他依赖此bean的bean使用
  addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));
}

//  准备初始化bean
Object exposedObject = bean;
try {
  // 填充bean的字段（依赖的字段bean）
  populateBean(beanName, mbd, instanceWrapper);
  // bean完全填充好属性后，开始调用各种初始化方法和BeanPostProcessor接口
  exposedObject = initializeBean(beanName, exposedObject, mbd);
}
    ... // 省略异常
}
... 
// 注册destroy相关方法
registerDisposableBeanIfNecessary(beanName, bean, mbd);
return exposedObject;

AbstractAutowireCapableBeanFactory#populateBean填充bean的字段

PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);

// 根据autowireMode来判断注入方式
// 1. xml显示配置的autowire
// 2. 配置了@Bean注解的autowire字段（这个字段默认不会走下面的代码注入）
int resolvedAutowireMode = mbd.getResolvedAutowireMode();
if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
  MutablePropertyValues newPvs = new MutablePropertyValues(pvs);
  // Add property values based on autowire by name if applicable.
  if (resolvedAutowireMode == AUTOWIRE_BY_NAME) {
    autowireByName(beanName, mbd, bw, newPvs);
  }
  // Add property values based on autowire by type if applicable.
  if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
    autowireByType(beanName, mbd, bw, newPvs);
  }
  pvs = newPvs;
}
// ==================== 以下就是@Autowired和@Resource注入方式的处理
// 是否存在InstantiationAwareBeanPostProcessor处理器（主要是注解解析PostProcessor）
boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();
boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE);

PropertyDescriptor[] filteredPds = null;
if (hasInstAwareBpps) {
  if (pvs == null) {
    pvs = mbd.getPropertyValues();
  }
  // 获取InstantiationAwareBeanPostProcessor处理器，并调用其postProcessProperties方法
  // 基于注解的依赖注入会用到
  for (BeanPostProcessor bp : getBeanPostProcessors()) {
    if (bp instanceof InstantiationAwareBeanPostProcessor) {
      InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
      // 注解相关的自动注入
      PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);
      pvs = pvsToUse;
    }
  }
}
}

AbstractAutowireCapableBeanFactory#initializeBean初始化bean

// 三种aware(BeanName，BeanClassLoader，BeanFactory)
invokeAwareMethods(beanName, bean);

// 名叫wrappedBean，表示这些方法返回的bean可能是被包装后的，比如aop相关
Object wrappedBean = bean;
if (mbd == null || !mbd.isSynthetic()) {
  // BeanPostProcessor接口实例回调（在bean的初始化方法调用之前调用）
  // 例如：@PostConstruct注解的实现
  wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
}

// InitializingBean方法和init-method方法
invokeInitMethods(beanName, wrappedBean, mbd);

if (mbd == null || !mbd.isSynthetic()) {
  // BeanPostProcessor#postProcessAfterInitialization接口实例回调。
  // 在bean的初始化方法调用完成之后调用，说明bean以及初始化完毕，可以实现其他扩展功能了
  //比如AOP的实现、 @Scheduled注解实现等
  wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
}

return wrappedBean;

三级缓存
一级缓存（DefaultSingletonBeanRegistry#singletonObjects）：存放的是完全初始化好的bean，包括已实例化、填充内部依赖的bean，运行完初始化方法（@PostConstruct、afterPropertiesSet方法、指定的init-method方法）
二级缓存（DefaultSingletonBeanRegistry#earlySingletonObjects）：存放bean缓存（如果能被AOP，就是AOP对象），但还未填充属性和允许初始化方法
三级缓存（DefaultSingletonBeanRegistry#singletonFactories）：存放bean的ObjectFactory工厂对象，使用这个工厂对象，可提前暴露出bean的引用（专用来提前暴露AOP对象的方法）

为什么要使用三级缓存​	三级缓存专门来解决AOP对象的暴露问题。
​	如果没用AOP是可以只用一级缓存和二级缓存就解决的。但如果使用了AOP且没有三级缓存，那么必须在实例化后就马上完成AOP代理，但这和spring的设计初衷不同，AOP代理的完成时使用了bean的后置处理器AnnotationAwareAspectJAutoProxyCreator来完成的，也就是在初始化bean后执行的bean后置处理器方法（AbstractAutowireCapableBeanFactory#initializeBean），就不可能再实例化bean后进行代理，所以才有了三级缓存，仅用来提前暴露AOP对象
三层级缓存真能完美解决吗？如果有3个bean分别为A、B、C，A依赖B和C，B只依赖A，C什么都不依赖，但提供一个方法sayHello使用。
​	当开始实例化A时，实例化A后将其工厂对象放入三级缓存中，开始填充A属性，发现了B需要填充，开始实例化B，实例化B对象过程中又需要填充其属性A，这时能从三级缓存中取出了A的引用（但此时A不完整），如果B对象有一个初始化方法（@PostConstruct），调用A对象里的C对象的sayHello方法，但由于A此时只是个空壳，就会抛出空指针异常。
​	总的来说，就是在循环引用期间的调用初始化方法时，调用了尚未完全创建好的bean（空壳bean）的某个字段的方法，导致抛出NPE，导致服务启动失败
关键流程总结
实例化bean：创建bean的空壳对象
将其工厂对象（ObjectFactory）放入三级缓存（根据AbstractAutowireCapableBeanFactory#allowCircularReferences字段决定）
填充依赖bean（AbstractAutowireCapableBeanFactory#populateBean）：进行@Autowired和@Resource等注解的字段注入。如果这些依赖的 Bean 还没创建，会触发递归创建
初始化bean（AbstractAutowireCapableBeanFactory#initializeBean）
4.1 调用BeanPostProcessor#postProcessBeforeInitialization方法（初始化前的hook）
4.2 调用各种初始化方法（**@PostConstruct、afterPropertiesSet方法、指定的init-method方法**）
4.3 调用BeanPostProcessor#postProcessAfterInitialization（初始化后的hook，AOP相关实现）


注册destory相关方法（AbstractBeanFactory#registerDisposableBeanIfNecessary）
完成创建，放入一级缓存。同时移除三级缓存和二级缓存中的相关对象

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>spring三级缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-AOP</title>
    <url>/2021-02-08/spring-aop/</url>
    <content><![CDATA[​	从源码分析了Spring AOP的实现逻辑，以及利用arthas对代理class进行反编译以更加清晰的理解源码流程




@EnableAspectJAutoProxy​	其主要功能是向容器中注册AnnotationAwareAspectJAutoProxyCreator这个BeanDefinition，以此实现基于以下注解的代理功能



注解名
说明



@Aspect
声明一个类是切面类


@Before
前置通知，目标方法执行前执行


@After
后置通知，目标方法执行后执行（无论是否异常）


@AfterReturning
返回通知，目标方法正常返回后执行


@AfterThrowing
异常通知，目标方法抛出异常时执行


@Around
环绕通知，完全控制目标方法执行的时机，可决定是否继续执行目标方法


@Pointcut
定义可复用的切点表达式，供上述注解引用


AnnotationAwareAspectJAutoProxyCreator​	Spring实现自动装配动态代理的Bean后置处理器，具有最高的执行优先级（表示是最先被执行的BeanPostProcessor。设置最高优先级的代码在org.springframework.aop.config.AopConfigUtils#registerOrEscalateApcAsRequired中）
wrapIfNecessary​	bean进行包装（增强）的入口，它会在如下两个地方被调用

postProcessAfterInitialization：常规的的bean初始化完成后hook，需要对bean进行代理并返回给容器
getEarlyBeanReference：针对循环依赖需要提前获取bean的引用。Spring 会在三级缓存中暴露“早期对象引用”。如果此 bean 需要 AOP，必须在这个阶段就包上代理，否则依赖方会拿到原始对象，导致切面失效。

protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {
    // 已经处理过
    if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) {
        return bean;
    }
    // 无需增强的bean缓存判断
    if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {
        return bean;
    }
    // 是一个基础设施类或者指定的不需要代理
    if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {
        this.advisedBeans.put(cacheKey, Boolean.FALSE);
        return bean;
    }

    // 查找这个bean能使用的所有Advisor
    Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);
    if (specificInterceptors != DO_NOT_PROXY) { // 存在增强器
        this.advisedBeans.put(cacheKey, Boolean.TRUE);
        // 创建其代理
        Object proxy = createProxy(
                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));
        this.proxyTypes.put(cacheKey, proxy.getClass());
        return proxy;
    }
    // 当前bean不需要增强，缓存起来
    this.advisedBeans.put(cacheKey, Boolean.FALSE);
    return bean;
}

获取Advisor阶段首先Advisor是什么？

​	我理解为增强器，一个Advisor对应一个切面。既包含Advice，也包含过滤器（判断bean是否需要增强的东西）。所以能用一个Advisor来判断任意一个bean是否能被它增强，并提供增强的Advice。
​	主要子接口为PointcutAdvisor，PointcutAdvisor提供了Pointcut，利用这个Pointcut即可以bean的class和method进行匹配看它是否能被增强。而Advisor获取的Advice则为真正执行代理方法的拦截器。

findCandidateAdvisors有两种如下获取Advisor的方式

查找所有实现了Advisor接口的BeanDefinition，并对其进行实例化（这种一般都是框架注册的增强器）

注解方式：获取所有基于注解的切面bean，并进行实例化

先拿到容器中所有Bean的beanName，再遍历这些beanName。通过BeanFactory获取当前beanName的Class，再判断Class上是否有@Aspect注解。如果存在@Aspect，就利用ReflectiveAspectJAdvisorFactory去解析这些Bean，将@Aspect Bean中的每个增强方法（如下注解，每个注解标注的方法就是一个增强方法）构造成一个Advisor（实现类为InstantiationModelAwarePointcutAdvisorImpl），最后封装到List里，返回给上层




@Override
protected List&lt;Advisor> findCandidateAdvisors() {
    // 查找spring内置的增强器（包括不限于事务、缓存等）
    List&lt;Advisor> advisors = super.findCandidateAdvisors();
    // aspectJAdvisorsBuilder不会为空，默认为BeanFactoryAspectJAdvisorsBuilderAdapter
    if (this.aspectJAdvisorsBuilder != null) {
        // 获取所有的与@Aspect注解相关的Advisor
        advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());
    }
    return advisors;
}

// 父类中的findAdvisorBeans
public List&lt;Advisor> findAdvisorBeans() {
    // 先从缓存中找，没有再搜索
    String[] advisorNames = this.cachedAdvisorBeanNames;
    if (advisorNames == null) { // 缓存为空
        // 查找出所有实现了Advisor接口的BeanDefinition，并缓存
        advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(
                this.beanFactory, Advisor.class, true, false);
        this.cachedAdvisorBeanNames = advisorNames;
    }
    if (advisorNames.length == 0) {
        return new ArrayList&lt;>();
    }

    List&lt;Advisor> advisors = new ArrayList&lt;>();
    for (String name : advisorNames) {
        if (isEligibleBean(name)) {
            if (this.beanFactory.isCurrentlyInCreation(name)) {
                if (logger.isTraceEnabled()) {
                    logger.trace("Skipping currently created advisor '" + name + "'");
                }
            } else {
                try {
                    // 尝试实例化这个Advisor Bean，并放入结果中
                    advisors.add(this.beanFactory.getBean(name, Advisor.class));
                } catch (BeanCreationException ex) {
                    Throwable rootCause = ex.getMostSpecificCause();
                    if (rootCause instanceof BeanCurrentlyInCreationException) {
                        BeanCreationException bce = (BeanCreationException) rootCause;
                        String bceBeanName = bce.getBeanName();
                        if (bceBeanName != null &amp;&amp; this.beanFactory.isCurrentlyInCreation(bceBeanName)) {
                            if (logger.isTraceEnabled()) {
                                logger.trace("Skipping advisor '" + name +
                                        "' with dependency on currently created bean: " + ex.getMessage());
                            }
                            // Ignore: indicates a reference back to the bean we're trying to advise.
                            // We want to find advisors other than the currently created bean itself.
                            continue;
                        }
                    }
                    throw ex;
                }
            }
        }
    }
    return advisors;
}

// BeanFactoryAspectJAdvisorsBuilder#buildAspectJAdvisors方法，找出基于注解的切面
public List&lt;Advisor> buildAspectJAdvisors() {
    // @Aspect注解BeanName的缓存
    List&lt;String> aspectNames = this.aspectBeanNames;

    if (aspectNames == null) {
        synchronized (this) {
            aspectNames = this.aspectBeanNames;
            if (aspectNames == null) {
                List&lt;Advisor> advisors = new ArrayList&lt;>();
                aspectNames = new ArrayList&lt;>();
                // 获取所有beanName
                String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(
                        this.beanFactory, Object.class, true, false);
                for (String beanName : beanNames) {
                    if (!isEligibleBean(beanName)) {
                        continue;
                    }
                    // 获取这个bean的type
                    Class&lt;?> beanType = this.beanFactory.getType(beanName);
                    if (beanType == null) {
                        continue;
                    }
                    // 存在 org.aspectj.lang.annotation.Aspect 注解
                    if (this.advisorFactory.isAspect(beanType)) {
                        aspectNames.add(beanName);
                        AspectMetadata amd = new AspectMetadata(beanType, beanName);
                        // 解析@Aspetc的value值，如果没有，默认kind就为SINGLETON
                        if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) {
                            MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(
                                    this.beanFactory, beanName);
                            // 解析标记 AspectJ 注解中的增强方法，并将每个切点方法都构造成一个Advisor
                            // 其实现类为InstantiationModelAwarePointcutAdvisorImpl
                            List&lt;Advisor> classAdvisors = this.advisorFactory.getAdvisors(factory);
                            // 缓存起来切面的解析结果
                            if (this.beanFactory.isSingleton(beanName)) {
                                this.advisorsCache.put(beanName, classAdvisors);
                            } else {
                                this.aspectFactoryCache.put(beanName, factory);
                            }
                            advisors.addAll(classAdvisors);
                        } else {
                            // Per target or per this.
                            if (this.beanFactory.isSingleton(beanName)) {
                                throw new IllegalArgumentException("Bean with name '" + beanName +
                                        "' is a singleton, but aspect instantiation model is not singleton");
                            }
                            MetadataAwareAspectInstanceFactory factory = new PrototypeAspectInstanceFactory(
                                    this.beanFactory, beanName);
                            this.aspectFactoryCache.put(beanName, factory);
                            advisors.addAll(this.advisorFactory.getAdvisors(factory));
                        }
                    }
                }
                this.aspectBeanNames = aspectNames;
                return advisors;
            }
        }
    }

    if (aspectNames.isEmpty()) { // 没有自定义的@Aspect，返回空
        return Collections.emptyList();
    }
    List&lt;Advisor> advisors = new ArrayList&lt;>();
    for (String aspectName : aspectNames) {
        List&lt;Advisor> cachedAdvisors = this.advisorsCache.get(aspectName);
        if (cachedAdvisors != null) {
            advisors.addAll(cachedAdvisors);
        } else {
            MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName);
            advisors.addAll(this.advisorFactory.getAdvisors(factory));
        }
    }
    return advisors;
}

findAdvisorsThatCanApply​	将上面流程中获取到的所有Advisor做过滤，过滤出可以对当前bean进行增强的Advisor。核心方法在org.springframework.aop.support.AopUtils#canApply中
public static boolean canApply(Pointcut pc, Class&lt;?> targetClass, boolean hasIntroductions) {
    Assert.notNull(pc, "Pointcut must not be null");
    if (!pc.getClassFilter().matches(targetClass)) { // 先按类匹配，如果类都匹配不了，那直接就不需要代理了
        return false;
    }

    MethodMatcher methodMatcher = pc.getMethodMatcher(); // 获取方法匹配器
    if (methodMatcher == MethodMatcher.TRUE) {
        // No need to iterate the methods if we're matching any method anyway...
        return true;
    }

    IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null;
    if (methodMatcher instanceof IntroductionAwareMethodMatcher) {
        introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher;
    }
    // 目标类和其所有接口的集和
    Set&lt;Class&lt;?>> classes = new LinkedHashSet&lt;>();
    if (!Proxy.isProxyClass(targetClass)) {
        classes.add(ClassUtils.getUserClass(targetClass));
    }
    classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass));

    for (Class&lt;?> clazz : classes) {
        Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz);
        for (Method method : methods) {
            // 对目标类和其所有接口的每个方法都进行匹配，只要能匹配上，就代表这个类可以增强，直接返回true
            if (introductionAwareMethodMatcher != null
                    ? introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions)
                    : methodMatcher.matches(method, targetClass)) {
                return true;
            }
        }
    }

    return false;
}

sortAdvisors​	源码就不分析了，直接说作用：它是 Spring AOP 中对多个 Advisor（增强器）进行排序的关键逻辑。它根据切面、通知类上的 @Order 注解或实现 Ordered 接口的优先级，对同一目标类或方法的所有 Advisor 进行排序。
​	排序完成后，每个类或方法的增强器顺序就被固定下来。在运行时调用该方法时，AOP 拦截器链会严格按照这个顺序执行对应的切面逻辑，确保增强行为的预期一致性。
开始增强（创建代理）cglib getProxycglib的增强实现主要步骤总结


校验final方法（只是打个日志，final方法不能增强）

创建org.springframework.cglib.proxy.Enhancer（核心的cglib增强器）

对Enhancer进行一系列的填充，包括设置当前Class为增强类的父类。当前Class的所有接口，增强类也要实现。

设置增强Class的命名策略（BySpringCGLIB）

默认再将当前线程上下文的ClassLoader设为加载增强Class字节码的ClassLoader

对Enhancer设置一些Callback，并设置固定的CallbackFilter（ProxyCallbackFilter）。非常重要：
 
 ​									Callback数组（每一个Callback都是方法的拦截器）
 
 ​	Callback数组的索引（ProxyCallbackFilter#accept实现），用来确定被增强的类的每一个方法该使用具体的某个拦截器，返回的是拦截器的数组索引

生成增强Class的字节码并实例化（代理bean就产生了），将其返回



// CglibAopProxy的创建代理方法
public Object getProxy(@Nullable ClassLoader classLoader) {
    if (logger.isTraceEnabled()) {
        logger.trace("Creating CGLIB proxy: " + this.advised.getTargetSource());
    }

    try {
        // 上一个被代理的目标类class（有可能已经是cglib的代理类了）
        Class&lt;?> rootClass = this.advised.getTargetClass();
        Assert.state(rootClass != null, "Target class must be available for creating a CGLIB proxy");
        // 真正代理的目标类class
        Class&lt;?> proxySuperClass = rootClass;
        if (ClassUtils.isCglibProxyClass(rootClass)) { // 已经是个cglib代理类了，就需要把真正被代理类的class和接口找出来
            proxySuperClass = rootClass.getSuperclass();
            Class&lt;?>[] additionalInterfaces = rootClass.getInterfaces();
            for (Class&lt;?> additionalInterface : additionalInterfaces) {
                this.advised.addInterface(additionalInterface);
            }
        }

        // 验证class的final相关方法并写日志
        validateClassIfNecessary(proxySuperClass, classLoader);

        // 创建通用的增强器，准备增强了
        Enhancer enhancer = createEnhancer();
        if (classLoader != null) {
            enhancer.setClassLoader(classLoader);
            if (classLoader instanceof SmartClassLoader &amp;&amp;
                    ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) {
                enhancer.setUseCache(false);
            }
        }
        // 设置被代理类class为增强类的父类
        enhancer.setSuperclass(proxySuperClass);
        // 对增强类设置接口：Advised和SpringProxy
        enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised));
        enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);
        enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));

        // 设置拦截器（真正支持切面操作的拦截器）
        Callback[] callbacks = getCallbacks(rootClass);
        Class&lt;?>[] types = new Class&lt;?>[callbacks.length];
        for (int x = 0; x &lt; types.length; x++) {
            types[x] = callbacks[x].getClass();
        }

        // 非常重要，就是通过这个filter来确定某个方法应该使用哪一个Callback的
        // 所以，代理类的任何一个方法只会用上一个Callback
        enhancer.setCallbackFilter(new ProxyCallbackFilter(
                this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset));
        enhancer.setCallbackTypes(types);

        // 生成代理类的class并实例化其对象
        return createProxyClassAndInstance(enhancer, callbacks);
    } catch (CodeGenerationException | IllegalArgumentException ex) {
        throw new AopConfigException("Could not generate CGLIB subclass of " + this.advised.getTargetClass() +
                ": Common causes of this problem include using a final class or a non-visible class",
                ex);
    } catch (Throwable ex) {
        // TargetSource.getTarget() failed
        throw new AopConfigException("Unexpected AOP exception", ex);
    }
}

jdk getProxy// JdkDynamicAopProxy的创建代理方法，该代理的InvocationHandler就为JdkDynamicAopProxy本身
public Object getProxy(@Nullable ClassLoader classLoader) {
   if (logger.isTraceEnabled()) {
      logger.trace("Creating JDK dynamic proxy: " + this.advised.getTargetSource());
   }
   // 对增强类设置Interface：Advised和SpringProxy和DecoratingProxy
   Class&lt;?>[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true);
   findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);
   return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);
}

调用阶段cglib invokecglib代理类中方法有切面时的调用重点流程分析（这时使用的Callback就是DynamicAdvisedInterceptor）

获取方法对应的拦截器链

 Spring 会调用 AdvisorChainFactory#getInterceptorsAndDynamicInterceptionAdvice 方法，为当前方法构建拦截器链。 它会遍历所有注册的 Advisor，并依次通过其中的 ClassFilter 和 MethodMatcher 判断当前方法是否匹配。如果匹配，就将该 Advisor 对应的拦截器（MethodInterceptor）加入到列表中，并最终缓存该方法与其拦截器链的映射关系。


触发代理方法调用

如果目标类采用了 CGLIB 代理（proxyTargetClass = true），则在调用代理对象方法时，会进入 CglibAopProxy.DynamicAdvisedInterceptor#intercept 方法。


构造并执行拦截链

Spring 会构造一个 CglibMethodInvocation 对象，它是 ReflectiveMethodInvocation 的子类，封装了目标对象、方法、参数、拦截器链等执行上下文。 调用 proceed() 方法开始执行拦截链。


依次执行拦截器

proceed() 方法会通过内部字段 currentInterceptorIndex（初始值为 -1）递增索引，按顺序执行拦截器链中的下一个 MethodInterceptor。 每个拦截器如果调用了 invocation.proceed()，则控制权会继续传递给下一个拦截器，实现“链式调用”。


执行原始方法

当所有拦截器都执行完后（即 currentInterceptorIndex &gt;= interceptors.size()），会最终调用原始目标对象的实际方法，实现增强与目标方法的结合。



// DynamicAdvisedInterceptor#intercept的入口
@Override
@Nullable
public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
    Object oldProxy = null;
    boolean setProxyContext = false;
    Object target = null;
    // 先准备目标对象源（调用原bean方法时会用到）
    TargetSource targetSource = this.advised.getTargetSource();
    try {
        if (this.advised.exposeProxy) {
            // 在当前线程上下文中设置了需要暴露代理，就要设置到当前线程ThreadLocal中
            // 就是用来解决方法内部需要调用代理方法
            oldProxy = AopContext.setCurrentProxy(proxy);
            setProxyContext = true;
        }
        // 获取真实的，不是代理的目标对象
        // 例：Session域从SimpleBeanTargetSource中获取，再转到BeanFactory，再转到SessionScope中，获取目标对象
        target = targetSource.getTarget();
        Class&lt;?> targetClass = (target != null ? target.getClass() : null);
        // 对当前方法构造切面链并缓存
        List&lt;Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);
        Object retVal;
        // 无切面，且方法为public，直接调用原方法
        if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) {

            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
            retVal = methodProxy.invoke(target, argsToUse);
        } else { // 存在切面，构造方法调用器并执行
            retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();
        }
        retVal = processReturnType(proxy, target, method, retVal);
        return retVal;
    } finally {
        if (target != null &amp;&amp; !targetSource.isStatic()) {
            targetSource.releaseTarget(target);
        }
        if (setProxyContext) { // 方法代理全部执行完毕，恢复执行前的现场
            AopContext.setCurrentProxy(oldProxy);
        }
    }
}

jdk invokepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    Object oldProxy = null;
    boolean setProxyContext = false;

    TargetSource targetSource = this.advised.targetSource;
    Object target = null;

    try {
        // 一些通用方法的处理
        if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) {
            return equals(args[0]);
        } else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) {
            return hashCode();
        } else if (method.getDeclaringClass() == DecoratingProxy.class) {
            return AopProxyUtils.ultimateTargetClass(this.advised);
        }
        // opaque为false，且该方法的类为实现了Advised的接口，则使用advised字段调用该方法
        else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp;
                method.getDeclaringClass().isAssignableFrom(Advised.class)) {
            // Service invocations on ProxyConfig with the proxy config...
            return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);
        }

        Object retVal;

        if (this.advised.exposeProxy) { // 需要暴露当前proxy，以便在本类中调用代理方法
            oldProxy = AopContext.setCurrentProxy(proxy);
            setProxyContext = true;
        }

        target = targetSource.getTarget();
        Class&lt;?> targetClass = (target != null ? target.getClass() : null);

        // 获取这个方法的所有拦截链
        List&lt;Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);

        if (chain.isEmpty()) { // 拦截链为空，则直接调用原方法
            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
            retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);
        } else {
            // 构造ReflectiveMethodInvocation，准备走代理方法了
            MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass,
                    chain);
            retVal = invocation.proceed();
        }

        // 处理返回值类型
        Class&lt;?> returnType = method.getReturnType();
        if (retVal != null &amp;&amp; retVal == target &amp;&amp;
                returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp;
                !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {
            retVal = proxy;
        } else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) {
            throw new AopInvocationException(
                    "Null return value from advice does not match primitive return type for: " + method);
        }
        return retVal;
    } finally {
        if (target != null &amp;&amp; !targetSource.isStatic()) {
            targetSource.releaseTarget(target);
        }
        if (setProxyContext) {
            // 恢复现场，移除当前线程上下文中的proxy
            AopContext.setCurrentProxy(oldProxy);
        }
    }
}

ReflectiveMethodInvocation​	Spring AOP 的cglib和jdk代理都会用到的数据结构。是 方法拦截链执行的核心实现类。每当调用代理类中的方法时，都会构造一个ReflectiveMethodInvocation对象，内部封装了一个方法调用的上下文，包括目标对象、目标方法、方法参数、拦截器链等。核心是通过调用 proceed() 方法按顺序执行所有拦截器，最终调用目标方法。
public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable {
    // 用于记录当前执行到第几个拦截器
    private int currentInterceptorIndex = -1;

    // 进行动态增强器的匹配判断，执行拦截器，和传播的实现
    public Object proceed() throws Throwable {
        // 执行完所有增强方法后执行切点方法
        if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {
            return invokeJoinpoint();
        }

        // 获取下一个要执行的拦截器
        Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers
                .get(++this.currentInterceptorIndex);
        // 调用拦截器方法时，都需要将this作为参数传递以保证当前拦截能传播给后面的增强器（proceed方法）

        if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) { // 动态匹配的增强器，需要进行动态参数匹配
            InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;
            Class&lt;?> targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());
            if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) {
                // 匹配，执行拦截器
                return dm.interceptor.invoke(this);
            } else {
                // 匹配失败就不执行拦截器，触发下一个拦截器的判断和执行
                return proceed();
            }
        } else {
            // 非动态拦截器，比如事务的TransactionInterceptor，和异步的 AnnotationAsyncExecutionInterceptor等等
            return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);
        }
    }
}

总结​	不论是cglib还是jdk的增强，增强的实现都可以总结为对原方法可使用的Advisor的收集，再构造成ReflectiveMethodInvocation，由ReflectiveMethodInvocation去进行动态增强器（一般都和参数有关）的判断，执行拦截器和拦截的传播。​	且Spring都会默认对代理bean实现两个接口（代码实现在AopProxyUtils#completeProxiedInterfaces中），分别是SpringProxy和Advised。SpringProxy用来表示当前bean已经被spring的增强了，而Advised则可以用来拿到原始bean（所以，要在代理bean中拿到原始bean，直接将代理bean强转为Advised，再利用其getTargetSource方法得到原始非代理bean）
AOP测试被增强的class，其中@BizLog是注解切面，切面类为LogInterceptor，用来做日志打印的
package site.shanzhao;

import site.shanzhao.BizLog;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

@Component
public class SpringAopDemo {

    @Transactional
    @BizLog
    public void aopMethod(){
        System.out.println("aopMethod run...............");
    }

    public void notAopMethod(){
        System.out.println("notAopMethod run...............");
    }
}

arthas解密sc
sc -d site.shanzhao.SpringAopDemo：查看指定的class加载信息（这里有两个class信息，增强class和源class，我这里只关心增强的class）

重点观察interfaces这一行，可以发现这个代理类实现了3个接口，分别为SpringProxy，Advised和Factory




 class-info        site.shanzhao.SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60
 code-source       /Users/shanzhao/IdeaProjects/soil/target/classes/
 name              site.shanzhao.SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60
 isInterface       false
 isAnnotation      false
 isEnum            false
 isAnonymousClass  false
 isArray           false
 isLocalClass      false
 isMemberClass     false
 isPrimitive       false
 isSynthetic       false
 simple-name       SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60
 modifier          public
 annotation
 interfaces        org.springframework.aop.SpringProxy,org.springframework.aop.framework.Advised,org.springframework.cglib.proxy.Factory
 super-class       +-site.shanzhao.SpringAopDemo
                     +-java.lang.Object
 class-loader      +-sun.misc.Launcher$AppClassLoader@18b4aac2
                     +-sun.misc.Launcher$ExtClassLoader@13fee20c
 classLoaderHash   18b4aac2

jad
jad site.shanzhao.SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60：使用jad反编译代理class，这里只展示出了重点代码

// package site.shanzhao;

import java.lang.reflect.Method;
import org.aopalliance.aop.Advice;
import org.springframework.aop.Advisor;
import org.springframework.aop.SpringProxy;
import org.springframework.aop.TargetClassAware;
import org.springframework.aop.TargetSource;
import org.springframework.aop.framework.Advised;
import org.springframework.aop.framework.AopConfigException;
import org.springframework.cglib.core.ReflectUtils;
import org.springframework.cglib.core.Signature;
import org.springframework.cglib.proxy.Callback;
import org.springframework.cglib.proxy.Dispatcher;
import org.springframework.cglib.proxy.Factory;
import org.springframework.cglib.proxy.MethodInterceptor;
import org.springframework.cglib.proxy.MethodProxy;
import org.springframework.cglib.proxy.NoOp;
import site.shanzhao.SpringAopDemo;

public class SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60
        extends SpringAopDemo
        implements SpringProxy,
        Advised,
        Factory {
    private boolean CGLIB$BOUND;
    public static Object CGLIB$FACTORY_DATA;
    private static final ThreadLocal CGLIB$THREAD_CALLBACKS;
    private static final Callback[] CGLIB$STATIC_CALLBACKS;
    private MethodInterceptor CGLIB$CALLBACK_0;
    private MethodInterceptor CGLIB$CALLBACK_1;
    private NoOp CGLIB$CALLBACK_2;
    private Dispatcher CGLIB$CALLBACK_3;
    private Dispatcher CGLIB$CALLBACK_4;
    private MethodInterceptor CGLIB$CALLBACK_5;
    private MethodInterceptor CGLIB$CALLBACK_6;

    // 为org.springframework.aop.framework.Advised的接口，内部直接使用4号callback转化为ProxyFactory对象再调用目标方法
    @Override
    public final TargetSource getTargetSource() {
        Dispatcher dispatcher = this.CGLIB$CALLBACK_4;
        if (dispatcher == null) {
            SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60.CGLIB$BIND_CALLBACKS(this);
            dispatcher = this.CGLIB$CALLBACK_4;
        }
        return ((Advised) dispatcher.loadObject()).getTargetSource();
    }

    // aop增强的方法，使用0号callback进行处理，实现类为DynamicAdvisedInterceptor。
    // 应该有两个适合这个方法的Advisor，一个是@BizLog的LogInterceptor切面，另一个是事物切面
    public final void aopMethod() {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_0;
        if (methodInterceptor == null) {
            SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_0;
        }
        if (methodInterceptor != null) {
            Object object = methodInterceptor.intercept(this, CGLIB$aopMethod$0$Method, CGLIB$emptyArgs,
                    CGLIB$aopMethod$0$Proxy);
            return;
        }
        super.aopMethod();
    }

    // 未增强的方法，同样使用0号callback进行处理，但却不会有适合这个方法的Advisor
    public final void notAopMethod() {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_0;
        if (methodInterceptor == null) {
            SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_0;
        }
        if (methodInterceptor != null) {
            Object object = methodInterceptor.intercept(this, CGLIB$notAopMethod$1$Method, CGLIB$emptyArgs,
                    CGLIB$notAopMethod$1$Proxy);
            return;
        }
        super.notAopMethod();
    }

    // Object的equals方法，使用5号callback处理，实现类为EqualsInterceptor
    public final boolean equals(Object object) {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_5;
        if (methodInterceptor == null) {
            SpringAopDemo$$EnhancerBySpringCGLIB$$6d7e1f60.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_5;
        }
        if (methodInterceptor != null) {
            Object object2 = methodInterceptor.intercept(this, CGLIB$equals$2$Method, new Object[] { object },
                    CGLIB$equals$2$Proxy);
            return object2 == null ? false : (Boolean) object2;
        }
        return super.equals(object);
    }

}

debug下代理类的信息这是从容器中直接获取SpringAopDemo这个class得到的对象，也就是代理类而不是源对象


重点信息已用红框框处，逐个分析

CGLIB$CALLBACK_0：通用拦截器，有切面和没有切面的普通方法方法都会用
advised：实现为org.springframework.aop.framework.ProxyFactory。是 Spring AOP 中封装代理创建逻辑的核心工具类，实现了 Advised 接口。它通过维护一系列配置和内部结构，完成对目标对象的方法级别增强。
targetSource：内部封装了源对象，可以将当前代理类强转为Advised，在调用其getTargetSource方法获取到源对象
methodCache：缓存方法与其对应增强（Advisor）链的映射，加快方法调用时的拦截查找过程。
notAopMethod：没有切面，所以size&#x3D;0
aopMethod：有两个切面，缓存的size&#x3D;2


advisor：代理类所有的Advisor
proxyTargetClass：是否直接代理的目标class。为true则表示cglib proxy，fasle则是jdk proxy
exposeProxy：是否将当前代理暴露到 ThreadLocal 上下文中，允许在目标对象内部通过 AopContext.currentProxy() 获取自身代理对象，用于内部方法调用也能被增强。
frozen：表示配置是否被冻结。默认为false，支持在运行时动态添加或移除 Advisor。如果设置为 true，配置将被锁定，并跳过 methodCache 的清理逻辑以提升性能。



]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-Bean的字段填充阶段处理</title>
    <url>/2021-01-14/spring-bean-de-zi-duan-tian-chong-jie-duan-chu-li/</url>
    <content><![CDATA[
​	对CommonAnnotationBeanPostProcessor和AutowiredAnnotationBeanPostProcessor从源码分析了其依赖的解析、创建流程
 



CommonAnnotationBeanPostProcessor​	专用来处理非Srping官方提供，而是javax的通用如下注解：

@javax.annotation.Resource
@javax.annotation.PostConstruct
@javax.annotation.PreDestroy
@javax.ejb.EJB
@javax.xml.ws.WebServiceRef

其主要有两个重要过程，一是提取这些注解所在字段或方法的元数据。之后才是使用这些注解
其架构如下图所示。1被用在解析注解所在字段的元数据，2则是使用这些注解的处理器接口，3则表示它也具备Init和Destory注解解析的功能

CommonAnnotationBeanPostProcessor架构

解析Field和方法
public void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?> beanType, String beanName) {
      // 调用父接口，解析@PostConstruct和@PreDestroy相关方法
    super.postProcessMergedBeanDefinition(beanDefinition, beanType, beanName);
        // 解析其余的注解
    InjectionMetadata metadata = findResourceMetadata(beanName, beanType, null);
    metadata.checkConfigMembers(beanDefinition);
}

private InjectionMetadata findResourceMetadata(String beanName, final Class&lt;?> clazz, @Nullable PropertyValues pvs) {
    // 构建当前bean的缓存key，用于存放这个bean的所有依赖
        String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName());
        // 先从injectionMetadataCache缓存中拿，没有再构造，最后放入缓存
        InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey);
        if (InjectionMetadata.needsRefresh(metadata, clazz)) {
            synchronized (this.injectionMetadataCache) {
                metadata = this.injectionMetadataCache.get(cacheKey);
                if (InjectionMetadata.needsRefresh(metadata, clazz)) {
                    if (metadata != null) {
                        metadata.clear(pvs);
                    }
                    metadata = buildResourceMetadata(clazz);
                    this.injectionMetadataCache.put(cacheKey, metadata);
                }
            }
        }
        return metadata;
    }
// 开始解析@WebServiceRef，@EJB和@Resource
// 这里面任意一个解析后都会进行Modifier.isStatic判断。可知静态字段或方法不支持自动注入，直接抛出了异常
private InjectionMetadata buildResourceMetadata(final Class&lt;?> clazz) {
        List&lt;InjectionMetadata.InjectedElement> elements = new ArrayList&lt;>();
        Class&lt;?> targetClass = clazz;

        do {
            final List&lt;InjectionMetadata.InjectedElement> currElements = new ArrayList&lt;>();

      // 遍历这个class的所有field，依次对每个field进行处理
            ReflectionUtils.doWithLocalFields(targetClass, field -> {
                // @WebServiceRef注解处理
                if (webServiceRefClass != null &amp;&amp; field.isAnnotationPresent(webServiceRefClass)) {
                    if (Modifier.isStatic(field.getModifiers())) {
                        throw new IllegalStateException("@WebServiceRef annotation is not supported on static fields");
                    }
                    currElements.add(new WebServiceRefElement(field, field, null));
                }
                // @EJB注解处理
                else if (ejbRefClass != null &amp;&amp; field.isAnnotationPresent(ejbRefClass)) {
                    if (Modifier.isStatic(field.getModifiers())) {
                        throw new IllegalStateException("@EJB annotation is not supported on static fields");
                    }
                    currElements.add(new EjbRefElement(field, field, null));
                }
                // @Resource注解处理
                else if (field.isAnnotationPresent(Resource.class)) {
                    if (Modifier.isStatic(field.getModifiers())) {
                        throw new IllegalStateException("@Resource annotation is not supported on static fields");
                    }
                    if (!this.ignoredResourceTypes.contains(field.getType().getName())) {
                        currElements.add(new ResourceElement(field, field, null));
                    }
                }
            });

      // 再遍历这个class的所有method，处理以set方法进行注入的方式
            ReflectionUtils.doWithLocalMethods(targetClass, method -> {
                Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method);
                if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) {
                    return;
                }
                if (method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) {
                    if (webServiceRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(webServiceRefClass)) {
                        if (Modifier.isStatic(method.getModifiers())) {
                            throw new IllegalStateException("@WebServiceRef annotation is not supported on static methods");
                        }
                        if (method.getParameterCount() != 1) {
                            throw new IllegalStateException("@WebServiceRef annotation requires a single-arg method: " + method);
                        }
                        PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);
                        currElements.add(new WebServiceRefElement(method, bridgedMethod, pd));
                    }
                    else if (ejbRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(ejbRefClass)) {
                        if (Modifier.isStatic(method.getModifiers())) {
                            throw new IllegalStateException("@EJB annotation is not supported on static methods");
                        }
                        if (method.getParameterCount() != 1) {
                            throw new IllegalStateException("@EJB annotation requires a single-arg method: " + method);
                        }
                        PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);
                        currElements.add(new EjbRefElement(method, bridgedMethod, pd));
                    }
                    else if (bridgedMethod.isAnnotationPresent(Resource.class)) {
                        if (Modifier.isStatic(method.getModifiers())) {
                            throw new IllegalStateException("@Resource annotation is not supported on static methods");
                        }
                        Class&lt;?>[] paramTypes = method.getParameterTypes();
                        if (paramTypes.length != 1) {
                            throw new IllegalStateException("@Resource annotation requires a single-arg method: " + method);
                        }
                        if (!this.ignoredResourceTypes.contains(paramTypes[0].getName())) {
                            PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);
                            currElements.add(new ResourceElement(method, bridgedMethod, pd));
                        }
                    }
                }
            });

            elements.addAll(0, currElements);
            targetClass = targetClass.getSuperclass();
        }
        while (targetClass != null &amp;&amp; targetClass != Object.class);

        return new InjectionMetadata(clazz, elements);
    }

ResourceElement源码​	以@Resource注解解析后的数据ResourceElement为例，可以发现beanName默认为@Resource的name字段。如果没有则为field字段（注解在field上）。或者则去掉前面的set，再将下个字母变为小写作为beanName（注解在set方法上）
private class ResourceElement extends LookupElement {

    /**
     * 存在@Lazy注解，且value为true，这个值就为true
     */
    private final boolean lazyLookup;

    public ResourceElement(Member member, AnnotatedElement ae, @Nullable PropertyDescriptor pd) {
       super(member, pd);
       Resource resource = ae.getAnnotation(Resource.class);
       // @Resource的name字段
       String resourceName = resource.name();
       Class&lt;?> resourceType = resource.type();
       this.isDefaultName = !StringUtils.hasLength(resourceName);
       if (this.isDefaultName) { // name字段为空
          // 先获取这个字段名
          resourceName = this.member.getName();
          if (this.member instanceof Method &amp;&amp; resourceName.startsWith("set") &amp;&amp; resourceName.length() > 3) { // 注解在set方法上，则去掉前面的set，再将下个字母变为小写作为beanName
             resourceName = Introspector.decapitalize(resourceName.substring(3));
          }
       }
       else if (embeddedValueResolver != null) { // 支持占位符解析
          resourceName = embeddedValueResolver.resolveStringValue(resourceName);
       }
       if (Object.class != resourceType) {
          checkResourceType(resourceType);
       }
       else {
          // No resource type specified... check field/method.
          resourceType = getResourceType();
       }
       // 默认字段名
       this.name = (resourceName != null ? resourceName : "");
       // 默认当前字段的Class类型
       this.lookupType = resourceType;
       String lookupValue = resource.lookup();
       this.mappedName = (StringUtils.hasLength(lookupValue) ? lookupValue : resource.mappedName());
       Lazy lazy = ae.getAnnotation(Lazy.class);
       this.lazyLookup = (lazy != null &amp;&amp; lazy.value());
    }

   /**
           字段注入方法，如果需要懒加载，则会创建一个代理对象
   */
    @Override
    protected Object getResourceToInject(Object target, @Nullable String requestingBeanName) {
       return (this.lazyLookup ? buildLazyResourceProxy(this, requestingBeanName) :
             getResource(this, requestingBeanName));
    }
}

字段注入bean的populateBean调用了InstantiationAwareBeanPostProcessor#postProcessProperties方法，开始字段的注入
CommonAnnotationBeanPostProcessor#postProcessPropertiespublic PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) {
        // 找出上一步缓存的元数据
    InjectionMetadata metadata = findResourceMetadata(beanName, bean.getClass(), pvs);
    try {
      // 开始注入
       metadata.inject(bean, beanName, pvs);
    }
    catch (Throwable ex) {
       throw new BeanCreationException(beanName, "Injection of resource dependencies failed", ex);
    }
    return pvs;
}

InjectionMetadata.InjectedElement#injectprotected void inject(Object target, @Nullable String requestingBeanName, @Nullable PropertyValues pvs)
       throws Throwable {

    if (this.isField) { // 字段注入
       Field field = (Field) this.member;
       ReflectionUtils.makeAccessible(field);
       // 根据不同的子类getResourceToInject实现，获取对应的bean。会触发依赖bean的创建
       // 依赖bean创建完毕并返回后，再将其赋予给field
       field.set(target, getResourceToInject(target, requestingBeanName));
    }
    else { // set方法注入
       if (checkPropertySkipping(pvs)) {
          return;
       }
       try {
          Method method = (Method) this.member;
          ReflectionUtils.makeAccessible(method);
          method.invoke(target, getResourceToInject(target, requestingBeanName));
       }
       catch (InvocationTargetException ex) {
          throw ex.getTargetException();
       }
    }
}

总结CommonAnnotationBeanPostProcessor 是标准注解(@Resource/@PostConstruct/@PreDestroy)的解析者，通过元数据提前解析+生命周期钩子回调，实现了依赖注入和生命周期管理。

CommonAnnotationBeanPostProcessor#postProcessMergedBeanDefinition：负责扫描 @Resource、@PostConstruct、@PreDestroy 注解，把解析结果封装成 InjectionMetadata（字段、方法对应的 ResourceElement 等），再缓存下来，等待后续注入或生命周期回调使用
CommonAnnotationBeanPostProcessor#postProcessProperties：负责根据解析好的 InjectionMetadata 真正进行注入
InitDestroyAnnotationBeanPostProcessor#postProcessBeforeInitialization： 在 Bean 初始化前，调用所有 @PostConstruct 标注的方法
InitDestroyAnnotationBeanPostProcessor#postProcessBeforeDestruction：在 Bean 销毁前，调用所有 @PreDestroy 标注的方法。



AutowiredAnnotationBeanPostProcessor根据构造方法可知，它专用来处理Spring提供的这些注解
public AutowiredAnnotationBeanPostProcessor() {
      // @Autowired支持
    this.autowiredAnnotationTypes.add(Autowired.class);
      // @Value支持
    this.autowiredAnnotationTypes.add(Value.class);
    try {
       // javax提供的@Value支持
       this.autowiredAnnotationTypes.add((Class&lt;? extends Annotation>)
             ClassUtils.forName("javax.inject.Value", AutowiredAnnotationBeanPostProcessor.class.getClassLoader()));
       logger.trace("JSR-330 'javax.inject.Inject' annotation found and supported for autowiring");
    }
    catch (ClassNotFoundException ex) {
       // JSR-330 API not available - simply skip.
    }
}


@org.springframework.beans.factory.annotation.Autowired
@org.springframework.beans.factory.annotation.Value
@javax.inject.Inject

​		整体流程和上面的CommonAnnotationBeanPostProcessor差不多。都是在postProcessMergedBeanDefinition方法里进行bean内部有上诉3个注解的字段或方法进行解析并缓存。然后在postProcessProperties进行依赖注入
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-Transactional</title>
    <url>/2021-02-23/spring-transactional/</url>
    <content><![CDATA[
​	从源码分析了@Transactional的解析和切面使用流程。Spring事物如此复杂是因为不同的PROPAGATION有不同的策略，特别是在嵌套的流程中，所以重点分析了PlatformTransactionManager的事物获取流程，深入了解了PROPAGATION的实现




@EnableTransactionManagement​	开启Spring基于注解的事务管理，其背后主要通过导入一个基础配置类 ProxyTransactionManagementConfiguration 来实现核心功能。
该配置类定义并注册了事务功能所依赖的三个关键 Bean：



Bean 名称
作用概述



TransactionAttributeSource
用于解析方法或类上的 @Transactional 注解，提取事务属性（如传播行为、回滚规则等）。默认实现为 AnnotationTransactionAttributeSource。


TransactionInterceptor
真正的事务拦截器，在目标方法执行前后进行事务管理操作（开启、提交、回滚等）。本质上是一个 MethodInterceptor。


BeanFactoryTransactionAttributeSourceAdvisor
是 Spring AOP 中的 Advisor，封装了 TransactionAttributeSource 和 TransactionInterceptor，通过切点判断哪些方法需要事务，并将拦截器应用到这些方法上。


BeanFactoryTransactionAttributeSourceAdvisor​	是一个PointcutAdvisor，既可以解析方法和类的注解事物信息，也能将真正的拦截器应用到代理中，实现注解事物的支持。
TransactionAttributeSourcePointcut​	TransactionAttributeSourcePointcut 是 Spring 声明式事务机制中的关键组件之一，它继承自 StaticMethodMatcherPointcut，这是一个仅关注方法匹配、对类无过滤限制的 Pointcut 实现。	
为什么这么设计？因为在事务注解的处理逻辑中

是否应用事务主要取决于方法级别是否存在 @Transactional 注解
若方法上无注解，才会回退查找类级别上的事务配置
因此，从设计上讲，应该保留对所有类的匹配资格，不能在 ClassFilter 层面就提前“判死刑”

换句话说，Spring 不会直接排除某些类，而是逐个方法检查是否具备事务属性，从而实现最大化的灵活性和兼容性。
public abstract class StaticMethodMatcherPointcut extends StaticMethodMatcher implements Pointcut {

    // 始终匹配为true的ClassFilter
    private ClassFilter classFilter = ClassFilter.TRUE;

    public void setClassFilter(ClassFilter classFilter) {
        this.classFilter = classFilter;
    }

    @Override
    public ClassFilter getClassFilter() {
        return this.classFilter;
    }

    @Override
    public final MethodMatcher getMethodMatcher() {
        return this;
    }

}

方法解析
public boolean matches(Method method, Class&lt;?> targetClass) {
    // === 排除掉一些不需要事务增强的内部类 ===
    // 例如事务代理自身、事务管理器、异常翻译器等，避免不必要的切面增强
    if (TransactionalProxy.class.isAssignableFrom(targetClass) ||
        PlatformTransactionManager.class.isAssignableFrom(targetClass) ||
        PersistenceExceptionTranslator.class.isAssignableFrom(targetClass)) {
        return false;
    }

    // === 通过 TransactionAttributeSource 判断该方法是否需要事务处理 ===
    // 如果解析不到事务属性（即无 @Transactional 注解），则不匹配
    TransactionAttributeSource tas = getTransactionAttributeSource();
    return (tas == null || tas.getTransactionAttribute(method, targetClass) != null);
}

TransactionAttributeSource​	TransactionAttributeSource 是 Spring 中用于解析方法&#x2F;类上的事务注解的核心接口，Spring 的默认实现为 **AnnotationTransactionAttributeSource**。
它的作用是从方法或类中提取事务元信息，并将其封装为一个 TransactionAttribute 对象，供后续事务切面使用。

支持的注解类型包括：

Spring 自身的 @org.springframework.transaction.annotation.Transactional
Java 标准的 @javax.transaction.Transactional
EJB 标准的 @javax.ejb.TransactionAttribute


​	Spring 的 @Transactional 注解最终会被解析为一个 RuleBasedTransactionAttribute 对象，该对象包含了传播行为、隔离级别、超时、只读等完整事务配置。
解析优先级​	在执行方法事务增强前，Spring 会根据如下顺序查找事务注解，一旦某一层找到了，就立即返回，停止继续向上查找

目标类中“具体实现方法”上的注解
目标类上（Class级别）的注解
接口中定义的“方法”上的注解
接口自身（Class级别）的注解

关键源码public class AnnotationTransactionAttributeSource extends AbstractFallbackTransactionAttributeSource
        implements Serializable {
    // javax.transaction.Transactional注解支持
    private static final boolean jta12Present;

    // javax.ejb.TransactionAttribute注解支持
    private static final boolean ejb3Present;

    static {
        ClassLoader classLoader = AnnotationTransactionAttributeSource.class.getClassLoader();
        jta12Present = ClassUtils.isPresent("javax.transaction.Transactional", classLoader);
        ejb3Present = ClassUtils.isPresent("javax.ejb.TransactionAttribute", classLoader);
    }
    // 是否只代理public方法，默认为true
    private final boolean publicMethodsOnly;

    // 事物解析器，顺序有优先级
    // 1. SpringTransactionAnnotationParser (这个是一定会有的)
    // 2. JtaTransactionAnnotationParser（需要有javax.transaction.Transactional注解）
    // 3. Ejb3TransactionAnnotationParser（需要有javax.ejb.TransactionAttribute注解）
    private final Set&lt;TransactionAnnotationParser> annotationParsers;

    public TransactionAttribute getTransactionAttribute(Method method, @Nullable Class&lt;?> targetClass) {
        if (method.getDeclaringClass() == Object.class) {
            return null;
        }

        // 先看看有没有缓存
        Object cacheKey = getCacheKey(method, targetClass);
        TransactionAttribute cached = this.attributeCache.get(cacheKey);
        if (cached != null) {
            // NULL_TRANSACTION_ATTRIBUTE表示无事物
            if (cached == NULL_TRANSACTION_ATTRIBUTE) {
                return null;
            } else {
                return cached;
            }
        } else {
            // 事物信息查找
            TransactionAttribute txAttr = computeTransactionAttribute(method, targetClass);
            // 缓存并返回
            if (txAttr == null) {
                this.attributeCache.put(cacheKey, NULL_TRANSACTION_ATTRIBUTE);
            } else {
                String methodIdentification = ClassUtils.getQualifiedMethodName(method, targetClass);
                if (txAttr instanceof DefaultTransactionAttribute) {
                    ((DefaultTransactionAttribute) txAttr).setDescriptor(methodIdentification);
                }
                if (logger.isTraceEnabled()) {
                    logger.trace(
                            "Adding transactional method '" + methodIdentification + "' with attribute: " + txAttr);
                }
                this.attributeCache.put(cacheKey, txAttr);
            }
            return txAttr;
        }
    }

    protected TransactionAttribute computeTransactionAttribute(Method method, @Nullable Class&lt;?> targetClass) {
        // 默认非public方法不支持
        if (allowPublicMethodsOnly() &amp;&amp; !Modifier.isPublic(method.getModifiers())) {
            return null;
        }
        // 获取最具体的方法（桥接方法处理），确保是目标类中的实现方法
        Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass);

        // 先解析方法上的解析事务注解
        TransactionAttribute txAttr = findTransactionAttribute(specificMethod);
        if (txAttr != null) {
            return txAttr;
        }

        // 方法上没有，在解析类上的事务注解
        txAttr = findTransactionAttribute(specificMethod.getDeclaringClass());
        if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) {
            return txAttr;
        }
        // === 此时 specificMethod ≠ method（说明原始 method 是接口定义） ===
        // 再尝试解析接口方法本身及其声明类（即接口）上的事务注解
        if (specificMethod != method) {
            txAttr = findTransactionAttribute(method);
            if (txAttr != null) {
                return txAttr;
            }
            txAttr = findTransactionAttribute(method.getDeclaringClass());
            if (txAttr != null &amp;&amp; ClassUtils.isUserLevelMethod(method)) {
                return txAttr;
            }
        }

        return null;
    }
}

TransactionInterceptor​	TransactionInterceptor 是用于处理声明式事务（@Transactional 注解）的 AOP 拦截器，本质上是一个环绕（Around）通知，拦截被 @Transactional 标注的方法。
​	它自身并不直接实现事务的提交、回滚等核心逻辑，而是将这些操作委托给底层的PlatformTransactionManager 来完成。
主要职责
从 TransactionAttributeSource 中获取事务属性（如传播行为、隔离级别、是否只读等）
调用 TransactionManager 获取或创建事务
执行目标方法，捕获异常判断是否回滚
正常返回时提交事务，异常时进行回滚
管理当前事务上下文（通过 ThreadLocal）以支持事务传播

关键源码public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable {

    // =============== 父类TransactionAspectSupport中的字段 =================
    private static final ThreadLocal&lt;TransactionInfo> transactionInfoHolder = new NamedThreadLocal&lt;>(
            "Current aspect-driven transaction");

    /**
     * AOP拦截器核心逻辑：拦截事务方法，并根据事务配置（声明式 or 编程式）处理事务生命周期
     */
    protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?> targetClass,
            final InvocationCallback invocation) throws Throwable {

        TransactionAttributeSource tas = getTransactionAttributeSource();
        // 获取事务属性
        final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);
        // 获取beanFactory中的TransactionManager（可能是DataSourceTransactionManager、JtaTransactionManager等）
        final PlatformTransactionManager tm = determineTransactionManager(txAttr);
        // 构造方法唯一标识（例如：site.shanzhao.UserService.save）
        final String joinpointIdentification = methodIdentification(method, targetClass, txAttr);

        // 声明式事务处理（@Transactional注解就走这）
        if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) {
            // 创建事务信息对象，必要时启动事务
            TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);

            Object retVal;
            try {
                // 执行被增强的方法
                retVal = invocation.proceedWithInvocation();
            } catch (Throwable ex) {
                // 处理异常回滚
                completeTransactionAfterThrowing(txInfo, ex);
                throw ex;
            } finally {
                // 清理ThreadLocal中的事务信息
                cleanupTransactionInfo(txInfo);
            }
            // 方法正常返回则提交事务
            commitTransactionAfterReturning(txInfo);
            return retVal;
        }

        else { // 编程式事务处理
            Object result;
            final ThrowableHolder throwableHolder = new ThrowableHolder();

            try {
                result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -> {
                    TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);
                    try {
                        return invocation.proceedWithInvocation();
                    } catch (Throwable ex) {
                        if (txAttr.rollbackOn(ex)) {
                            if (ex instanceof RuntimeException) {
                                throw (RuntimeException) ex;
                            } else {
                                throw new ThrowableHolderException(ex);
                            }
                        } else {
                            throwableHolder.throwable = ex;
                            return null;
                        }
                    } finally {
                        cleanupTransactionInfo(txInfo);
                    }
                });
            } catch (ThrowableHolderException ex) {
                throw ex.getCause();
            } catch (TransactionSystemException ex2) {
                if (throwableHolder.throwable != null) {
                    logger.error("Application exception overridden by commit exception", throwableHolder.throwable);
                    ex2.initApplicationException(throwableHolder.throwable);
                }
                throw ex2;
            } catch (Throwable ex2) {
                if (throwableHolder.throwable != null) {
                    logger.error("Application exception overridden by commit exception", throwableHolder.throwable);
                }
                throw ex2;
            }

            // Check result state: It might indicate a Throwable to rethrow.
            if (throwableHolder.throwable != null) {
                throw throwableHolder.throwable;
            }
            return result;
        }
    }

    /**
     * 根据事务属性创建事务（如果有必要）。
     *
     * - 若当前方法配置了事务属性（如 @Transactional），则获取事务管理器并尝试开启事务。
     * - 若未指定事务名称，则使用方法签名作为事务名称（便于日志跟踪和调试）。
     * - 最终返回一个封装了事务状态的 TransactionInfo 对象（用于后续提交或回滚处理）。
     *
     */
    protected TransactionInfo createTransactionIfNecessary(
            @Nullable PlatformTransactionManager tm,
            @Nullable TransactionAttribute txAttr,
            final String joinpointIdentification) {

        // 如果没有设置事务名称，则使用方法签名作为名称，并封装成 DelegatingTransactionAttribute。
        if (txAttr != null &amp;&amp; txAttr.getName() == null) {
            txAttr = new DelegatingTransactionAttribute(txAttr) {
                @Override
                public String getName() {
                    return joinpointIdentification;
                }
            };
        }

        TransactionStatus status = null;

        // 若存在事务属性，表示方法需要事务处理
        if (txAttr != null) {
            if (tm != null) {
                // 调用事务管理器开启事务，返回事务状态（可能是新事务，也可能是参与已有事务）
                status = tm.getTransaction(txAttr);
            } else {
                // 没有配置事务管理器，无法执行事务控制，打印调试日志
                if (logger.isDebugEnabled()) {
                    logger.debug("Skipping transactional joinpoint [" + joinpointIdentification +
                            "] because no transaction manager has been configured");
                }
            }
        }

        // 构造 TransactionInfo 对象，并将其绑定到父类TransactionAspectSupport#ThreadLocal 中，
        // 用于在线程内部保存当前事务的上下文信息（如 TransactionStatus、事务属性等），
        // 以支持事务传播、回滚控制和资源清理等操作
        return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);
    }

    /**
     * 在目标方法抛出异常后完成事务处理（回滚或提交）
     *
     * 该方法根据事务属性（如 @Transactional 中的 rollbackFor）判断是否需要回滚，
     * 若不需要回滚则尝试提交（注意：提交时内部仍可能因为标记了 rollbackOnly 而实际执行回滚）。
     *
     */
    protected void completeTransactionAfterThrowing(@Nullable TransactionInfo txInfo, Throwable ex) {
        if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) {
            if (logger.isTraceEnabled()) {
                logger.trace("Completing transaction for [" + txInfo.getJoinpointIdentification() +
                        "] after exception: " + ex);
            }
            if (txInfo.transactionAttribute != null &amp;&amp; txInfo.transactionAttribute.rollbackOn(ex)) {
                // 命中回滚异常，需要操作事务回滚
                try {
                    txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus());
                } catch (TransactionSystemException ex2) {
                    logger.error("Application exception overridden by rollback exception", ex);
                    ex2.initApplicationException(ex);
                    throw ex2;
                } catch (RuntimeException | Error ex2) {
                    logger.error("Application exception overridden by rollback exception", ex);
                    throw ex2;
                }
            } else {
                // 出现了异常但不需要回滚。则尝试commit（不一定真的会commit，内部还是可能根据rollbackOnly来判断是否rollback）
                try {
                    txInfo.getTransactionManager().commit(txInfo.getTransactionStatus());
                } catch (TransactionSystemException ex2) {
                    logger.error("Application exception overridden by commit exception", ex);
                    ex2.initApplicationException(ex);
                    throw ex2;
                } catch (RuntimeException | Error ex2) {
                    logger.error("Application exception overridden by commit exception", ex);
                    throw ex2;
                }
            }
        }
    }
}

PlatformTransactionManager​	PlatformTransactionManager 抽象了事务的获取、提交、回滚，是 Spring 事务架构的核心入口。所有 @Transactional 的底层实现最终都依赖它完成真正的事务操作。基本实现类为DataSourceTransactionManager。
TransactionStatus​	默认实现为DefaultTransactionStatus。每个@Transactional注解都会生成一个DefaultTransactionStatus，用于表示当前事物的允许状态。在事务执行流程中，它作为事务的运行时上下文贯穿始终，PlatformTransactionManager 对其进行更新和查询，以决定事务的提交、回滚及其他控制逻辑。
​	其中的isNewTransaction()方法决定了当前@Transactional生成的事物是否有资格进行commit或rollback
public class DefaultTransactionStatus extends AbstractTransactionStatus {

    /**
     * 当前事务对象，一般为具体事务实现（如 DataSourceTransactionObject）。
     *
     * - 若当前方法运行在事务上下文中，则 非null；
     * - 若未开启事务（如事务传播行为为 NOT_SUPPORTED），则为 null；
     *
     * 注意：即使在同一个物理事务中，每个 @Transactional 方法对应的 DefaultTransactionStatus 实例不同，
     * 但它们内部的 transaction（如 ConnectionHolder）可能是同一个对象，表示共享同一底层连接。
     */
    @Nullable
    private final Object transaction;

    /**
     * 是否是“新事务”的创建者。
     *
     * - true：当前方法通过传播行为触发了事务创建；
     * - false：当前方法加入了已有事务；
     *
     * 注意：该值为 true 不等于事务实际存在，需结合 transaction 字段判断是否真有事务资源。
     */
    private final boolean newTransaction;

    /**
     * 是否注册了 TransactionSynchronizationManager，同步管理器用于事务钩子（如 afterCommit）。
     * 即是否是本方法负责事务同步的初始化（如绑定资源、触发同步回调）。
     */
    private final boolean newSynchronization;

    /**
     * 当前事务是否只读，由 @Transactional 配置
     */
    private final boolean readOnly;

    /**
     * 当前日志是否是debug等级以上
     */
    private final boolean debug;

    /**
     * 很重要
     * 如果当前事务为嵌套事务或需要挂起上一个事务，则用于保存被挂起的事务资源。
     *
     * 一般为 SuspendedResourcesHolder 类型，用于在当前事务完成后恢复之前的事务状态。
     */
    @Nullable
    private final Object suspendedResources;

    // ============ 父类AbstractTransactionStatus中的字段 ============

    /**
     * 标识当前事务是否被标记为回滚（通常通过 setRollbackOnly() 触发）。
     */
    private boolean rollbackOnly = false;

    /**
     * 当前事务是否已完成（无论提交还是回滚）。
     */
    private boolean completed = false;

    /**
     * 用于保存事务的保存点（Savepoint），支持嵌套事务回滚。
     */
    @Nullable
    private Object savepoint;


    /**
     * 很重要的方法，决定了当前@Transactional生成的事物是否有资格进行commit或rollback
     */
    public boolean isNewTransaction() {
        return (hasTransaction() &amp;&amp; this.newTransaction);
    }
}

DataSourceTransactionManagerSpring 默认提供的基于 JDBC 数据源（javax.sql.DataSource）的 PlatformTransactionManager 实现
核心方法getTransaction 流程总结

首先判断当前线程是否已绑定事务（即 transactionActive 状态）；若存在事务，则代表当前可能处于嵌套或参与中 事务的处理场景
根据 TransactionDefinition 中指定的事务传播行为（PROPAGATION_*）来决定事务处理策略：
是否加入当前事务
是否挂起已有事务
是否开启新事务


最终构建 DefaultTransactionStatus 实例，其中封装了当前事务的控制信息（如是否新建、是否可回滚、是否只读等）
如果事务被创建（非参与），还会：
设置数据库连接的自动提交为 false
绑定资源到当前线程（ThreadLocal）
注册事务同步管理器（TransactionSynchronizationManager）以支持hook函数的调用（如 beforeCommit、afterCompletion 等）



关键源码public class DataSourceTransactionManager extends AbstractPlatformTransactionManager
        implements ResourceTransactionManager, InitializingBean {

    /**
     * 事物的获取（父类中AbstractPlatformTransactionManager的方法 ）
     */
    public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition)
            throws TransactionException {
        // 获取当前事务上下文对象，默认为 DataSourceTransactionObject
        // 初次进入时内部的 ConnectionHolder 为空（即还未绑定连接）
        Object transaction = doGetTransaction();

        // 缓存日志等级判断，避免多次调用 logger.isDebugEnabled()
        boolean debugEnabled = logger.isDebugEnabled();

        // 若无自定义事务定义，使用默认配置（PROPAGATION_REQUIRED，ISOLATION_DEFAULT 等）
        if (definition == null) {
            definition = new DefaultTransactionDefinition();
        }

        // ========== 检查当前线程是否已存在事务 ========== //
        // 条件：当前线程绑定了 ConnectionHolder 且其 transactionActive = true
        if (isExistingTransaction(transaction)) {
            // 已存在事务，根据传播行为判断处理方式
            return handleExistingTransaction(definition, transaction, debugEnabled);
        }

        // ========== 走到这表示还没有事物，根据传播行为判断是否需要新建事务 ========== //

        // 超时时间校验：不能小于默认值（-1）
        if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) {
            throw new InvalidTimeoutException("Invalid transaction timeout", definition.getTimeout());
        }

        // ========== 根据事务传播行为做决策 ========== //

        // 传播行为为 MANDATORY，但当前又没有事务，抛出异常
        if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) {
            throw new IllegalTransactionStateException(
                    "No existing transaction found for transaction marked with propagation 'mandatory'");
        }

        // 传播行为为 REQUIRED、REQUIRES_NEW、NESTED 都需要新建事务
        else if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED ||
                definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW ||
                definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {

            // 先挂起当前事务（无事务时挂空）
            SuspendedResourcesHolder suspendedResources = suspend(null);

            if (debugEnabled) {
                logger.debug("Creating new transaction with name [" + definition.getName() + "]: " + definition);
            }

            try {
                // 判断是否启用事务同步，默认是 true（除非设置为 NEVER）
                boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);

                // 构建 DefaultTransactionStatus，封装事务上下文信息
                DefaultTransactionStatus status = newTransactionStatus(
                        definition, transaction, true, newSynchronization, debugEnabled, suspendedResources);

                // 初始化事务：如创建连接、设置隔离级别、timeout，并将资源绑定到当前线程
                doBegin(transaction, definition);

                // 注册事务同步器（如触发 beforeCommit、afterCompletion 等回调）
                prepareSynchronization(status, definition);

                return status;
            } catch (RuntimeException | Error ex) {
                // 异常时恢复挂起的事务资源
                resume(null, suspendedResources);
                throw ex;
            }
        }

        // 传播行为为 SUPPORTS、NOT_SUPPORTED、NEVER —— 不启动实际事务，只做同步处理（如果配置了）
        else {
            if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) {
                logger.warn("Custom isolation level specified but no actual transaction initiated; " +
                        "isolation level will effectively be ignored: " + definition);
            }

            // 是否启用事务同步，SYNCHRONIZATION_ALWAYS 时启用
            boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);

            // 创建一个“空事务”状态，主要用于注册同步器，但没有实际事务操作
            return prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null);
        }
    }

    private TransactionStatus handleExistingTransaction(
            TransactionDefinition definition, Object transaction, boolean debugEnabled)
            throws TransactionException {

        // NEVER：完全不支持事务，当前线程存在事务则抛异常
        if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) {
            throw new IllegalTransactionStateException(
                    "Existing transaction found for transaction marked with propagation 'never'");
        }

        // NOT_SUPPORTED：暂停（挂起）当前事务，然后以非事务的方式运行
        if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) {
            if (debugEnabled) {
                logger.debug("Suspending current transaction");
            }
            Object suspendedResources = suspend(transaction);
            boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);
            return prepareTransactionStatus(
                    definition, null, false, newSynchronization, debugEnabled, suspendedResources);
        }

        // REQUIRES_NEW：暂停当前事务，新开一个事务
        if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) {
            if (debugEnabled) {
                logger.debug("Suspending current transaction, creating new transaction with name [" +
                        definition.getName() + "]");
            }
            // 暂停当前事务，方便之后还原
            SuspendedResourcesHolder suspendedResources = suspend(transaction);
            try {
                boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);
                DefaultTransactionStatus status = newTransactionStatus(
                        definition, transaction, true, newSynchronization, debugEnabled, suspendedResources);
                doBegin(transaction, definition);
                prepareSynchronization(status, definition);
                return status;
            } catch (RuntimeException | Error beginEx) {
                resumeAfterBeginException(transaction, suspendedResources, beginEx);
                throw beginEx;
            }
        }

        // NESTED：先判断是否允许嵌套事务（默认允许），然后优先通过数据库保存点（Savepoint）实现
        if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {
            if (!isNestedTransactionAllowed()) {
                throw new NestedTransactionNotSupportedException(
                        "Transaction manager does not allow nested transactions by default - " +
                                "specify 'nestedTransactionAllowed' property with value 'true'");
            }
            if (debugEnabled) {
                logger.debug("Creating nested transaction with name [" + definition.getName() + "]");
            }
            if (useSavepointForNestedTransaction()) { // 默认走这，使用数据库Savepoint模拟嵌套事务
                DefaultTransactionStatus status = prepareTransactionStatus(definition, transaction, false, false,
                        debugEnabled, null);
                status.createAndHoldSavepoint();
                return status;
            } else { // 少数情况使用真正的嵌套事务，如JTA中可能嵌套 begin/commit 调用
                boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);
                DefaultTransactionStatus status = newTransactionStatus(
                        definition, transaction, true, newSynchronization, debugEnabled, null);
                doBegin(transaction, definition);
                prepareSynchronization(status, definition);
                return status;
            }
        }

        // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED.
        // 传播策略为SUPPORTS 或 REQUIRED 或 MANDATORY
        // 这三个对已存在的事务处理方式是一致的，啥也不做，也就是直接加入已存在的事务
        if (debugEnabled) {
            logger.debug("Participating in existing transaction");
        }
        if (isValidateExistingTransaction()) {
            // 校验当前传播策略的隔离等级和是否只读与已存在的事务是否一致，不过默认不校验。
            if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) {
                Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel();
                if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) {
                    Constants isoConstants = DefaultTransactionDefinition.constants;
                    throw new IllegalTransactionStateException("Participating transaction with definition [" +
                            definition + "] specifies isolation level which is incompatible with existing transaction: "
                            +
                            (currentIsolationLevel != null
                                    ? isoConstants.toCode(currentIsolationLevel,
                                            DefaultTransactionDefinition.PREFIX_ISOLATION)
                                    : "(unknown)"));
                }
            }
            // 校验只读属性
            if (!definition.isReadOnly()) {
                if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {
                    throw new IllegalTransactionStateException("Participating transaction with definition [" +
                            definition + "] is not marked as read-only but existing transaction is");
                }
            }
        }
        // 创建事务状态对象，参与已存在事务
        boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);
        return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null);
    }

    /**
     * 开启事物
     */
    @Override
    protected void doBegin(Object transaction, TransactionDefinition definition) {
        DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction;
        Connection con = null;

        try {
            // 是否需要新建 Connection：满足任意一个条件即可
            // 1. 当前没有 ConnectionHolder（首次创建事务）
            // 2. 当前 ConnectionHolder 已参与过其他事务（如嵌套事务 REQUIRES_NEW 中旧连接已同步过）。此时不能复用旧连接，必须重新获取
            if (!txObject.hasConnectionHolder() ||
                    txObject.getConnectionHolder().isSynchronizedWithTransaction()) {
                Connection newCon = obtainDataSource().getConnection();
                if (logger.isDebugEnabled()) {
                    logger.debug("Acquired Connection [" + newCon + "] for JDBC transaction");
                }
                txObject.setConnectionHolder(new ConnectionHolder(newCon), true);
            }

            // 标记当前连接已参与事务同步
            txObject.getConnectionHolder().setSynchronizedWithTransaction(true);
            con = txObject.getConnectionHolder().getConnection();

            // 根据事务定义设置隔离级别，并记录旧值，事务完成后会恢复
            Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition);
            txObject.setPreviousIsolationLevel(previousIsolationLevel);

            // 当前Connection设为手动提交。此时把事物提交的控制权交给了Spring
            if (con.getAutoCommit()) {
                txObject.setMustRestoreAutoCommit(true);
                if (logger.isDebugEnabled()) {
                    logger.debug("Switching JDBC Connection [" + con + "] to manual commit");
                }
                con.setAutoCommit(false);
            }

            // readOnly 设置
            prepareTransactionalConnection(con, definition);
            // 标记事务为“激活”状态（事务已开启）
            txObject.getConnectionHolder().setTransactionActive(true);

            // 设置事务超时时间（单位：秒）
            int timeout = determineTimeout(definition);
            if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) {
                txObject.getConnectionHolder().setTimeoutInSeconds(timeout);
            }

            // 将当前 ConnectionHolder 绑定到线程上下文中（核心 ThreadLocal 操作）
            if (txObject.isNewConnectionHolder()) {
                TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder());
            }
        }

        catch (Throwable ex) {
            // 如果创建连接过程中出现异常，释放资源并清理 ConnectionHolder
            if (txObject.isNewConnectionHolder()) {
                DataSourceUtils.releaseConnection(con, obtainDataSource());
                txObject.setConnectionHolder(null, false);
            }
            throw new CannotCreateTransactionException("Could not open JDBC Connection for transaction", ex);
        }
    }

    /**
     * 事物的commit判断，根据rollbackOnly字段也可能走rollback。（父类中AbstractPlatformTransactionManager的方法）
     */
    public final void commit(TransactionStatus status) throws TransactionException {
        if (status.isCompleted()) { // 事务已完成（提交或回滚），不允许再次提交或回滚，属于非法状态
            throw new IllegalTransactionStateException(
                    "Transaction is already completed - do not call commit or rollback more than once per transaction");
        }

        DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status;
        // 标记为rollbackOnly的走强制回滚
        if (defStatus.isLocalRollbackOnly()) {
            if (defStatus.isDebug()) {
                logger.debug("Transactional code has requested rollback");
            }
            processRollback(defStatus, false);
            return;
        }

        if (!shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) {
            // 当前事务被标记为全局回滚，说明内部事务标记为回滚，但外层需要commit。
            // 所以会先回滚，再抛UnexpectedRollbackException异常

            if (defStatus.isDebug()) {
                logger.debug("Global transaction is marked as rollback-only but transactional code requested commit");
            }
            // 出现了意外（外层commit，但内层rollback）unexpected为true
            processRollback(defStatus, true);
            return;
        }

        // 正常事务提交流程
        // 1. 调用 beforeCommit 和 beforeCompletion 钩子
        // 2. 如果存在保存点（Savepoint）则处理嵌套事务
        // 3. 真正调用底层数据库事务管理器进行提交
        // 4. 调用 afterCommit 和 afterCompletion 钩子
        // 5. 捕获并处理提交中的异常
        processCommit(defStatus);
    }
}

PROPAGATION总结

肯定派，必须存在事务



传播行为
说明



PROPAGATION_REQUIRED （默认）
不存在就新建，存在就加入


PROPAGATION_REQUIRES_NEW
始终新建一个事务，且与旧事物完全隔离。也就至少有两此commit或rollback。存在原事务时会将原事务封装为SuspendedResourcesHolder，再重新获取一个新的数据库连接开启事务，等这个新事物运行完，再把SuspendedResourcesHolder复原


PROPAGATION_NESTED
不存在就新建，存在就新开一个嵌套的事务。（先检查nestedTransactionAllowed，为false就抛异常了，代表不支持嵌套事务。不过默认为true。）和PROPAGATION_REQUIRES_NEW的区别在于这是用数据库的Savepoint实现，至始至终只会存在一个事务，如果当前回滚，也只会退回到Savepoint，不会对外层的事务造成影响，如果都能提交，最终也只有一次真正的事务commit。所以，注册的TransactionSynchronization hook函数也只会等待整个事务的结束来回调。如果不支持安全点（JTA），那实现就完全等于PROPAGATION_REQUIRES_NEW


PROPAGATION_MANDATORY
支持已存在的事务，不存在则直接抛异常



中立派，不一定有事务



传播行为
说明



PROPAGATION_SUPPORTS
源码中并没有处理这种的传播策略。所以，它的作用是：存在事务就加入，不存在就以非事务的方式运行



否定派，不支持事务



传播行为
说明



PROPAGATION_NOT_SUPPORTED
以非事务的方式运行（有事务就暂停事务，重新获取一个没有事物的Connection使用。没有就啥也不做），实现和上面的差不多。但默认仍会注册事物同步器，让当前这个事物始终用同一个Connection


PROPAGATION_NEVER
强制性的不支持事务，要是当前存在事务，就直接抛异常





TransactionSynchronizationManager​	是Spring事物体系中的一个辅助工具，维护线程级事务上下文信息，保证事务行为在多层调用、事务传播、资源管理等场景中保持一致。
Spring 的事务是通过 AOP 管理的跨方法事务逻辑。Spring 需要有个全局但又线程安全的上下文去维护事务信息。如果没有它，则：

不同方法无法共享事务资源（比如同一个 JDBC Connection）

无法实现事务传播（比如事务嵌套时决定是否复用原事务）

无法注册和触发事务的生命周期回调（如 beforeCommit、afterCompletion）


关键字段public abstract class TransactionSynchronizationManager {

    // 绑定到当前线程的资源，比如数据库连接（key 为 DataSource ，value 为ConnectionHolder）
    // Spring 在事务开始时绑定，在事务完成后解除绑定。
    private static final ThreadLocal&lt;Map&lt;Object, Object>> resources = new NamedThreadLocal&lt;>("Transactional resources");

    // 当前线程注册的事务同步器集合（TransactionSynchronization），
    // 用于在事务生命周期各个阶段（如提交前、提交后、回滚后）执行hook回调。
    private static final ThreadLocal&lt;Set&lt;TransactionSynchronization>> synchronizations = new NamedThreadLocal&lt;>(
            "Transaction synchronizations");

    // 当前事务的名称（来自 TransactionDefinition#getName），通常用于日志记录和调试。
    private static final ThreadLocal&lt;String> currentTransactionName = new NamedThreadLocal&lt;>(
            "Current transaction name");

    // 当前事务是否被声明为只读，影响底层连接是否设置为只读模式（如 Connection#setReadOnly(true)）。
    private static final ThreadLocal&lt;Boolean> currentTransactionReadOnly = new NamedThreadLocal&lt;>(
            "Current transaction read-only status");

    // 当前事务的隔离级别（来自 TransactionDefinition）
    // 决定数据库访问的一致性级别，例如 READ_COMMITTED、REPEATABLE_READ 等。
    private static final ThreadLocal&lt;Integer> currentTransactionIsolationLevel = new NamedThreadLocal&lt;>(
            "Current transaction isolation level");

    // 当前事物是否被激活（即运行在有事物的情况下），不一定有commit或rollback的资格
    private static final ThreadLocal&lt;Boolean> actualTransactionActive = new NamedThreadLocal&lt;>(
            "Actual transaction active");

}

DataSourceUtils​		前面我们分析了 Spring 事务的整体流程，但还有1个关键问题：在实际项目中，Spring 很少直接作为持久化框架，MyBatis、Hibernate 等才是执行数据库操作的主力。那么事务是 Spring 管的，数据库连接却是由 MyBatis 获取的，两者如何协同？
这就引出了 DataSourceUtils 的作用：为持久层框架提供“Spring 管控下的连接”，确保它们获取到的 Connection 是当前事务中绑定的那个，这样事务控制（包括 commit&#x2F;rollback）才能正确生效。
核心源码public abstract class DataSourceUtils {
    

    public static Connection doGetConnection(DataSource dataSource) throws SQLException {
        Assert.notNull(dataSource, "No DataSource specified");

        // 1. 尝试从 TransactionSynchronizationManager 中获取线程绑定的 ConnectionHolder
        // 只要TransactionSynchronizationManager.isSynchronizationActive()，都应该获取的是同一个ConnectionHolder
        ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource);

        // 2. 如果当前线程中存在已关联的 ConnectionHolder 且已经持有连接，或者它被事务标记为已同步
        if (conHolder != null &amp;&amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) {
            // 引用计数
            conHolder.requested();

            // 如果还没有设置具体的连接，则新建连接并设置到 holder 中（resume 的场景）
            if (!conHolder.hasConnection()) {
                logger.debug("Fetching resumed JDBC Connection from DataSource");
                conHolder.setConnection(fetchConnection(dataSource));
            }

            return conHolder.getConnection();
        }
        // =============== 否则：没有事务，或没有绑定连接的事务 ==================

        logger.debug("Fetching JDBC Connection from DataSource");

        // 3. 获取一个新的物理连接（不在事务中或事务尚未绑定连接）
        Connection con = fetchConnection(dataSource);

        // 如果当前事物的事物同步器被激活，则将上面获取的Connection也绑定到事物资源里。让当前事物始终用用一个Connection
        // 就算当前事物是NOT_SUPPORTED，默认也会缓存ConnectionHolder
        if (TransactionSynchronizationManager.isSynchronizationActive()) {
            try {
                ConnectionHolder holderToUse = conHolder;

                if (holderToUse == null) {
                    holderToUse = new ConnectionHolder(con);
                } else {
                    holderToUse.setConnection(con);
                }

                holderToUse.requested();

                // 注册一个事物同步器用于hook
                TransactionSynchronizationManager.registerSynchronization(
                        new ConnectionSynchronization(holderToUse, dataSource));

                // 标记该连接已参与事务同步
                holderToUse.setSynchronizedWithTransaction(true);

                // 第一次调用时才绑定：DataSource -> ConnectionHolder
                if (holderToUse != conHolder) {
                    TransactionSynchronizationManager.bindResource(dataSource, holderToUse);
                }

            } catch (RuntimeException ex) {
                releaseConnection(con, dataSource);
                throw ex;
            }
        }

        return con;
    }
}

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Transactional注解</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-事物NOT_SUPPORTED策略下多数据源切换的问题</title>
    <url>/2022-03-03/spring-shi-wu-not-supported-ce-lue-xia-duo-shu-ju-yuan-qie-huan-de-wen-ti/</url>
    <content><![CDATA[​	从案例中分析了NOT_SUPPORTED默认情况下为什么不能进行多数据源切换以及优雅的解决办法，以及给出了自己的思考




起因今天写代码时遇到一个多数据源的切换问题，框架为Spring和Mybatus-Plus。在完全没事物的情况下pgsql和mysql切换没问题，但在@Transactional(propagation &#x3D; Propagation.NOT_SUPPORTED)下却切换不了。翻了以前的Spring-Transactional文章和代码，遂记录一下原因和解决思路，以及整体的思考
​	在有事物的情况下多数据源切换不了这是很正常的，毕竟Connection绑定到ThreadLocal了。但我开始简单的认为只要使用Propagation.NOT_SUPPORTED传播策略，毕竟这都不支持事物了，应该就能进行数据源切换。实际就是代码报错了，还是切换不了
伪代码ProductService#recommend被调用在一个事物里
public class ProductService {

    @Transactional(propagation = Propagation.NOT_SUPPORTED)
    public void recommend(int i){

        // pgsqlMapper这个mapper有注解 @DS("postgresql")，走pqsql库
        pgsqlMapper.queryById(i);
        
        // 走mysql库
        msyqlMapper.queryById(i);
    }
    
}

分析原因​	ProductService#recommend使用了@Transactional(propagation &#x3D; Propagation.NOT_SUPPORTED)注解，它构造出来的DefaultTransactionStatus中有如下两个字段需要重点关注。
public class DefaultTransactionStatus extends AbstractTransactionStatus {
    // 是否开启了真实的物理事物
    private final boolean newTransaction;
    // 是否由当前事务初始化并管理事务同步器（如注册连接绑定、hook 回调）
    private final boolean newSynchronization;
}

​	其中newTransaction&#x3D;false, newSynchronization&#x3D;true（受AbstractPlatformTransactionManager.transactionSynchronization字段控制）。

表示尽管当前未开启物理事务，但事务管理器仍会初始化事务同步器（TransactionSynchronizationManager.initSynchronization()），并允许资源绑定（如 ConnectionHolder）与注册事务hook（TransactionSynchronization）。
换句话说，“没有物理事务，但仍可进行事务性资源管理和 hook 回调”

​	所以当触发pgsqlMapper.queryById(i)方法时，会绑定如下资源。（这一切必须要newSynchronization&#x3D;true）


获取SqlSession时（SqlSessionUtils#getSqlSession）将SqlSessionFactory -&gt; SqlSessionHolder 给缓存到TransactionSynchronizationManager#resources中
获取Connection时（DataSourceUtils#doGetConnection）将DataSource -&gt; ConnectionHolder 也缓存到TransactionSynchronizationManager#resources中


​	所以，当走到第二个方法msyqlMapper.queryById(i)时，会拿到上一步中缓存的SqlSessionHolder，内部操作的是同一个Connection（具体为DefaultSqlSession.executor.transaction.connection），即pgsql的Connection，所以报错了
解决办法​	将这个字段AbstractPlatformTransactionManager.transactionSynchronization由默认的SYNCHRONIZATION_ALWAYS改为SYNCHRONIZATION_ON_ACTUAL_TRANSACTION。直接获取这个AbstractPlatformTransactionManager bean再进行改动有些不优雅，我翻了一遍发现有这个PlatformTransactionManagerCustomizer接口，可以对PlatformTransactionManager的子类进行定制化修改。所以可以添加如下的bean到容器中即可
@Component
public class TransactionSynchronizationCustomizer implements PlatformTransactionManagerCustomizer&lt;AbstractPlatformTransactionManager>{

    @Override
    public void customize(AbstractPlatformTransactionManager transactionManager) {
        // 解决Propagation.NOT_SUPPORTED下多数据源不能切换动态切换的问题
        transactionManager.setTransactionSynchronization(AbstractPlatformTransactionManager.SYNCHRONIZATION_ON_ACTUAL_TRANSACTION);
    }
}

思考（重点）​		在 Spring 的事务模型中，Propagation.NOT_SUPPORTED 虽然会挂起当前事务，但默认配置下（SYNCHRONIZATION_ALWAYS）仍会注册事务同步器。 这导致即使没有物理事务，依然会出现线程绑定连接的行为（如通过 DataSourceUtils.getConnection() 获得的 Connection 会复用）。
​	所以如果希望这个方法在语义上和“非事务环境”（即不使用@Transactional等情况）一致，避免隐式连接绑定，应将 transactionSynchronization 设置为 SYNCHRONIZATION_ON_ACTUAL_TRANSACTION。
​	看样子应该是Spring 为了支持某些非事务性方法（Propagation.NOT_SUPPORTED）也能参与事务资源控制才这样设计的
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title>Spring-其他重要的BeanPostProcesor</title>
    <url>/2021-04-01/spring-qi-ta-chong-yao-de-beanpostprocesor/</url>
    <content><![CDATA[
​	AsyncAnnotationBeanPostProcessor和ScheduledAnnotationBeanPostProcessor源码解析




AsyncAnnotationBeanPostProcessor@EnableAsync​	其主要功能是向容器中注册AsyncAnnotationBeanPostProcessor这个BeanDefinition，其继承了AbstractBeanFactoryAwareAdvisingPostProcessor，可以处理指定的Advisor以此实现@Async的代理，来开启异步
主要属性



属性
说明



annotation
自定义的异步注解，可以用来定制化


proxyTargetClass
是否代理目标类。默认为false，即走jdk代理；为true则用cglib代理


mode
AOP 模式，取值有： PROXY（默认）：使用 Spring 的代理机制 ASPECTJ：使用 AspectJ（需要额外依赖与编译时&#x2F;加载时织入配置）


order
AsyncAnnotationBeanPostProcessor的执行顺序，默认最后才执行


AsyncAnnotationAdvisor​	在AsyncAnnotationBeanPostProcessor#setBeanFactory（bean初始化阶段的一个hook方法，用于给bean填充BeanFactory）中设置的Advisor

public class AsyncAnnotationAdvisor extends AbstractPointcutAdvisor implements BeanFactoryAware {

    private Advice advice;

    private Pointcut pointcut;

    public AsyncAnnotationAdvisor(
            @Nullable Supplier&lt;Executor> executor, @Nullable Supplier&lt;AsyncUncaughtExceptionHandler> exceptionHandler) {

        Set&lt;Class&lt;? extends Annotation>> asyncAnnotationTypes = new LinkedHashSet&lt;>(2);
        // 支持@Async
        asyncAnnotationTypes.add(Async.class);
        try {
            // 也支持EJB的@Asynchronous
            asyncAnnotationTypes.add((Class&lt;? extends Annotation>) ClassUtils.forName("javax.ejb.Asynchronous",
                    AsyncAnnotationAdvisor.class.getClassLoader()));
        } catch (ClassNotFoundException ex) {
            // 类路径里不存在@javax.ejb.Asynchronous，也无所谓
        }
        this.advice = buildAdvice(executor, exceptionHandler);
        this.pointcut = buildPointcut(asyncAnnotationTypes);
    }

    /**
     * 构建异步拦截器 Advice：用于真正执行异步调用逻辑
     */
    protected Advice buildAdvice(
            @Nullable Supplier&lt;Executor> executor, @Nullable Supplier&lt;AsyncUncaughtExceptionHandler> exceptionHandler) {

        AnnotationAsyncExecutionInterceptor interceptor = new AnnotationAsyncExecutionInterceptor(null);
        interceptor.configure(executor, exceptionHandler);
        return interceptor;
    }

    /**
     * 将asyncAnnotationTypes所有注解构造成一个ComposablePointcut，只要class或method上存在任意一个asyncAnnotationType，即可进行代理
     */
    protected Pointcut buildPointcut(Set&lt;Class&lt;? extends Annotation>> asyncAnnotationTypes) {
        ComposablePointcut result = null;
        for (Class&lt;? extends Annotation> asyncAnnotationType : asyncAnnotationTypes) {
            // AnnotationMatchingPointcut是用于注解进行匹配的Pointcut
            // cpc用于class匹配（只要class上存在asyncAnnotationType注解就行）
            Pointcut cpc = new AnnotationMatchingPointcut(asyncAnnotationType, true);
            // mpc用于方法匹配（只要method上存在asyncAnnotationType注解就行）
            Pointcut mpc = new AnnotationMatchingPointcut(null, asyncAnnotationType, true);
            // ComposablePointcut为注解组合，或逻辑。只要内部的ClasaFilter匹配一个就为true。MethodMatcher匹配一个就为true
            if (result == null) {
                result = new ComposablePointcut(cpc);
            } else {
                result.union(cpc);
            }
            result = result.union(mpc);
        }
        return (result != null ? result : Pointcut.TRUE);
    }

}

AnnotationAsyncExecutionInterceptor​	拦截器核心，用于解析指定的执行器，并异步执行目标方法
public class AnnotationAsyncExecutionInterceptor extends AsyncExecutionInterceptor {

    public Object invoke(final MethodInvocation invocation) throws Throwable {
        Class&lt;?> targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);
        Method specificMethod = ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass);
        final Method userDeclaredMethod = BridgeMethodResolver.findBridgedMethod(specificMethod);

        // 根据@Async的value来获取容器中对象的执行器，准备在这个Executor中执行代理逻辑
        AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod);
        if (executor == null) {
            throw new IllegalStateException(
                    "No executor specified and no default executor set on AsyncExecutionInterceptor either");
        }

        // 构建Callable
        Callable&lt;Object> task = () -> {
            try {
                Object result = invocation.proceed();
                if (result instanceof Future) {
                    return ((Future&lt;?>) result).get();
                }
            }
            catch (ExecutionException ex) {
                handleError(ex.getCause(), userDeclaredMethod, invocation.getArguments());
            }
            catch (Throwable ex) {
                handleError(ex, userDeclaredMethod, invocation.getArguments());
            }
            return null;
        };

        // 提交任务到Executor中
        return doSubmit(task, executor, invocation.getMethod().getReturnType());
    }

    /**
     *  可知对于CompletableFuture，ListenableFuture，Future这三种返回值都是支持的，但对于其他返回值都直接返回null了
     */
    protected Object doSubmit(Callable&lt;Object> task, AsyncTaskExecutor executor, Class&lt;?> returnType) {
        if (CompletableFuture.class.isAssignableFrom(returnType)) {
            return CompletableFuture.supplyAsync(() -> {
                try {
                    return task.call();
                }
                catch (Throwable ex) {
                    throw new CompletionException(ex);
                }
            }, executor);
        }
        else if (ListenableFuture.class.isAssignableFrom(returnType)) {
            return ((AsyncListenableTaskExecutor) executor).submitListenable(task);
        }
        else if (Future.class.isAssignableFrom(returnType)) {
            return executor.submit(task);
        }
        else {
            executor.submit(task);
            return null;
        }
    }
}

总结
方法或类上只要存在@Async或@Asynchronous即可走异步
可使用@Async的value字段指定异步线程池（前提是要这个线程池在容器中）
如未指定value，则使用容器中的AsyncConfigurer提供的Executor
如果容器中没有AsyncConfigurer，则使用默认的SimpleAsyncTaskExecutor。其每次execute都会新开一个线程




只支持CompletableFuture，ListenableFuture，Future这三种返回值。其余返回值都直接返回null
异步切面会在这个方法中的所有切面里最先执行（因为其AsyncAnnotationBeanPostProcessor.beforeExistingAdvisors &#x3D; true）

ScheduledAnnotationBeanPostProcessor@EnableScheduling​	向容器中注册ScheduledAnnotationBeanPostProcessor这个BeanDefinition，用于@Schedules和@Scheduled的解析和注册
ScheduledAnnotationBeanPostProcessor核心源码public class ScheduledAnnotationBeanPostProcessor
        implements ScheduledTaskHolder, MergedBeanDefinitionPostProcessor, DestructionAwareBeanPostProcessor,
        Ordered, EmbeddedValueResolverAware, BeanNameAware, BeanFactoryAware, ApplicationContextAware,
        SmartInitializingSingleton, ApplicationListener&lt;ContextRefreshedEvent>, DisposableBean {

    /**
     * bean初始化完成后的hook，只做定时任务的解析和封装，这里并不执行
     */
    public Object postProcessAfterInitialization(Object bean, String beanName) {
        if (bean instanceof AopInfrastructureBean || bean instanceof TaskScheduler ||
                bean instanceof ScheduledExecutorService) {
            // Ignore AOP infrastructure such as scoped proxies.
            return bean;
        }

        Class&lt;?> targetClass = AopProxyUtils.ultimateTargetClass(bean);
        if (!this.nonAnnotatedClasses.contains(targetClass)) {
            // 解析方法上的@Schedules和@Scheduled
            Map&lt;Method, Set&lt;Scheduled>> annotatedMethods = MethodIntrospector.selectMethods(targetClass,
                    (MethodIntrospector.MetadataLookup&lt;Set&lt;Scheduled>>) method -> {
                        Set&lt;Scheduled> scheduledMethods = AnnotatedElementUtils.getMergedRepeatableAnnotations(
                                method, Scheduled.class, Schedules.class);
                        return (!scheduledMethods.isEmpty() ? scheduledMethods : null);
                    });
            if (annotatedMethods.isEmpty()) {
                this.nonAnnotatedClasses.add(targetClass);
            } else {
                // 存在注解，对每个定时任务方法进行处理
                annotatedMethods.forEach((method, scheduledMethods) -> scheduledMethods
                        .forEach(scheduled -> processScheduled(scheduled, method, bean)));
            }
        }
        return bean;
    }

    /**
     * 解析@Scheduled注解，可知其定时字段优先级：cron > fixedDelay > fixedDelayString > fixedRate > fixedRateString
     */
    protected void processScheduled(Scheduled scheduled, Method method, Object bean) {
        try {
            // 将方法封装为可直接运行的Runnable（方法不能有参数）
            Runnable runnable = createRunnable(bean, method);
            // 是否已处理过（一个@Scheduled只能使用一个定时）
            boolean processedSchedule = false;
            String errorMessage = "Exactly one of the 'cron', 'fixedDelay(String)', or 'fixedRate(String)' attributes is required";

            Set&lt;ScheduledTask> tasks = new LinkedHashSet&lt;>(4);

            // 解析初始延时
            long initialDelay = scheduled.initialDelay();
            String initialDelayString = scheduled.initialDelayString();
            if (StringUtils.hasText(initialDelayString)) {
                Assert.isTrue(initialDelay &lt; 0, "Specify 'initialDelay' or 'initialDelayString', not both");
                if (this.embeddedValueResolver != null) {
                    initialDelayString = this.embeddedValueResolver.resolveStringValue(initialDelayString);
                }
                if (StringUtils.hasLength(initialDelayString)) {
                    try {
                        initialDelay = parseDelayAsLong(initialDelayString);
                    } catch (RuntimeException ex) {
                        throw new IllegalArgumentException(
                                "Invalid initialDelayString value \"" + initialDelayString
                                        + "\" - cannot parse into long");
                    }
                }
            }

            // 优先解析cron表达式
            String cron = scheduled.cron();
            if (StringUtils.hasText(cron)) {
                String zone = scheduled.zone();
                if (this.embeddedValueResolver != null) {
                    cron = this.embeddedValueResolver.resolveStringValue(cron);
                    zone = this.embeddedValueResolver.resolveStringValue(zone);
                }
                if (StringUtils.hasLength(cron)) {
                    // 校验cron不支持初始延时
                    Assert.isTrue(initialDelay == -1, "'initialDelay' not supported for cron triggers");
                    processedSchedule = true;
                    if (!Scheduled.CRON_DISABLED.equals(cron)) {
                        TimeZone timeZone;
                        if (StringUtils.hasText(zone)) {
                            timeZone = StringUtils.parseTimeZoneString(zone);
                        } else {
                            timeZone = TimeZone.getDefault();
                        }
                        // 构造为CronTask，先缓存起来
                        tasks.add(this.registrar
                                .scheduleCronTask(new CronTask(runnable, new CronTrigger(cron, timeZone))));
                    }
                }
            }

            if (initialDelay &lt; 0) {
                initialDelay = 0;
            }

            // 解析固定周期
            long fixedDelay = scheduled.fixedDelay();
            if (fixedDelay >= 0) {
                Assert.isTrue(!processedSchedule, errorMessage);
                processedSchedule = true;
                tasks.add(
                        this.registrar.scheduleFixedDelayTask(new FixedDelayTask(runnable, fixedDelay, initialDelay)));
            }
            String fixedDelayString = scheduled.fixedDelayString();
            if (StringUtils.hasText(fixedDelayString)) {
                if (this.embeddedValueResolver != null) {
                    fixedDelayString = this.embeddedValueResolver.resolveStringValue(fixedDelayString);
                }
                if (StringUtils.hasLength(fixedDelayString)) {
                    Assert.isTrue(!processedSchedule, errorMessage);
                    processedSchedule = true;
                    try {
                        fixedDelay = parseDelayAsLong(fixedDelayString);
                    } catch (RuntimeException ex) {
                        throw new IllegalArgumentException(
                                "Invalid fixedDelayString value \"" + fixedDelayString + "\" - cannot parse into long");
                    }
                    // 构造为FixedDelayTask，先缓存起来
                    tasks.add(this.registrar
                            .scheduleFixedDelayTask(new FixedDelayTask(runnable, fixedDelay, initialDelay)));
                }
            }

            // 最后才解析固定频率
            long fixedRate = scheduled.fixedRate();
            if (fixedRate >= 0) {
                Assert.isTrue(!processedSchedule, errorMessage);
                processedSchedule = true;
                tasks.add(this.registrar.scheduleFixedRateTask(new FixedRateTask(runnable, fixedRate, initialDelay)));
            }
            String fixedRateString = scheduled.fixedRateString();
            if (StringUtils.hasText(fixedRateString)) {
                if (this.embeddedValueResolver != null) {
                    fixedRateString = this.embeddedValueResolver.resolveStringValue(fixedRateString);
                }
                if (StringUtils.hasLength(fixedRateString)) {
                    Assert.isTrue(!processedSchedule, errorMessage);
                    processedSchedule = true;
                    try {
                        fixedRate = parseDelayAsLong(fixedRateString);
                    } catch (RuntimeException ex) {
                        throw new IllegalArgumentException(
                                "Invalid fixedRateString value \"" + fixedRateString + "\" - cannot parse into long");
                    }
                    // 构造为FixedRateTask，先缓存起来
                    tasks.add(
                            this.registrar.scheduleFixedRateTask(new FixedRateTask(runnable, fixedRate, initialDelay)));
                }
            }

            // 校验使用了注解的必须有定时任务
            Assert.isTrue(processedSchedule, errorMessage);

            // Finally register the scheduled tasks
            synchronized (this.scheduledTasks) {
                Set&lt;ScheduledTask> regTasks = this.scheduledTasks.computeIfAbsent(bean, key -> new LinkedHashSet&lt;>(4));
                regTasks.addAll(tasks);
            }
        } catch (IllegalArgumentException ex) {
            throw new IllegalStateException(
                    "Encountered invalid @Scheduled method '" + method.getName() + "': " + ex.getMessage());
        }
    }

    /**
     * ContextRefreshed事件，表示容器刷新完毕，可以真正的注册定时任务了
     */
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if (event.getApplicationContext() == this.applicationContext) {
            finishRegistration();
        }
    }

    /**
     * 开始真正的投递定时任务到线程池中。
     * 定时线程池优先级：
     * 1. scheduler
     * 2. TaskScheduler(beanName为taskScheduler) bean
     * 3. 任意TaskScheduler bean
     * 4. ScheduledExecutorService(beanName为taskScheduler) bean
     * 5. 任意ScheduledExecutorService bean
     * 6. ScheduledThreadPoolExecutor（线程数为1）
     */
    private void finishRegistration() {
        if (this.scheduler != null) {
            this.registrar.setScheduler(this.scheduler);
        }

        if (this.beanFactory instanceof ListableBeanFactory) {
            Map&lt;String, SchedulingConfigurer> beans = ((ListableBeanFactory) this.beanFactory)
                    .getBeansOfType(SchedulingConfigurer.class);
            List&lt;SchedulingConfigurer> configurers = new ArrayList&lt;>(beans.values());
            AnnotationAwareOrderComparator.sort(configurers);
            for (SchedulingConfigurer configurer : configurers) {
                configurer.configureTasks(this.registrar);
            }
        }

        if (this.registrar.hasTasks() &amp;&amp; this.registrar.getScheduler() == null) {
            Assert.state(this.beanFactory != null, "BeanFactory must be set to find scheduler by type");
            try {
                // 先获取beanName为taskScheduler的TaskScheduler bean
                this.registrar.setTaskScheduler(resolveSchedulerBean(this.beanFactory, TaskScheduler.class, false));
            } catch (NoUniqueBeanDefinitionException ex) {
                try {
                    // 再按class获取TaskScheduler bean
                    this.registrar.setTaskScheduler(resolveSchedulerBean(this.beanFactory, TaskScheduler.class, true));
                } catch (NoSuchBeanDefinitionException ex2) {

                }
            } catch (NoSuchBeanDefinitionException ex) {
                try {
                    // 再获取beanName为taskScheduler的ScheduledExecutorService bean
                    this.registrar.setScheduler(
                            resolveSchedulerBean(this.beanFactory, ScheduledExecutorService.class, false));
                } catch (NoUniqueBeanDefinitionException ex2) {
                    try {
                        // 再按class获取ScheduledExecutorService bean
                        this.registrar.setScheduler(
                                resolveSchedulerBean(this.beanFactory, ScheduledExecutorService.class, true));
                    } catch (NoSuchBeanDefinitionException ex3) {

                    }
                } catch (NoSuchBeanDefinitionException ex2) {

                }
            }
        }
        // 到这了如果taskScheduler还没有，内部则会创建一个容量为1的ScheduledThreadPoolExecutor去执行定时任务
        // 将bean解析完成的所有定时任务投递到定时任务线程吃
        this.registrar.afterPropertiesSet();
    }

}

总结
bean初始化完成后解析才@Scheduled和@Schedules（只是解析，并不投递），缓存到统一的ScheduledTaskRegistrar中
@Scheduled只能解析为一个定时任务，优先级：
cron
fixedDelay
fixedDelayString
fixedRate
fixedRateString


要定时成多个任务需要使用@Schedules


ContextRefreshedEvent事件触发，开始投递任务
先获取任务定时器，定时线程池优先级：
ScheduledAnnotationBeanPostProcessor#scheduler（只能为TaskScheduler或ScheduledExecutorService的子类）
任意TaskScheduler  bean
TaskScheduler(beanName为taskScheduler)  bean
任意ScheduledExecutorService  bean
ScheduledExecutorService(beanName为taskScheduler)  bean
ScheduledThreadPoolExecutor（线程数为1），即默认线程池


将解析阶段ScheduledTaskRegistrar内缓存的Task都投递到定时线程池中


重点了解下cron，它会被封装为ReschedulingRunnable，每次执行完后才根据cron计算下一次任务的执行时间，这样循环动态的计算执行时间

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
        <tag>Async注解</tag>
        <tag>Scheduled注解</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-ConfigurationClassPostProcessor</title>
    <url>/2021-05-13/spring-configurationclasspostprocessor/</url>
    <content><![CDATA[
​	呕心沥血的分析了ConfigurationClassPostProcessor的核心源码，深入剖析了Spring注解驱动的原理。对其中的延迟机制、字节码解析优化和代理模型进行了深度的思考，并通过arthas反编译反向验证了full configuration的代理




​	是Spring 容器中最重要的 BeanFactoryPostProcessor ，它负责解析并处理大量核心注解，其核心职责是：

统一解析所有来源的组件定义（BeanDefinition），并注册到 BeanFactory 中，为后续 Bean 的实例化做好准备。

其处理过程是递归执行的， 每当发现新的配置类、新的导入组件或扫描结果，它都会再次触发处理，直到不再有新组件为止。也就是说，新解析出的类本身也可能包含注解配置，需要进一步递归处理。



注解
描述



@Configuration
标记一个类为配置类，作为入口被首次处理，并会被标记为 full  配置类。


@ComponentScan
扫描指定包路径下的组件类，将扫描到的 @Component、和元注解中包含 @Component的注解等注册为 BeanDefinition。


@Import
导入外部配置类（普通类、ImportSelector），注册其中定义的 Bean。


@ImportResource
加载 XML 配置文件中的 Bean 定义，与传统的 applicationContext.xml 类似。


@Bean
方法级别的注解，注册方法返回值作为 Bean，由 Spring 容器管理。


@PropertySource
加载外部配置文件（如 .properties），供 @Value 和 Environment 使用。


@Conditional
根据条件决定是否注册当前配置类或 Bean，贯穿上述所有注解的执行过程。


处理BeanDefinitionpublic void processConfigBeanDefinitions(BeanDefinitionRegistry registry) {
    // 收集所有配置类候选项（Full/Lite）
    List&lt;BeanDefinitionHolder> configCandidates = new ArrayList&lt;>();
    String[] candidateNames = registry.getBeanDefinitionNames();

    for (String beanName : candidateNames) {
        BeanDefinition beanDef = registry.getBeanDefinition(beanName);
        // 判断这个BeanDefinition是否已经被处理过（只有被处理过才会设置configurationClass属性）
        if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) ||
                ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) {
            if (logger.isDebugEnabled()) {
                logger.debug("Bean definition has already been processed as a configuration class: " + beanDef);
            }
        }
        /**
         * 判断配置类是full（优先判断）还是lite
         * 
         * full: 类上存在@Configuration元注解
         * 
         * lite: 类上存在@Component，@ComponentScan，@Import，@ImportResource元注解。
         * 或方法上存在@Bean方法注解
         * 
         */
        else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) {
            configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));
        }
    }

    // 没有配置类则立即返回
    if (configCandidates.isEmpty()) {
        return;
    }

    // bean排序（@Order）
    configCandidates.sort((bd1, bd2) -> {
        int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());
        int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());
        return Integer.compare(i1, i2);
    });

    SingletonBeanRegistry sbr = null;
    if (registry instanceof SingletonBeanRegistry) {
        sbr = (SingletonBeanRegistry) registry;
        if (!this.localBeanNameGeneratorSet) {
            BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR);
            if (generator != null) {
                this.componentScanBeanNameGenerator = generator;
                this.importBeanNameGenerator = generator;
            }
        }
    }

    if (this.environment == null) {
        this.environment = new StandardEnvironment();
    }

    // 创建Full和Lite的解析器
    ConfigurationClassParser parser = new ConfigurationClassParser(
            this.metadataReaderFactory, this.problemReporter, this.environment,
            this.resourceLoader, this.componentScanBeanNameGenerator, registry);

    Set&lt;BeanDefinitionHolder> candidates = new LinkedHashSet&lt;>(configCandidates);
    Set&lt;ConfigurationClass> alreadyParsed = new HashSet&lt;>(configCandidates.size());
    do {
        // 解析Full Configuration和Lite Configuration类（会递归解析）
        parser.parse(candidates);
        // 解析完成后的校验（@Configuration类的final校验）
        parser.validate();

        // 获取所有新解析出来的 ConfigurationClass
        Set&lt;ConfigurationClass> configClasses = new LinkedHashSet&lt;>(parser.getConfigurationClasses());
        // 移除已经解析完成的类
        configClasses.removeAll(alreadyParsed);

        // Read the model and create bean definitions based on its content
        if (this.reader == null) {
            this.reader = new ConfigurationClassBeanDefinitionReader(
                    registry, this.sourceExtractor, this.resourceLoader, this.environment,
                    this.importBeanNameGenerator, parser.getImportRegistry());
        }
        // 将解析出来的 ConfigurationClass 转换为真正的 BeanDefinition 注册到容器中
        this.reader.loadBeanDefinitions(configClasses);
        alreadyParsed.addAll(configClasses);

        candidates.clear();
        if (registry.getBeanDefinitionCount() > candidateNames.length) {
            String[] newCandidateNames = registry.getBeanDefinitionNames();
            Set&lt;String> oldCandidateNames = new HashSet&lt;>(Arrays.asList(candidateNames));
            Set&lt;String> alreadyParsedClasses = new HashSet&lt;>();
            for (ConfigurationClass configurationClass : alreadyParsed) {
                alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());
            }
            for (String candidateName : newCandidateNames) {
                if (!oldCandidateNames.contains(candidateName)) {
                    BeanDefinition bd = registry.getBeanDefinition(candidateName);
                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;
                            !alreadyParsedClasses.contains(bd.getBeanClassName())) {
                        candidates.add(new BeanDefinitionHolder(bd, candidateName));
                    }
                }
            }
            candidateNames = newCandidateNames;
        }
    } while (!candidates.isEmpty());

    // // 注册 ImportRegistry 用于支持 ImportAware 的功能
    if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) {
        sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());
    }

    if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) {
        ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();
    }
}

解析BeanDefinitionConfigurationClassParser#doProcessConfigurationClass​	真正解析Configuration Class的工具类（真正的解析上面的核心注解），并实现递归解析
protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)
        throws IOException {

    // 1.如果类包含元注解@Component，则递归处理当前类的所有内部类（包括private的）
    if (configClass.getMetadata().isAnnotated(Component.class.getName())) {
        // Recursively process any member (nested) classes first
        processMemberClasses(configClass, sourceClass);
    }

    // 2.处理 @PropertySource注解
    for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), PropertySources.class,
            org.springframework.context.annotation.PropertySource.class)) {
        if (this.environment instanceof ConfigurableEnvironment) {
            processPropertySource(propertySource);
        } else {
            logger.info("Ignoring @PropertySource annotation on [" + sourceClass.getMetadata().getClassName() +
                    "]. Reason: Environment must implement ConfigurableEnvironment");
        }
    }

    // 3.处理@ComponentScan注解
    Set&lt;AnnotationAttributes> componentScans = AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);
    if (!componentScans.isEmpty() &amp;&amp;
            !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) {
        for (AnnotationAttributes componentScan : componentScans) {
            // 执行 @ComponentScan，扫描
            Set&lt;BeanDefinitionHolder> scannedBeanDefinitions = this.componentScanParser.parse(componentScan,
                    sourceClass.getMetadata().getClassName());
            // 继续检查这些新扫描的出来的BeanDefinition，递归处理
            for (BeanDefinitionHolder holder : scannedBeanDefinitions) {
                BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();
                if (bdCand == null) {
                    bdCand = holder.getBeanDefinition();
                }
                // 递归继续解析新扫描出来的BeanDefinition
                if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) {
                    parse(bdCand.getBeanClassName(), holder.getBeanName());
                }
            }
        }
    }

    // 4.处理@Import注解
    processImports(configClass, sourceClass, getImports(sourceClass), true);

    // 5.处理 @ImportResource注解
    AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(),
            ImportResource.class);
    if (importResource != null) {
        String[] resources = importResource.getStringArray("locations");
        Class&lt;? extends BeanDefinitionReader> readerClass = importResource.getClass("reader");
        for (String resource : resources) {
            String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);
            configClass.addImportedResource(resolvedResource, readerClass);
        }
    }

    // 6.处理有@Bean注解的方法，将这种方法封装为BeanMethod对象并加入beanMethods缓存里，等待后续的处理
    Set&lt;MethodMetadata> beanMethods = retrieveBeanMethodMetadata(sourceClass);
    for (MethodMetadata methodMetadata : beanMethods) {
        configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));
    }

    // 解析配置类实现的接口中的带有@Bean注解的default方法
    processInterfaces(configClass, sourceClass);

    // 处理父类
    if (sourceClass.getMetadata().hasSuperClass()) {
        String superclass = sourceClass.getMetadata().getSuperClassName();
        if (superclass != null &amp;&amp; !superclass.startsWith("java") &amp;&amp;
                !this.knownSuperclasses.containsKey(superclass)) {
            this.knownSuperclasses.put(superclass, configClass);
            // Superclass found, return its annotation metadata and recurse
            return sourceClass.getSuperClass();
        }
    }

    // 没有父类或父类已处理完毕，则这个配置类解析完毕
    return null;
}

1. 内部类处理（递归处理）​	用于处理配置类内部的成员类（例如静态内部类），若其本身也是一个配置类（full 或 lite），则递归进行解析（并使用importStack防止循环依赖解析）。
private void processMemberClasses(ConfigurationClass configClass, SourceClass sourceClass) throws IOException {
    // 获取所有成员类（包括静态/非静态内部类）
    Collection&lt;SourceClass> memberClasses = sourceClass.getMemberClasses();
    if (!memberClasses.isEmpty()) {
        List&lt;SourceClass> candidates = new ArrayList&lt;>(memberClasses.size());
        for (SourceClass memberClass : memberClasses) {
            // 判断该成员类是否是一个有效的配置类（full 或 lite），且不是当前类本身
            if (ConfigurationClassUtils.isConfigurationCandidate(memberClass.getMetadata()) &amp;&amp;
                !memberClass.getMetadata().getClassName().equals(configClass.getMetadata().getClassName())) {
                candidates.add(memberClass);
            }
        }

        // 对候选配置类进行排序，排序依据可能是 @Order 注解或实现 Ordered 接口
        OrderComparator.sort(candidates);

        // 逐个处理符合条件的成员配置类
        for (SourceClass candidate : candidates) {
            // 检查 import 栈中是否存在当前 configClass，防止循环 import 导致死递归
            if (this.importStack.contains(configClass)) {
                this.problemReporter.error(new CircularImportProblem(configClass, this.importStack));
            }
            else {
                // 将当前配置类推入 import 栈，准备递归处理内部类
                this.importStack.push(configClass);
                try {
                    // 将该成员类包装成 ConfigurationClass 并递归处理
                    processConfigurationClass(candidate.asConfigClass(configClass));
                }
                finally {
                    // 处理完成后将当前配置类弹出 import 栈
                    this.importStack.pop();
                }
            }
        }
    }
}

2.  @PropertySource​	将指定的 .properties 配置文件解析并注册到 Spring 的 Environment 中，使配置文件中的属性在应用中可用，并支持如下功能

多路径
编码设置
自定义的 PropertySourceFactory
占位符解析
是否忽略加载失败的配置文件

private void processPropertySource(AnnotationAttributes propertySource) throws IOException {
    String name = propertySource.getString("name");
    if (!StringUtils.hasLength(name)) {
        name = null;
    }

    String encoding = propertySource.getString("encoding");
    if (!StringUtils.hasLength(encoding)) {
        encoding = null;
    }

    // 获取 value 属性（属性文件路径），不能为空
    String[] locations = propertySource.getStringArray("value");
    Assert.isTrue(locations.length > 0, "At least one @PropertySource(value) location is required");

    // 获取是否忽略找不到资源的异常标志
    boolean ignoreResourceNotFound = propertySource.getBoolean("ignoreResourceNotFound");

    // 获取指定的 PropertySourceFactory。默认使用DefaultPropertySourceFactory
    Class&lt;? extends PropertySourceFactory> factoryClass = propertySource.getClass("factory");
    PropertySourceFactory factory = (factoryClass == PropertySourceFactory.class ?
            DEFAULT_PROPERTY_SOURCE_FACTORY : BeanUtils.instantiateClass(factoryClass));

    for (String location : locations) {
        try {
            // 解析占位符（如 ${user.home}/config.properties）
            String resolvedLocation = this.environment.resolveRequiredPlaceholders(location);

            // 加载资源（通常是 classpath 或文件系统路径）
            Resource resource = this.resourceLoader.getResource(resolvedLocation);

            // 使用 factory 解析资源并加入 Environment 的 PropertySources 中
            addPropertySource(factory.createPropertySource(name, new EncodedResource(resource, encoding)));
        }
        catch (IllegalArgumentException | FileNotFoundException | UnknownHostException | SocketException ex) {
            // 根据异常标志判断是否抛异常
            if (ignoreResourceNotFound) {
                if (logger.isInfoEnabled()) {
                    logger.info("Properties location [" + location + "] not resolvable: " + ex.getMessage());
                }
            }
            else {
                throw ex;
            }
        }
    }
}

3. @ComponentScan注解解析ComponentScanAnnotationParser#parse方法解析@ComponentScan注解，为后续的真正扫描做准备
public Set&lt;BeanDefinitionHolder> parse(AnnotationAttributes componentScan, final String declaringClass) {
    // 创建 ClassPathBeanDefinitionScanner（包扫描器）
    // 默认启用 useDefaultFilters，会注册默认过滤器，只扫描 @Component、@ManagedBean、@Named 等组件
    ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(this.registry,
            componentScan.getBoolean("useDefaultFilters"), this.environment, this.resourceLoader);

    // 配置 BeanNameGenerator（用于生成 Bean 的名称）
    Class&lt;? extends BeanNameGenerator> generatorClass = componentScan.getClass("nameGenerator");
    boolean useInheritedGenerator = (BeanNameGenerator.class == generatorClass);
    scanner.setBeanNameGenerator(
            useInheritedGenerator ? this.beanNameGenerator : BeanUtils.instantiateClass(generatorClass));

    // 处理 @Scope 注解代理方式：ScopedProxyMode
    ScopedProxyMode scopedProxyMode = componentScan.getEnum("scopedProxy");
    if (scopedProxyMode != ScopedProxyMode.DEFAULT) {
        scanner.setScopedProxyMode(scopedProxyMode);
    } else {
        Class&lt;? extends ScopeMetadataResolver> resolverClass = componentScan.getClass("scopeResolver");
        scanner.setScopeMetadataResolver(BeanUtils.instantiateClass(resolverClass));
    }

    scanner.setResourcePattern(componentScan.getString("resourcePattern"));

    // 添加 includeFilters（包含过滤器），只匹配指定条件的类
    for (AnnotationAttributes filter : componentScan.getAnnotationArray("includeFilters")) {
        for (TypeFilter typeFilter : typeFiltersFor(filter)) {
            scanner.addIncludeFilter(typeFilter);
        }
    }
    // 添加 excludeFilters（排除过滤器），排除不需要的类
    for (AnnotationAttributes filter : componentScan.getAnnotationArray("excludeFilters")) {
        for (TypeFilter typeFilter : typeFiltersFor(filter)) {
            scanner.addExcludeFilter(typeFilter);
        }
    }

    // 设置默认的懒加载（如果开启，则所有扫描到的 Bean 默认 lazy-init）
    boolean lazyInit = componentScan.getBoolean("lazyInit");
    if (lazyInit) {
        scanner.getBeanDefinitionDefaults().setLazyInit(true);
    }

    Set&lt;String> basePackages = new LinkedHashSet&lt;>();
    String[] basePackagesArray = componentScan.getStringArray("basePackages");
    for (String pkg : basePackagesArray) {
        String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg),
                ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS);
        Collections.addAll(basePackages, tokenized);
    }
    for (Class&lt;?> clazz : componentScan.getClassArray("basePackageClasses")) {
        basePackages.add(ClassUtils.getPackageName(clazz));
    }
    // 如果未显式指定 basePackages，则默认扫描当前配置类所在的包
    if (basePackages.isEmpty()) {
        basePackages.add(ClassUtils.getPackageName(declaringClass));
    }

    // 排除当前class，避免source class的重复解析
    scanner.addExcludeFilter(new AbstractTypeHierarchyTraversingFilter(false, false) {
        @Override
        protected boolean matchClassName(String className) {
            return declaringClass.equals(className);
        }
    });
    // 准备工作完成，开始扫描
    return scanner.doScan(StringUtils.toStringArray(basePackages));
}

扫描​	ClassPathBeanDefinitionScanner类开始真正的扫描包（使用ASM而不是反射，避免无用的Class被JVM加载），并进行一系列的过滤以判断是否该纳入容器中。过滤如下

需要有**@Component、@ManagedBean、@Named**元注解
是具体类（非抽象），或者是抽象类但包含 @Lookup 注解的方法
excludeFilters（黑名单）和includeFilters（白名单）匹配（excludeFilters优先级更高）

protected Set&lt;BeanDefinitionHolder> doScan(String... basePackages) {
    // 至少有1个被扫描的包
    Assert.notEmpty(basePackages, "At least one base package must be specified");
    // 最终BeanDefinitionHolder合集
    Set&lt;BeanDefinitionHolder> beanDefinitions = new LinkedHashSet&lt;>();
    for (String basePackage : basePackages) {
        Set&lt;BeanDefinition> candidates = findCandidateComponents(basePackage);
        for (BeanDefinition candidate : candidates) {
            // 解析 @Scope 作用域元数据（如 singleton、prototype、request 等）
            ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate);
            candidate.setScope(scopeMetadata.getScopeName());
            String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry);
            // 对 AbstractBeanDefinition 进行后处理（如设置懒加载、自动注入模式等）
            if (candidate instanceof AbstractBeanDefinition) {
                postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName);
            }
            // 处理通用注解（@Lazy、@Primary、@DependsOn、@Role、@Description 等）
            if (candidate instanceof AnnotatedBeanDefinition) {
                AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate);
            }
            // 再次检查BeanDefinition，校验是否重复冲突
            if (checkCandidate(beanName, candidate)) {
                BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName);
                // 如果是request、session 等作用域，可能会应用 scoped proxy 代理模式（如 JDK 或 CGLIB）
                definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder,
                        this.registry);
                beanDefinitions.add(definitionHolder);
                // 最终将其注册到 BeanDefinitionRegistry 中（供 Spring 后续实例化使用）
                registerBeanDefinition(definitionHolder, this.registry);
            }
        }
    }
    return beanDefinitions;
}

private Set&lt;BeanDefinition> scanCandidateComponents(String basePackage) {
    Set&lt;BeanDefinition> candidates = new LinkedHashSet&lt;>();
    try {
        // 例如扫描site.shanzhao包 -> classpath*:site/shanzhao/**/*.class
        String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX +
                resolveBasePackage(basePackage) + '/' + this.resourcePattern;
        // 上述指定路径下的每个class文件将被封装成Resource对象并返回
        Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath);
        boolean traceEnabled = logger.isTraceEnabled();
        boolean debugEnabled = logger.isDebugEnabled();
        for (Resource resource : resources) {
            if (traceEnabled) {
                logger.trace("Scanning " + resource);
            }
            if (resource.isReadable()) {
                try {
                    // 不使用反射，使用asm直接将字节码的信息解析出来（包括所有注解（父注解等））
                    MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource);
                    // 对metaData进行判断，是否纳入容器中（@Component、@ManagedBean、@Named判断，@Conditional校验）
                    if (isCandidateComponent(metadataReader)) {
                        ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader);
                        sbd.setSource(resource);
                        // 再次校验是否为合法的候选组件（是具体类（非抽象），或者是抽象类但包含 @Lookup 注解的方法）
                        if (isCandidateComponent(sbd)) {
                            if (debugEnabled) {
                                logger.debug("Identified candidate component class: " + resource);
                            }
                            candidates.add(sbd);
                        } else {
                            if (debugEnabled) {
                                logger.debug("Ignored because not a concrete top-level class: " + resource);
                            }
                        }
                    } else {
                        if (traceEnabled) {
                            logger.trace("Ignored because not matching any filter: " + resource);
                        }
                    }
                } catch (Throwable ex) {
                    throw new BeanDefinitionStoreException(
                            "Failed to read candidate component class: " + resource, ex);
                }
            } else {
                if (traceEnabled) {
                    logger.trace("Ignored because not readable: " + resource);
                }
            }
        }
    } catch (IOException ex) {
        throw new BeanDefinitionStoreException("I/O failure during classpath scanning", ex);
    }
    return candidates;
}

递归​	对上述返回的Set集合BeanDefinitionHolder继续full或lite判断，并递归解析其所有的导入情况
// 继续检查这些新扫描的出来的BeanDefinition，递归处理
for (BeanDefinitionHolder holder : scannedBeanDefinitions) {
    BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();
    if (bdCand == null) {
        bdCand = holder.getBeanDefinition();
    }
    // 递归继续解析新扫描出来的BeanDefinition
    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) {
        parse(bdCand.getBeanClassName(), holder.getBeanName());
    }
}

4. @Import​	处理 @Import 注解导入的配置类，是一种显式导入配置类或组件的机制。其相比@ComponentScan，这个注解更轻量和有针对性。它包括以下三类情况

ImportSelector（DeferredImportSelector 是其延迟版本，会在所有配置类处理完后统一处理，常用于 Spring Boot 自动配置机制）： 动态返回要导入的类名（递归）
ImportBeanDefinitionRegistrar ：手动注册 BeanDefinition（不会递归）
普通类 ：按照配置类继续解析（递归）

private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass,
        Collection&lt;SourceClass> importCandidates, boolean checkForCircularImports) {

    if (importCandidates.isEmpty()) { // @Import导入为空，就直接返回
        return;
    }

    // 检查是否存在循环导入链，例如 A -> B -> C -> A
    if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) {
        this.problemReporter.error(new CircularImportProblem(configClass, this.importStack));
    } else {
        // 压栈当前 configClass，防止循环引用
        this.importStack.push(configClass);
        try {
            for (SourceClass candidate : importCandidates) {
                // ImportSelector解析（会循环解析）
                if (candidate.isAssignable(ImportSelector.class)) {
                    Class&lt;?> candidateClass = candidate.loadClass();
                    ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class);
                    // aware注入
                    ParserStrategyUtils.invokeAwareMethods(
                            selector, this.environment, this.resourceLoader, this.registry);
                    if (selector instanceof DeferredImportSelector) { // DeferredImportSelector暂不处理（Spring boot用到）
                        this.deferredImportSelectorHandler.handle(configClass, (DeferredImportSelector) selector);
                    } else {
                        // 普通 ImportSelector 立即执行 selectImports() 获取要导入的类名数组
                        String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata());
                        Collection&lt;SourceClass> importSourceClasses = asSourceClasses(importClassNames);
                        // 递归解析新导入的类
                        processImports(configClass, currentSourceClass, importSourceClasses, false);
                    }
                }
                // ImportBeanDefinitionRegistrar解析
                // 不会递归，因为这个接口已经给了BeanDefinitionRegistry，就是让你自由发挥注册BeanDefinition的
                else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) {
                    // Candidate class is an ImportBeanDefinitionRegistrar ->
                    // delegate to it to register additional bean definitions
                    Class&lt;?> candidateClass = candidate.loadClass();
                    ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass,
                            ImportBeanDefinitionRegistrar.class);
                    ParserStrategyUtils.invokeAwareMethods(
                            registrar, this.environment, this.resourceLoader, this.registry);
                    // 将 registrar 注册到当前配置类中，后续统一调用
                    configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata());
                } else {

                    // 其他类型的类（即非 ImportSelector / ImportBeanDefinitionRegistrar）
                    // 作为普通的 @Configuration 类进行解析处理（可能再次触发 @Import）
                    this.importStack.registerImport(
                            currentSourceClass.getMetadata(), candidate.getMetadata().getClassName());
                    processConfigurationClass(candidate.asConfigClass(configClass));
                }
            }
        } catch (BeanDefinitionStoreException ex) {
            throw ex;
        } catch (Throwable ex) {
            throw new BeanDefinitionStoreException(
                    "Failed to process import candidates for configuration class [" +
                            configClass.getMetadata().getClassName() + "]",
                    ex);
        } finally {
            // 解析完成后出栈
            this.importStack.pop();
        }
    }
}

public void handle(ConfigurationClass configClass, DeferredImportSelector importSelector) {
    DeferredImportSelectorHolder holder = new DeferredImportSelectorHolder(configClass, importSelector);
    if (this.deferredImportSelectors == null) {
        // deferredImportSelectors 为 null，说明当前不是“延迟批量处理阶段”，而是递归触发时遇到的
        // DeferredImportSelector
        // 此时直接单独处理当前这个 DeferredImportSelector，不等到后面统一处理
        DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler();
        handler.register(holder);
        handler.processGroupImports();
    } else {
        // deferredImportSelectors 不为 null，说明当前处于“延迟导入收集阶段”，此时仅将当前 holder 暂存下来，后续由
        // ConfigurationClassParser#process 统一处理
        this.deferredImportSelectors.add(holder);
    }
}

5. @ImportResource解析​	解析@ImportResource，将解析后得到的数据缓存到ConfigurationClass#importedResources中，等待后续注册BeanDefinition使用
AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);
if (importResource != null) {
    String[] resources = importResource.getStringArray("locations");
    Class&lt;? extends BeanDefinitionReader> readerClass = importResource.getClass("reader");
    for (String resource : resources) {
        String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);
        configClass.addImportedResource(resolvedResource, readerClass);
    }
}

6. @Bean解析​	@Bean注解的解析和缓存，主要步骤总结：

使用 ASM 而非反射：通过 ASM 读取类字节码，获取所有 @Bean 方法的有序列表，避免 JVM 反射 API 导致的无序行为
封装为 BeanMethod：每个方法会被抽象为 BeanMethod（包含方法元信息和所属配置类引用）。
缓存到 ConfigurationClass：最终这些 BeanMethod 会被缓存到 ConfigurationClass#beanMethods 集合中，等到配置类加载完成后由 ConfigurationClassBeanDefinitionReader 注册为真正的 BeanDefinition。

private Set&lt;MethodMetadata> retrieveBeanMethodMetadata(SourceClass sourceClass) {
    AnnotationMetadata original = sourceClass.getMetadata();
    Set&lt;MethodMetadata> beanMethods = original.getAnnotatedMethods(Bean.class.getName());
    // 如果 Bean 方法数量大于1 且使用的是基于反射的元数据，尝试使用 ASM 获取确定顺序
    if (beanMethods.size() > 1 &amp;&amp; original instanceof StandardAnnotationMetadata) {
        try {
            // 使用 ASM 从 class 文件中获取元数据（包括方法顺序）
            AnnotationMetadata asm = this.metadataReaderFactory.getMetadataReader(original.getClassName())
                    .getAnnotationMetadata();
            Set&lt;MethodMetadata> asmMethods = asm.getAnnotatedMethods(Bean.class.getName());
            // 若 ASM 获取的 @Bean 方法数量 >= 反射获取的，且名字匹配，则使用 ASM 顺序
            if (asmMethods.size() >= beanMethods.size()) {
                Set&lt;MethodMetadata> selectedMethods = new LinkedHashSet&lt;>(asmMethods.size());
                for (MethodMetadata asmMethod : asmMethods) {
                    for (MethodMetadata beanMethod : beanMethods) {
                        if (beanMethod.getMethodName().equals(asmMethod.getMethodName())) {
                            // 保留反射对象，但按 ASM 顺序排列
                            selectedMethods.add(beanMethod);
                            break;
                        }
                    }
                }
                // 如果反射获取的所有方法都在 ASM 中找到，则使用 ASM 顺序
                if (selectedMethods.size() == beanMethods.size()) {
                    // All reflection-detected methods found in ASM method set -> proceed
                    beanMethods = selectedMethods;
                }
            }
        } catch (IOException ex) {
            logger.debug("Failed to read class file via ASM for determining @Bean method order", ex);
            // 忽略异常，降级使用反射获取的 Bean 方法集合，虽然顺序不稳定，但逻辑不受影响
        }
    }
    return beanMethods;
}

注册BeanDefinitionConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForConfigurationClassprivate void loadBeanDefinitionsForConfigurationClass(
        ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) {

    // @Conditional注解判断（OnBeanCondition会在这发挥作用）
    if (trackedConditionEvaluator.shouldSkip(configClass)) {
        // 若被跳过且之前已注册过 beanDefinition，则将其移除
        String beanName = configClass.getBeanName();
        if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) {
            this.registry.removeBeanDefinition(beanName);
        }
        this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());
        return;
    }

    // 如果是被 @Import 导入的配置类，注册为一个 beanDefinition
    if (configClass.isImported()) {
        registerBeanDefinitionForImportedConfigurationClass(configClass);
    }
    // 加载@Bean注解方法的BeanDefinition，并设置使用工厂方法构造
    for (BeanMethod beanMethod : configClass.getBeanMethods()) {
        loadBeanDefinitionsForBeanMethod(beanMethod);
    }

    // 处理 @ImportResource 注解导入的 XML 配置文件，注册其中定义的 bean
    loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());
    // @Import注解(ImportBeanDefinitionRegistrar)的结果注册bean
    loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());
}

@Bean注册​	真正将@Bean方法抽象为ConfigurationClassBeanDefinition并注册到容器中，主要步骤总结：

条件匹配判断：若 @Bean 方法上存在 @Conditional，需判断是否应跳过注册
确定 Bean 名称与别名
构建 BeanDefinition：将方法封装为 ConfigurationClassBeanDefinition，并设置元数据、作用域、初始化和销毁方法、autowire 策略等属性
区分方法类型调用方式
静态方法：无需依赖配置类实例，直接通过类调用工厂方法。
实例方法：需要通过配置类的 Bean 实例来调用方法（即依赖于配置类自身作为 FactoryBean）。


作用域代理支持：若存在 @Scope(proxyMode = ...)，则通过 ScopedProxyCreator 构造代理 BeanDefinition
注册 BeanDefinition 到容器中：最终调用 registry.registerBeanDefinition() 完成注册。

private void loadBeanDefinitionsForBeanMethod(BeanMethod beanMethod) {
    ConfigurationClass configClass = beanMethod.getConfigurationClass();
    MethodMetadata metadata = beanMethod.getMetadata();
    String methodName = metadata.getMethodName();

    // @Conditional注解判断是否该跳过
    if (this.conditionEvaluator.shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN)) {
        configClass.skippedBeanMethods.add(methodName);
        return;
    }
    if (configClass.skippedBeanMethods.contains(methodName)) {
        return;
    }

    AnnotationAttributes bean = AnnotationConfigUtils.attributesFor(metadata, Bean.class);
    Assert.state(bean != null, "No @Bean annotation attributes");

    List&lt;String> names = new ArrayList&lt;>(Arrays.asList(bean.getStringArray("name")));
    String beanName = (!names.isEmpty() ? names.remove(0) : methodName);

    for (String alias : names) {
        this.registry.registerAlias(beanName, alias);
    }

    // 检查是否存在覆盖（例如 XML ），再根据beanName判断是否抛异常
    if (isOverriddenByExistingDefinition(beanMethod, beanName)) {
        if (beanName.equals(beanMethod.getConfigurationClass().getBeanName())) {
            throw new BeanDefinitionStoreException(beanMethod.getConfigurationClass().getResource().getDescription(),
                    beanName, "Bean name derived from @Bean method '" + beanMethod.getMetadata().getMethodName() +
                            "' clashes with bean name for containing configuration class; please make those names unique!");
        }
        return;
    }

    // 构建 BeanDefinition，封装元信息
    ConfigurationClassBeanDefinition beanDef = new ConfigurationClassBeanDefinition(configClass, metadata);
    beanDef.setSource(this.sourceExtractor.extractSource(metadata, configClass.getResource()));

    // 使用工厂模式实例化bean：静态方法 or 实例方法
    if (metadata.isStatic()) {
        // 静态方法直接使用class对象调用
        beanDef.setBeanClassName(configClass.getMetadata().getClassName());
        beanDef.setFactoryMethodName(methodName);
    } else { // 实例方法要使用FactoryBean对象调用
        beanDef.setFactoryBeanName(configClass.getBeanName());
        beanDef.setUniqueFactoryMethodName(methodName);
    }
    // 设置自动装配模式为构造器注入
    beanDef.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_CONSTRUCTOR);
    beanDef.setAttribute(
            org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor.SKIP_REQUIRED_CHECK_ATTRIBUTE,
            Boolean.TRUE);

    // @Bean方法上的常用注解解析@Lazy等等
    AnnotationConfigUtils.processCommonDefinitionAnnotations(beanDef, metadata);

    Autowire autowire = bean.getEnum("autowire");
    if (autowire.isAutowire()) {
        beanDef.setAutowireMode(autowire.value());
    }

    boolean autowireCandidate = bean.getBoolean("autowireCandidate");
    if (!autowireCandidate) {
        beanDef.setAutowireCandidate(false);
    }

    String initMethodName = bean.getString("initMethod");
    if (StringUtils.hasText(initMethodName)) {
        beanDef.setInitMethodName(initMethodName);
    }

    String destroyMethodName = bean.getString("destroyMethod");
    beanDef.setDestroyMethodName(destroyMethodName);

    ScopedProxyMode proxyMode = ScopedProxyMode.NO;
    AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(metadata, Scope.class);
    if (attributes != null) {
        beanDef.setScope(attributes.getString("value"));
        proxyMode = attributes.getEnum("proxyMode");
        // 默认就为No
        if (proxyMode == ScopedProxyMode.DEFAULT) {
            proxyMode = ScopedProxyMode.NO;
        }
    }

    // 若需要作用域代理（如 request-scoped Bean），则创建代理 BeanDefinition
    BeanDefinition beanDefToRegister = beanDef;
    if (proxyMode != ScopedProxyMode.NO) {
        BeanDefinitionHolder proxyDef = ScopedProxyCreator.createScopedProxy(
                new BeanDefinitionHolder(beanDef, beanName), this.registry,
                proxyMode == ScopedProxyMode.TARGET_CLASS);
        beanDefToRegister = new ConfigurationClassBeanDefinition(
                (RootBeanDefinition) proxyDef.getBeanDefinition(), configClass, metadata);
    }

    if (logger.isTraceEnabled()) {
        logger.trace(String.format("Registering bean definition for @Bean method %s.%s()",
                configClass.getMetadata().getClassName(), beanName));
    }
    // 最终注册 BeanDefinition
    this.registry.registerBeanDefinition(beanName, beanDefToRegister);
}

代理Full Configurationpublic void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) {
    // 记录所有需要增强的配置类
    Map&lt;String, AbstractBeanDefinition> configBeanDefs = new LinkedHashMap&lt;>();
    for (String beanName : beanFactory.getBeanDefinitionNames()) {
        BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName);
        // @Configuration类才会被增强（即full configuration class）
        if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) {
            // 必须是 AbstractBeanDefinition 类型，否则无法增强（不支持自定义 BeanDefinition 实现）
            if (!(beanDef instanceof AbstractBeanDefinition)) {
                throw new BeanDefinitionStoreException("Cannot enhance @Configuration bean definition '" +
                        beanName + "' since it is not stored in an AbstractBeanDefinition subclass");
            } else if (logger.isInfoEnabled() &amp;&amp; beanFactory.containsSingleton(beanName)) {
                // 如果这个 @Configuration Bean 已经被提前实例化，则无法再增强，打印警告日志
                // 这种情况通常发生在某些早期调用触发了配置类的提前加载，比如BeanDefinitionRegistryPostProcessor这类bean
                logger.info("Cannot enhance @Configuration bean definition '" + beanName +
                        "' since its singleton instance has been created too early. The typical cause " +
                        "is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor " +
                        "return type: Consider declaring such methods as 'static'.");
            }
            configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef);
        }
    }
    if (configBeanDefs.isEmpty()) {
        // 无full则直接返回
        return;
    }

    // 创建配置类增强器
    ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer();
    for (Map.Entry&lt;String, AbstractBeanDefinition> entry : configBeanDefs.entrySet()) {
        AbstractBeanDefinition beanDef = entry.getValue();
        beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE);
        try {
            Class&lt;?> configClass = beanDef.resolveBeanClass(this.beanClassLoader);
            if (configClass != null) {
                // 使用ConfigurationClassEnhancer开始增强
                Class&lt;?> enhancedClass = enhancer.enhance(configClass, this.beanClassLoader);
                // 如果增强成功（即 class 被改动了），则更新 beanDefinition 中的 beanClass，用增强后的class来实例化这个bean，而抛弃原class
                if (configClass != enhancedClass) {
                    beanDef.setBeanClass(enhancedClass);
                }
            }
        } catch (Throwable ex) {
            throw new IllegalStateException("Cannot load configuration class: " + beanDef.getBeanClassName(), ex);
        }
    }
}

ConfigurationClassEnhancer增强class// 方法拦截器
private static final Callback[] CALLBACKS = new Callback[] {
        new BeanMethodInterceptor(), // @Bean方法拦截器
        new BeanFactoryAwareMethodInterceptor(), // setBeanFactory方法拦截器
        NoOp.INSTANCE
};

// 方法拦截器的匹配器，用于匹配class中的具体方法该使用上诉的某个具体拦截器
private static final ConditionalCallbackFilter CALLBACK_FILTER = new ConditionalCallbackFilter(CALLBACKS);

// 增强类内部新增的字段名（类型为BeanFactory）
private static final String BEAN_FACTORY_FIELD = "$$beanFactory";

/**
 * 增强后的@Configuration类会实现此接口，既是一种标记，也具备注入BeanFactory的能力
 */
public interface EnhancedConfiguration extends BeanFactoryAware {
}

public Class&lt;?> enhance(Class&lt;?> configClass, @Nullable ClassLoader classLoader) {
    // 判断是否实现了EnhancedConfiguration接口，以此来判断是否已经增强
    if (EnhancedConfiguration.class.isAssignableFrom(configClass)) {
        if (logger.isDebugEnabled()) {
            logger.debug(String.format("Ignoring request to enhance %s as it has " +
                    "already been enhanced. This usually indicates that more than one " +
                    "ConfigurationClassPostProcessor has been registered (e.g. via " +
                    "&lt;context:annotation-config>). This is harmless, but you may " +
                    "want check your configuration and remove one CCPP if possible",
                    configClass.getName()));
        }
        return configClass;
    }
    // 开始增强
    Class&lt;?> enhancedClass = createClass(newEnhancer(configClass, classLoader));
    return enhancedClass;
}

/**
 * 创建CGLIB Enhancer对象并配置参数
 */
private Enhancer newEnhancer(Class&lt;?> configSuperClass, @Nullable ClassLoader classLoader) {
    Enhancer enhancer = new Enhancer();
    enhancer.setSuperclass(configSuperClass);
    // 设置EnhancedConfiguration接口，这个也实现了BeanFactoryAware接口
    // 这样才能获得BeanFactory，让@Bean方法间的调用结果先从BeanFactory中取，维持单例
    enhancer.setInterfaces(new Class&lt;?>[] { EnhancedConfiguration.class });
    enhancer.setUseFactory(false);
    enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);
    // 自定义生成策略，注入BeanFactory字段（字段名就是$$beanFactory）
    enhancer.setStrategy(new BeanFactoryAwareGeneratorStrategy(classLoader));
    // 设置拦截器（@Bean方法拦截器和BeanFactoryAware接口里的setBeanFactory方法拦截器）
    enhancer.setCallbackFilter(CALLBACK_FILTER);
    enhancer.setCallbackTypes(CALLBACK_FILTER.getCallbackTypes());
    return enhancer;
}

BeanMethodInterceptor​	根据其isMatch方法可知其是一个专用于拦截 @Bean 方法调用的 CGLIB 方法拦截器，主要解决了以下两个问题：


避免每次调用 @Bean 方法都重复创建 bean 实例
支持 @Bean 方法之间的依赖注入（即方法之间互调不再是直接 new，而是走容器获取）


核心执行流程
获取BeanFactoryAwareMethodInterceptor设置的BeanFactory
FactoryBean特殊处理
判断是否是工厂方法正在被调用（即二次调用）：是为避免通过 getBean(beanName) 自身递归调用，必须直接调用原始方法体（即 super）执行实例化逻辑
根据方法的参数，利用BeanFactory真正获取bean（使用的是sourceClass的工厂方法进行实例化）

核心源码private static class BeanMethodInterceptor implements MethodInterceptor, ConditionalCallback {

    @Override
    @Nullable
    public Object intercept(Object enhancedConfigInstance, Method beanMethod, Object[] beanMethodArgs,
            MethodProxy cglibMethodProxy) throws Throwable {

        // 获取 BeanFactory 实例（通过代理类中的字段注入）
        ConfigurableBeanFactory beanFactory = getBeanFactory(enhancedConfigInstance);
        String beanName = BeanAnnotationHelper.determineBeanNameFor(beanMethod);

        // 若是作用域代理（如 @Scope(proxyMode = TARGET_CLASS)），需要特殊处理
        if (BeanAnnotationHelper.isScopedProxy(beanMethod)) {
            String scopedBeanName = ScopedProxyCreator.getTargetBeanName(beanName);
            if (beanFactory.isCurrentlyInCreation(scopedBeanName)) {
                beanName = scopedBeanName;
            }
        }

        // 处理 FactoryBean 的特殊情况
        if (factoryContainsBean(beanFactory, BeanFactory.FACTORY_BEAN_PREFIX + beanName) &amp;&amp;
                factoryContainsBean(beanFactory, beanName)) {
            Object factoryBean = beanFactory.getBean(BeanFactory.FACTORY_BEAN_PREFIX + beanName);
            if (factoryBean instanceof ScopedProxyFactoryBean) {
                // Scoped proxy factory beans are a special case and should not be further
                // proxied
            } else {
                // It is a candidate FactoryBean - go ahead with enhancement
                return enhanceFactoryBean(factoryBean, beanMethod.getReturnType(), beanFactory, beanName);
            }
        }

        // 很重要
        // 判断当前是否正在通过本方法实例化 bean；如果是，为避免递归代理，直接执行原始方法体（super）创建实例
        if (isCurrentlyInvokedFactoryMethod(beanMethod)) {
            if (logger.isInfoEnabled() &amp;&amp;
                    BeanFactoryPostProcessor.class.isAssignableFrom(beanMethod.getReturnType())) {
                logger.info(String.format("@Bean method %s.%s is non-static and returns an object " +
                        "assignable to Spring's BeanFactoryPostProcessor interface. This will " +
                        "result in a failure to process annotations such as @Autowired, " +
                        "@Resource and @PostConstruct within the method's declaring " +
                        "@Configuration class. Add the 'static' modifier to this method to avoid " +
                        "these container lifecycle issues; see @Bean javadoc for complete details.",
                        beanMethod.getDeclaringClass().getSimpleName(), beanMethod.getName()));
            }
            return cglibMethodProxy.invokeSuper(enhancedConfigInstance, beanMethodArgs);
        }

        // 从 BeanFactory 中解析目标 Bean 的引用，必要时传递参数
        return resolveBeanReference(beanMethod, beanMethodArgs, beanFactory, beanName);
    }

    private Object resolveBeanReference(Method beanMethod, Object[] beanMethodArgs,
            ConfigurableBeanFactory beanFactory, String beanName) {

        boolean alreadyInCreation = beanFactory.isCurrentlyInCreation(beanName);
        try {
            // 防止循环依赖死锁：临时将当前 bean 标记为非创建中
            if (alreadyInCreation) {
                beanFactory.setCurrentlyInCreation(beanName, false);
            }
            boolean useArgs = !ObjectUtils.isEmpty(beanMethodArgs);
            if (useArgs &amp;&amp; beanFactory.isSingleton(beanName)) {
                for (Object arg : beanMethodArgs) {
                    if (arg == null) {
                        useArgs = false;
                        break;
                    }
                }
            }
            // 根据参数从容器中获取 Bean
            Object beanInstance = (useArgs ? beanFactory.getBean(beanName, beanMethodArgs)
                    : beanFactory.getBean(beanName));
            // 返回值不匹配，需要抛出异常
            if (!ClassUtils.isAssignableValue(beanMethod.getReturnType(), beanInstance)) {
                // 兼容处理 Spring 的 NullBean
                if (beanInstance.equals(null)) {
                    if (logger.isDebugEnabled()) {
                        logger.debug(String.format("@Bean method %s.%s called as bean reference " +
                                "for type [%s] returned null bean; resolving to null value.",
                                beanMethod.getDeclaringClass().getSimpleName(), beanMethod.getName(),
                                beanMethod.getReturnType().getName()));
                    }
                    beanInstance = null;
                } else {
                    // 不为空抛异常
                    String msg = String.format("@Bean method %s.%s called as bean reference " +
                            "for type [%s] but overridden by non-compatible bean instance of type [%s].",
                            beanMethod.getDeclaringClass().getSimpleName(), beanMethod.getName(),
                            beanMethod.getReturnType().getName(), beanInstance.getClass().getName());
                    try {
                        BeanDefinition beanDefinition = beanFactory.getMergedBeanDefinition(beanName);
                        msg += " Overriding bean of same name declared in: " + beanDefinition.getResourceDescription();
                    } catch (NoSuchBeanDefinitionException ex) {
                    }
                    throw new IllegalStateException(msg);
                }
            }
            // 最后再注册依赖关系：当前 bean 被哪个外部工厂方法创建
            Method currentlyInvoked = SimpleInstantiationStrategy.getCurrentlyInvokedFactoryMethod();
            if (currentlyInvoked != null) {
                String outerBeanName = BeanAnnotationHelper.determineBeanNameFor(currentlyInvoked);
                beanFactory.registerDependentBean(beanName, outerBeanName);
            }
            return beanInstance;
        } finally {
            if (alreadyInCreation) {
                beanFactory.setCurrentlyInCreation(beanName, true);
            }
        }
    }

}

BeanFactoryAwareMethodInterceptor​	主要的作用是填充$$beanFactory字段
private static class BeanFactoryAwareMethodInterceptor implements MethodInterceptor, ConditionalCallback {

    @Override
    @Nullable
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        Field field = ReflectionUtils.findField(obj.getClass(), BEAN_FACTORY_FIELD);
        Assert.state(field != null, "Unable to find generated BeanFactory field");
        // 将BeanFactoryAware接口传来的BeanFactory实例设置到内部新增的$$beanFactory字段上
        field.set(obj, args[0]);

        // 判断SourceClass是否实现了BeanFactoryAware接口。如果也实现了，则再调用其setBeanFactory方法，将BeanFactory实例设置进去
        if (BeanFactoryAware.class.isAssignableFrom(ClassUtils.getUserClass(obj.getClass().getSuperclass()))) {
            return proxy.invokeSuper(obj, args);
        }
        return null;
    }

    @Override
    public boolean isMatch(Method candidateMethod) {
        return isSetBeanFactory(candidateMethod);
    }

    public static boolean isSetBeanFactory(Method candidateMethod) {
        return (candidateMethod.getName().equals("setBeanFactory") &amp;&amp;
                candidateMethod.getParameterCount() == 1 &amp;&amp;
                BeanFactory.class == candidateMethod.getParameterTypes()[0] &amp;&amp;
                BeanFactoryAware.class.isAssignableFrom(candidateMethod.getDeclaringClass()));
    }
}

arthas反向验证full class demo@Configuration
public class ConfigurationClassDemo {
    @Bean(initMethod = "initMethod")
    public A beanA() {
        return new A();
    }
    @Bean(initMethod = "initMethod")
    public B beanB() {
        Assert.isTrue(beanA() == beanA(), "impossible error");
        return new B();
    }
    public static class A {
        public void initMethod() {
            System.out.println("bean A initialized");
        }
    }
    public static class B {
        public void initMethod() {
            System.out.println("bean B initialized");
        }
    }
}

arthas反编译后只保留了关键代码，从反编译后的源码可进行上诉源码分析的验证：

实现了ConfigurationClassEnhancer.EnhancedConfiguration接口
cglib代理，继承了原class
@Bean方法走的是CGLIB$CALLBACK_0，即BeanMethodInterceptor
setBeanFactory方法走的是CGLIB$CALLBACK_1，即BeanFactoryAwareMethodInterceptor
存在新增的$$beanFactory这个BeanFactory字段

public class ConfigurationClassDemo$$EnhancerBySpringCGLIB$$988746da
extends ConfigurationClassDemo
implements ConfigurationClassEnhancer.EnhancedConfiguration {
    // BeanMethodInterceptor
    private MethodInterceptor CGLIB$CALLBACK_0;
    // BeanFactoryAwareMethodInterceptor
    private MethodInterceptor CGLIB$CALLBACK_1;
    private NoOp CGLIB$CALLBACK_2;
    public BeanFactory $$beanFactory;



    public final ConfigurationClassDemo.B beanB() {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_0;
        if (methodInterceptor == null) {
            ConfigurationClassDemo$$EnhancerBySpringCGLIB$$988746da.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_0;
        }
        if (methodInterceptor != null) {
            return (ConfigurationClassDemo.B)methodInterceptor.intercept(this, CGLIB$beanB$0$Method, CGLIB$emptyArgs, CGLIB$beanB$0$Proxy);
        }
        return super.beanB();
    }

    public final ConfigurationClassDemo.A beanA() {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_0;
        if (methodInterceptor == null) {
            ConfigurationClassDemo$$EnhancerBySpringCGLIB$$988746da.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_0;
        }
        if (methodInterceptor != null) {
            return (ConfigurationClassDemo.A)methodInterceptor.intercept(this, CGLIB$beanA$1$Method, CGLIB$emptyArgs, CGLIB$beanA$1$Proxy);
        }
        return super.beanA();
    }


    @Override
    public final void setBeanFactory(BeanFactory beanFactory) throws BeansException {
        MethodInterceptor methodInterceptor = this.CGLIB$CALLBACK_1;
        if (methodInterceptor == null) {
            ConfigurationClassDemo$$EnhancerBySpringCGLIB$$988746da.CGLIB$BIND_CALLBACKS(this);
            methodInterceptor = this.CGLIB$CALLBACK_1;
        }
        if (methodInterceptor != null) {
            Object object = methodInterceptor.intercept(this, CGLIB$setBeanFactory$6$Method, new Object[]{beanFactory}, CGLIB$setBeanFactory$6$Proxy);
            return;
        }
        super.setBeanFactory(beanFactory);
    }

}


总结
通过增强 Full 模式的 @Configuration 类，确保 @Bean 方法之间的调用不会绕过容器，而是始终返回容器中管理的单例 Bean，避免出现多个实例
通过 BeanFactoryAwareMethodInterceptor 拦截器，使增强类持有 BeanFactory 的引用，为后续拦截器中从容器获取 Bean 提供支持
通过 BeanMethodInterceptor 拦截器，拦截所有 @Bean 方法调用，并通过 BeanFactory 获取对应 Bean，从而确保每次调用返回的都是同一个（单例）实例

总之，Full 模式的增强本质上是让配置类自身也成为容器管理的入口，避免“Java 方法调用”破坏了 Spring 的生命周期和作用域控制
最后​	通过整体的源码分析，可知ConfigurationClassPostProcessor是Spring注解驱动的核心，其内部的延迟机制、字节码解析优化和代理模型，是 Spring 保持灵活与健壮性的体现。 最后我再总结以下几个核心的问题
ASM的使用
@ComponentScan 扫描 class 文件时，使用 ASM 而不是反射 来提取类的元数据
ASM 更高效，不会触发类的加载，避免了对未来可能不会用到的类进行 JVM 加载。
此阶段 Spring 尚未确定是否要注册这些类为 Bean，因此避免使用反射是出于性能和安全性的双重考量。


@Bean 方法也通过 ASM 解析为 MethodMetadata 对象：
反射获取的方法列表顺序是不确定的，使用 ASM 能保留 @Bean 方法在 .class 文件中的定义顺序



DeferredImportSelector的作用​	顾名思义，和延迟相关。是SpringBoot中自动配置的关键，确保了优先解析当前项目中所有的BeanDefinition，以达到覆盖SpringBoot中提供的默认Bean（比如，项目中配置了DataSource的BeanDefinition，这样Springboot提供的DataSourceAutoConfiguration中的DataSource则不会生效）	
full configration class的增强​	和lite configration class唯一的区别，就是full会被cglib增强，确保@Bean方法始终返回单例bean。所以，可以得出结论，如果配置类不使用 @Bean 方法，只做组件聚合，建议使用 @Component 而非 @Configuration，可节省 CGLIB 增强开销
@Bean方法拦截获取bean如何避免循环调用​	full中@Bean方法会走代理，代理内部会用BeanFactory.getBean()来真正获取bean，获取bean时最终又会走到@Bean代理方法。不怕死循环吗？
​	其实不用担心，BeanFactory.getBean()来真正获取bean是用工厂方法来创建实例的，调用时会将此方法保存在当前线程的ThreadLocal里（SimpleInstantiationStrategy.currentlyInvokedFactoryMethod字段）。再第二次进入代理时会检查当前方法是否就是调用栈顶部的那个工厂方法，如果是，则绕开代理直接调用 super 方法生成实例。 这一机制确保了代理与容器实例化流程之间协同工作，不会引发死循环
其它链接
DeferedImportSelector的实现与处理逻辑
Condition的实现与处理流程

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>BeanPostProcessor</tag>
        <tag>BeanDefinitionRegistryPostProcessor</tag>
        <tag>Configuration注解</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-容器refresh</title>
    <url>/2021-06-03/spring-rong-qi-refresh/</url>
    <content><![CDATA[
​	从源码分析了Spring容器的refresh过程，并通过图文的方式记录了整个流程的核心步骤




核心步骤总结
准备 BeanFactory（包括类加载器、SPEL解析器等基础设施）
执行 BeanDefinitionRegistryPostProcessor：优先处理配置类等，动态注册更多 BeanDefinition
执行 BeanFactoryPostProcessor：可用来修改 BeanDefinition 信息
注册 BeanPostProcessor：用于后续 Bean 创建生命周期中的扩展
初始化 MessageSource：国际化消息解析支持
初始化事件广播器（ApplicationEventMulticaster）并注册为 Bean
调用 onRefresh()：留给子类扩展（如创建 Web Server）
注册 ApplicationListener：用于监听容器事件
实例化非懒加载的单例 Bean
完成刷新：启动 SmartLifecycle Bean，发布 ContextRefreshedEvent


AbstractApplicationContext#refresh-源码分析整体的refreshpublic void refresh() throws BeansException, IllegalStateException {
    synchronized (this.startupShutdownMonitor) {
        // 1. 准备上下文环境（包括设置启动时间、状态标志位、初始化环境属性等）
        prepareRefresh();

        // 2. 创建并刷新 BeanFactory（默认 DefaultListableBeanFactory）
        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

        // 3. 对BeanFactory做各种填充
        prepareBeanFactory(beanFactory);

        try {
            // 4. hook方法，供子类在 BeanFactory 初始化后、自定义修改它
            postProcessBeanFactory(beanFactory);

            // 5. 调用 BeanFactoryPostProcessor(BeanDefinitionRegistryPostProcessor >
            // BeanFactoryPostProcessor)
            // ConfigurationClassPostProcessor就是这阶段处理的
            invokeBeanFactoryPostProcessors(beanFactory);

            // 6. 注册 BeanPostProcessor（并非调用），用于后续Bean实例化的hook
            registerBeanPostProcessors(beanFactory);

            // 7. 为上下文初始化Message源，国际化处理
            initMessageSource();

            // 8. 初始化事件广播器（默认实现为SimpleApplicationEventMulticaster，专门用来查找对应ApplicationEvent应该使用哪个ApplicationListener（按类型匹配））
            initApplicationEventMulticaster();

            // 9. 留给子类初始化其他bean（spring boot中子类会初始化web服务器）
            onRefresh();

            // 10. 注册所有实现了 ApplicationListener 的 Bean 到广播器中
            registerListeners();

            // 11. 初始化剩下Bean（非lazy 且 singleton）
            finishBeanFactoryInitialization(beanFactory);

            // 12. SmartLifecycle的Bean可以start了，并且发布ContextRefreshedEvent事件
            finishRefresh();
        }

        catch (BeansException ex) {
            if (logger.isWarnEnabled()) {
                logger.warn("Exception encountered during context initialization - " +
                        "cancelling refresh attempt: " + ex);
            }

            // 异常处理1：销毁已创建的单例 bean，避免资源泄漏
            destroyBeans();

            // 异常处理2：重置 context 状态标志，保证下次调用 refresh 可以重新开始
            cancelRefresh(ex);

            throw ex;
        }

        finally {
            // 最终清除 Spring 内部使用的一些缓存（如反射、泛型元信息等）
            resetCommonCaches();
        }
    }
}

关键步骤分析prepareBeanFactory​	目的是对内部 BeanFactory 进行增强配置，注入 ApplicationContext 级别的基础能力，主要包括如下

设置类加载器、SpEL 表达式解析器与资源编辑器
注册常见 Aware 接口的处理器与特殊依赖的自动解析
注册内置基础 Bean（如 Spring Environment、系统属性、系统环境变量）

protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {
    // 设置类加载器（用于加载 bean 类、AOP 等）
    beanFactory.setBeanClassLoader(getClassLoader());
    // 设置beanFactory的表达式语言（SpEL）处理器
    beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));
    // 设置各种PropertyEditor（用于解析 Resource 等）
    beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));

    // 注册 ApplicationContextAwareProcessor，处理以下几个 Aware 接口注入
    beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));
    // 设置一些忽略自动装配的接口,上面的ApplicationContextAwareProcessor就已经搞定了
    beanFactory.ignoreDependencyInterface(EnvironmentAware.class);
    beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);
    beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);
    beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);
    beanFactory.ignoreDependencyInterface(MessageSourceAware.class);
    beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);

    // 设置几个特殊的依赖注入值（无需在容器中定义，注入时直接解析为指定对象）
    beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);
    beanFactory.registerResolvableDependency(ResourceLoader.class, this);
    beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);
    beanFactory.registerResolvableDependency(ApplicationContext.class, this);

    // 添加ApplicationListener的监听器，当单例bean初始化后，且实现了ApplicationListener接口，就将其缓存起来以便使用
    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));

    // 如果容器中有 LoadTimeWeaver，注册对应的 Aware 处理器，并设置临时 ClassLoader
    if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {
        beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));
        beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));
    }

    // Spring Environment Bean 注册（当前环境信息）
    if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) {
        beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());
    }
    // 系统属性（System.getProperties()）Bean注册
    if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) {
        beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());
    }
    // 系统环境变量（System.getenv()）Bean注册
    if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) {
        beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());
    }
}

invokeBeanFactoryPostProcessors

先处理 BeanDefinitionRegistryPostProcessor：
手动传入的优先执行
容器中的按 PriorityOrdered &gt; Ordered &gt; 剩下的
若执行过程中有动态注册的后处理器，继续迭代


再处理 BeanFactoryPostProcessor：
优先级一样， PriorityOrdered &gt; Ordered &gt; 剩下的


最后清除合并后的 BeanDefinition 缓存，确保后处理器修改生效


​	ConfigurationClassPostProcessor 就是最早执行的 BeanDefinitionRegistryPostProcessor之一，其负责解析 @Configuration 等注解并动态注册大量 BeanDefinition。因此，我们可以通过自定义 BeanDefinitionRegistryPostProcessor 在它之后介入，统一处理或修改所有后续注册的 BeanDefinition，实现排除、添加或调整。
// PostProcessorRegistrationDelegate类
public static void invokeBeanFactoryPostProcessors(
        ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor> beanFactoryPostProcessors) {

    // 已经处理过了的BeanDefinitionRegistryPostProcessors集和，避免重复处理bean
    Set&lt;String> processedBeans = new HashSet&lt;>();

    /// 判断 beanFactory 是否支持注册
    /// BeanDefinition，以优先处理BeanDefinitionRegistryPostProcessor
    if (beanFactory instanceof BeanDefinitionRegistry) {
        BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;
        List&lt;BeanFactoryPostProcessor> regularPostProcessors = new ArrayList&lt;>();
        List&lt;BeanDefinitionRegistryPostProcessor> registryProcessors = new ArrayList&lt;>();

        for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) {
            if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) {
                BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor;
                registryProcessor.postProcessBeanDefinitionRegistry(registry);
                registryProcessors.add(registryProcessor);
            } else {
                regularPostProcessors.add(postProcessor);
            }
        }

        // 当前阶段要执行的 BeanDefinitionRegistryPostProcessor 处理器列表，处理的优先级：PriorityOrdered >
        // Ordered > 剩下的
        List&lt;BeanDefinitionRegistryPostProcessor> currentRegistryProcessors = new ArrayList&lt;>();

        // =================== 第一轮：处理 PriorityOrdered 的 BD 处理器 ===================
        String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true,
                false);
        for (String ppName : postProcessorNames) {
            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                processedBeans.add(ppName);
            }
        }
        sortPostProcessors(currentRegistryProcessors, beanFactory);
        registryProcessors.addAll(currentRegistryProcessors);
        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
        currentRegistryProcessors.clear();

        // =================== 第二轮：处理 Ordered 的 BD 处理器 ===================
        postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
        for (String ppName : postProcessorNames) {
            if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) {
                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                processedBeans.add(ppName);
            }
        }
        sortPostProcessors(currentRegistryProcessors, beanFactory);
        registryProcessors.addAll(currentRegistryProcessors);
        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
        currentRegistryProcessors.clear();

        // =================== 最后：处理剩余的无序 BD 处理器（可能动态注册） ===================
        boolean reiterate = true;
        while (reiterate) {
            reiterate = false;
            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true,
                    false);
            for (String ppName : postProcessorNames) {
                if (!processedBeans.contains(ppName)) {
                    currentRegistryProcessors
                            .add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                    processedBeans.add(ppName);
                    reiterate = true;
                }
            }
            sortPostProcessors(currentRegistryProcessors, beanFactory);
            registryProcessors.addAll(currentRegistryProcessors);
            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
            currentRegistryProcessors.clear();
        }

        // =================== 执行所有已注册 BD 处理器的 postProcessBeanFactory 回调
        // ===================
        invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);
        // =================== 执行用户提供的常规 BeanFactoryPostProcessor ===================
        invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);
    }

    else {
        invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);
    }

    // =================== 从配置中获取剩余的 BeanFactoryPostProcessor ===================
    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);

    // 分类收集 PriorityOrdered、Ordered、其他的 三类处理器
    List&lt;BeanFactoryPostProcessor> priorityOrderedPostProcessors = new ArrayList&lt;>();
    List&lt;String> orderedPostProcessorNames = new ArrayList&lt;>();
    List&lt;String> nonOrderedPostProcessorNames = new ArrayList&lt;>();
    for (String ppName : postProcessorNames) {
        if (processedBeans.contains(ppName)) {
            // skip - already processed in first phase above
        } else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
            priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));
        } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {
            orderedPostProcessorNames.add(ppName);
        } else {
            nonOrderedPostProcessorNames.add(ppName);
        }
    }

    // 执行顺序类似上面的BD处理器
    // PriorityOrdered
    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);
    invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);

    // Ordered
    List&lt;BeanFactoryPostProcessor> orderedPostProcessors = new ArrayList&lt;>();
    for (String postProcessorName : orderedPostProcessorNames) {
        orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));
    }
    sortPostProcessors(orderedPostProcessors, beanFactory);
    invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);

    // 其他的
    List&lt;BeanFactoryPostProcessor> nonOrderedPostProcessors = new ArrayList&lt;>();
    for (String postProcessorName : nonOrderedPostProcessorNames) {
        nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));
    }
    invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);
    // 清理 BeanDefinition 的缓存，防止元信息过期（如占位符已被替换）
    beanFactory.clearMetadataCache();
}

registerBeanPostProcessors​	实例化并注册所有 BeanPostProcessor，按 PriorityOrdered &gt; Ordered &gt; 无序 的优先级添加到容器中，确保 Bean 生命周期中的处理器执行顺序符合预期；内部处理器（MergedBeanDefinitionPostProcessor）统一放在末尾，确保其在所有普通处理器之后执行。
// PostProcessorRegistrationDelegate类
public static void registerBeanPostProcessors(
        ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {
    // 获取所有实现了 BeanPostProcessor 接口的 beanName（不实例化）
    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);

    // 记录目标 BeanPostProcessor 总数：现有 + 新注册 + 最终数量
    int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;
   /*
     *   专门用来检查普通bean是否走完所有的BeanPostProcessor的
     *
     * 一个普通的bean在实例化时，正常情况下应该走完所有的BeanPostProcessor，
     * 但当只注册了部分的BeanPostProcessor(放到IOC容器中)时，
     * 此时实例化一个bean可能就导致还未注册的BeanPostProcessor处理不了（看优先级），
     * 就会由这个checker来日志提醒（仅打印info日志）
     */
    beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));

    // 准备分组存储不同优先级的 BeanPostProcessor
    List&lt;BeanPostProcessor> priorityOrderedPostProcessors = new ArrayList&lt;>();
    List&lt;BeanPostProcessor> internalPostProcessors = new ArrayList&lt;>();
    List&lt;String> orderedPostProcessorNames = new ArrayList&lt;>();
    List&lt;String> nonOrderedPostProcessorNames = new ArrayList&lt;>();
    // 分类：根据是否实现 PriorityOrdered / Ordered / 无排序
    for (String ppName : postProcessorNames) {
        if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { // PriorityOrdered的直接实例化
            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
            priorityOrderedPostProcessors.add(pp);
            if (pp instanceof MergedBeanDefinitionPostProcessor) {
                internalPostProcessors.add(pp);
            }
        } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {
            orderedPostProcessorNames.add(ppName);
        } else {
            nonOrderedPostProcessorNames.add(ppName);
        }
    }

    // PriorityOrdered以及实例化了，就可直接 排序 ->  注册
    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);

    // Ordered，实例化 -> 排序 -> 注册
    List&lt;BeanPostProcessor> orderedPostProcessors = new ArrayList&lt;>();
    for (String ppName : orderedPostProcessorNames) {
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        orderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            internalPostProcessors.add(pp);
        }
    }
    sortPostProcessors(orderedPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, orderedPostProcessors);

    // 无顺序，实例化 -> 注册
    List&lt;BeanPostProcessor> nonOrderedPostProcessors = new ArrayList&lt;>();
    for (String ppName : nonOrderedPostProcessorNames) {
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        nonOrderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            internalPostProcessors.add(pp);
        }
    }
    registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);

    // 四、最后统一注册 MergedBeanDefinitionPostProcessor（内部BPP），例如：
    // - AutowiredAnnotationBeanPostProcessor
    // - CommonAnnotationBeanPostProcessor
    // - ApplicationListenerDetector 等
    sortPostProcessors(internalPostProcessors, beanFactory);
    registerBeanPostProcessors(beanFactory, internalPostProcessors);

    // 五、重新注册 ApplicationListenerDetector，用来收集ApplicationListener Bean（确保在链末尾执行（避免过早代理））
    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));
}

initApplicationEventMulticaster​	注册的默认事件广播器为SimpleApplicationEventMulticaster，其主要是对所有的ApplicationEvent事件进行分发匹配到对应的ApplicationListener中（支持异步，线程池为SimpleApplicationEventMulticaster.taskExecutor，默认同步分发）
protected void initApplicationEventMulticaster() {
    ConfigurableListableBeanFactory beanFactory = getBeanFactory();
    if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) {
        this.applicationEventMulticaster =
                beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class);
        if (logger.isTraceEnabled()) {
            logger.trace("Using ApplicationEventMulticaster [" + this.applicationEventMulticaster + "]");
        }
    }
    else {
        // 实例化并注册默认的事件广播器Bean：SimpleApplicationEventMulticaster
        this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);
        beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster);
        if (logger.isTraceEnabled()) {
            logger.trace("No '" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + "' bean, using " +
                    "[" + this.applicationEventMulticaster.getClass().getSimpleName() + "]");
        }
    }
}

onRefresh​	一个模板方法（hook），由子类实现，用于在 refresh() 流程中 容器刷新完成、所有 BeanFactory 初始化完毕之后，进行特定上下文的扩展初始化工作。
​	比如在 Spring Boot 中，AnnotationConfigServletWebServerApplicationContext 会在该方法中创建和启动内嵌的 Web 服务器（默认是 Tomcat，可选 Jetty 或 Undertow），并完成 Web 环境相关的初始化。
finishBeanFactoryInitialization是 Spring 容器刷新流程中的 核心收尾步骤之一，主要职责如下：

初始化所有非懒加载（non-lazy）、非抽象的单例 Bean
这一步会触发 Bean 的完整生命周期流程：依赖注入（populate）、初始化方法调用（如 @PostConstruct、InitializingBean#afterPropertiesSet）、AOP 代理包装等


触发 SmartInitializingSingleton 回调
所有实现了 SmartInitializingSingleton 接口的单例 Bean，会在 所有非懒加载的单例 Bean 完成初始化之后 统一回调其 afterSingletonsInstantiated() 方法。
这是容器中所有 Bean 都就绪之后的 “最后的hook”，用于执行依赖所有 Bean 的集中初始化逻辑



// AbstractApplicationContext
protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {

    // 清空临时类加载器
    beanFactory.setTempClassLoader(null);

    // 冻结BeanDefinition的配置，代表需要的地方可以缓存了
    // 走到这，BeanDefinition都已经处理完毕了，所以可以考虑缓存了
    beanFactory.freezeConfiguration();

    // 实例化所有非lazy加载的单例bean，并在加载完后调用SmartInitializingSingleton接口
    // SmartInitializingSingleton这个接口就是在实例化所有非lazy且单例bean完成后需要调用的
    beanFactory.preInstantiateSingletons();
}

真正初始化单例bean（DefaultListableBeanFactory#preInstantiateSingletons方法）
public void preInstantiateSingletons() throws BeansException {
    List&lt;String> beanNames = new ArrayList&lt;>(this.beanDefinitionNames);

    for (String beanName : beanNames) {
        RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);
        // 非抽象 + 单例 + 非lazy加载
        if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) {
            // 实例化工厂Bean
            if (isFactoryBean(beanName)) {
                Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);
                if (bean instanceof FactoryBean) {
                    FactoryBean&lt;?> factory = (FactoryBean&lt;?>) bean;
                    boolean isEagerInit;
                    if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) {
                        isEagerInit = AccessController.doPrivileged(
                                (PrivilegedAction&lt;Boolean>) ((SmartFactoryBean&lt;?>) factory)::isEagerInit,
                                getAccessControlContext());
                    }
                    else {
                        isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;
                                ((SmartFactoryBean&lt;?>) factory).isEagerInit());
                    }
                    if (isEagerInit) {
                        getBean(beanName);
                    }
                }
            }
            else {
                // 实例化非工厂Bean
                getBean(beanName);
            }
        }
    }

    // apply所有SmartInitializingSingleton Bean逻辑
    // 重要的拓展口，可以在这里最早感知到大部分Bean准备完毕，可以放心调用这些bean的各种方法了
    for (String beanName : beanNames) {
        Object singletonInstance = getSingleton(beanName);
        if (singletonInstance instanceof SmartInitializingSingleton) {
            SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;
            if (System.getSecurityManager() != null) {
                AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> {
                    smartSingleton.afterSingletonsInstantiated();
                    return null;
                }, getAccessControlContext());
            }
            else {
                smartSingleton.afterSingletonsInstantiated();
            }
        }
    }
}

finishRefresh​	这一步结束，容器对外就完全可用了
protected void finishRefresh() {
    // 清除上下文级别的缓存资源，例如类扫描过程中缓存的 ASM 元数据。
    clearResourceCaches();

    // 初始化生命周期处理器（LifecycleProcessor）。
    // 默认实现为 DefaultLifecycleProcessor，用于统一管理实现了 Lifecycle 接口的 bean 的启动与停止
    initLifecycleProcessor();

    // 通知生命周期处理器，容器刷新完成
    // 将启动所有实现了 SmartLifecycle 接口并设置了 autoStartup = true 的 Bean（通常用于自动启动的组件，如消息监听容器、调度器等）
    getLifecycleProcessor().onRefresh();

    // 广播容器刷新完成事件：ContextRefreshedEvent
    // 所有实现了 ApplicationListener 接口，监听该事件的 Bean 都会收到通知，可用于执行基于“容器就绪”的后置逻辑。
    publishEvent(new ContextRefreshedEvent(this));

    // 将当前 ApplicationContext 注册到 JMX 的 LiveBeansView 中（如果启用）
    // 这允许通过 JMX 客户端动态查看容器中所有 Bean 的状态（例如 VisualVM 插件）
    LiveBeansView.registerApplicationContext(this);
}

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
  </entry>
  <entry>
    <title>SpringBoot（二）— SPI和starter优化器原理</title>
    <url>/2022-03-04/springboot-spi-he-starter-you-hua-qi/</url>
    <content><![CDATA[​	算是一篇SrpingBoot自动配置原理解析的前置文章。首先从源码角度回顾了早期的 spring.factories SPI 加载机制，接着分析了 Spring Boot 2.7.x 引入的基于注解粒度的 .imports 文件机制，展示了其在自动配置解耦方面的优势。并介绍了两个常被 starter 使用的辅助组件：

spring-boot-configuration-processor：生成配置元数据，IDE使用
spring-boot-autoconfigure-processor：加速自动配置加载

​	最后，结合自定义 starter 的实践，附上了完整的测试用例，验证上述机制在实际开发中的可用性


SPI机制可先看看这篇文章，了解下如何从ClassLoader的classpath读取到指定资源
SpringFactoriesLoader​	SpringBoot 早期采用的 SPI 扩展机制实现，整体加载逻辑相对简单，负责从指定 ClassLoader 的所有 classpath 路径中加载并缓存META-INF/spring.factories 文件
​	这个文件本质上是一个 Properties 格式的配置文件，支持一个 key 对应多个 value，多个 value 之间使用英文逗号分隔
public final class SpringFactoriesLoader {

    public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories";

    /**
     * 加载并缓存指定ClassLoader下的所有META-INF/spring.factories里的配置
     */
    private static Map&lt;String, List&lt;String>> loadSpringFactories(ClassLoader classLoader) {
        // 从缓存里取
        Map&lt;String, List&lt;String>> result = cache.get(classLoader);
        if (result != null) {
            return result;
        }

        result = new HashMap&lt;>();
        try {
            // 返回classpath下所有的META-INF/spring.factories文件URL形式
            Enumeration&lt;URL> urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION);
            while (urls.hasMoreElements()) {
                URL url = urls.nextElement();
                UrlResource resource = new UrlResource(url);
                // 读取为Properties
                Properties properties = PropertiesLoaderUtils.loadProperties(resource);
                for (Map.Entry&lt;?, ?> entry : properties.entrySet()) {
                    String factoryTypeName = ((String) entry.getKey()).trim();
                    String[] factoryImplementationNames = StringUtils
                            .commaDelimitedListToStringArray((String) entry.getValue());
                    for (String factoryImplementationName : factoryImplementationNames) {
                        result.computeIfAbsent(factoryTypeName, key -> new ArrayList&lt;>())
                                .add(factoryImplementationName.trim());
                    }
                }
            }
            // 去重后再转化为不可修改的List
            result.replaceAll((factoryType, implementations) -> implementations.stream().distinct()
                    .collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList)));
            // 缓存
            cache.put(classLoader, result);
        } catch (IOException ex) {
            throw new IllegalArgumentException(
                    "Unable to load factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex);
        }
        return result;
    }
}

ImportCandidates​	是SpringBoot 2.7.x版本引入的新的SPI，替代早期的 META-INF/spring.factories 里的部分配置。传统的 spring.factories 文件中将所有自动配置、监听器等内容集中在一个文件中，内容有些杂。为了更加精细化，Spring Boot 引入了基于注解粒度的 .imports 配置机制：每个注解对应一个独立的配置文件，配置文件名为META-INF&#x2F;spring&#x2F;注解全类名.imports
​	但SpringBoot现阶段也就@AutoConfiguration和@ManagementContextConfiguration这两个注解用了这个SPI
​	以常用的@AutoConfiguration为例，其配置文件名如下，是专门替换META-INF&#x2F;spring.factories中org.springframework.boot.autoconfigure.EnableAutoConfiguration的配置

META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports

public final class ImportCandidates implements Iterable&lt;String> {

    private static final String LOCATION = "META-INF/spring/%s.imports";

    // 注释符号
    private static final String COMMENT_START = "#";

    private final List&lt;String> candidates;

    // 支持迭代
    @Override
    public Iterator&lt;String> iterator() {
        return this.candidates.iterator();
    }

    public static ImportCandidates load(Class&lt;?> annotation, ClassLoader classLoader) {
        // annotation一般为注解全类名
        Assert.notNull(annotation, "'annotation' must not be null");
        ClassLoader classLoaderToUse = decideClassloader(classLoader);
        String location = String.format(LOCATION, annotation.getName());
        // 从classLoader的classpath下查找指定文件URL
        Enumeration&lt;URL> urls = findUrlsInClasspath(classLoaderToUse, location);
        List&lt;String> importCandidates = new ArrayList&lt;>();
        while (urls.hasMoreElements()) {
            URL url = urls.nextElement();
            // 解析文件（每行为一个class，并跳过注释）
            importCandidates.addAll(readCandidateConfigurations(url));
        }
        return new ImportCandidates(importCandidates);
    }

}

starter优化器spring-boot-configuration-processor引入组件&lt;dependency>
    &lt;groupId>org.springframework.boot&lt;/groupId>
    &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId>
    &lt;optional>true&lt;/optional> &lt;!-- 避免被传递依赖 -->
&lt;/dependency>

介绍​	这个组件对项目的运行时没有任何影响，它的作用如下：

​	会在编译期 自动解析使用了 @ConfigurationProperties 等注解的配置类，将配置项的 属性名、类型、默认值、Javadoc 注释 等信息生成到 META-INF/spring-configuration-metadata.json 文件中

​	这个文件主要供IDE使用（如IDEA），用于在编辑 application.yml时提供配置自动补全、类型校验和快速跳转到对应配置类，所以也没必要把这个依赖传递下去
spring-boot-autoconfigure-processor引入组件&lt;dependency>
    &lt;groupId>org.springframework.boot&lt;/groupId>
    &lt;artifactId>spring-boot-autoconfigure-processor&lt;/artifactId>
    &lt;optional>true&lt;/optional>
&lt;/dependency>

介绍​	一个作用在编译期，用于扫描自动配置类上的部分注解，将解析结果提前生成到META-INF/spring-autoconfigure-metadata.properties文件
​	 通过解析工具AutoConfigureAnnotationProcessor可知，支持的注解如下
@SupportedAnnotationTypes({ "org.springframework.boot.autoconfigure.condition.ConditionalOnClass",
        "org.springframework.boot.autoconfigure.condition.ConditionalOnBean",
        "org.springframework.boot.autoconfigure.condition.ConditionalOnSingleCandidate",
        "org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication",
        "org.springframework.boot.autoconfigure.AutoConfigureBefore",
        "org.springframework.boot.autoconfigure.AutoConfigureAfter",
        "org.springframework.boot.autoconfigure.AutoConfigureOrder",
        "org.springframework.boot.autoconfigure.AutoConfiguration" })

META-INF/spring-autoconfigure-metadata.properties文件内部信息格式如下，每一行表示某个自动配置类的某个注解信息：

配置类全类名.上述注解简单名&#x3D;注解值
site.xxx.Demo.ConditionalOnClass&#x3D;org.springframework.boot.context.event.ApplicationReadyEvent

​	该文件会在SpringBoot启动时被AutoConfigurationMetadataLoader加载，这种预解析的结果比反射或asm实时解析相关注解更快，以此来加速程序的启动。
实现一个starter一个简单的starter，主要目的是在项目成功启动后打印成功信息和耗费时间的日志，且提供可配置的开关和时间格式。时间统计方式：ApplicationStartingEvent到ApplicationReadyEvent这段时间
自动配置类@AutoConfiguration
@AutoConfigureAfter(name = "org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration")
@EnableConfigurationProperties(StartupLoggerProperties.class)
@ConditionalOnClass(ApplicationReadyEvent.class)
@ConditionalOnProperty(prefix = "startup.logger", name = "enabled", havingValue = "true", matchIfMissing = true)
public class StartupLoggerAutoConfiguration {


    @Bean
    public ApplicationListener&lt;ApplicationReadyEvent> startupLoggerListener(StartupLoggerProperties props) {
        return event -> {
            long cost = StartupCostTimeRecorder.cost();
            String timeStr = props.getTimeUnit().equals("s") ? (cost / 1000.0 + "s") : cost + "ms";
            String appName = event.getApplicationContext().getEnvironment().getProperty("spring.application.name", "Application");

            Logger log = LoggerFactory.getLogger("StartupLogger");
            log.info("========================================================");
            log.info("========================================================");
            log.info("=======   {} startup successful, cost time：{}   =======", appName, timeStr);
            log.info("========================================================");
            log.info("========================================================");
        };
    }
}

开关配置@ConfigurationProperties("startup.logger")
public class StartupLoggerProperties {
    /**
     * 是否开启
     */
    private boolean enabled = true;

    /**
     * 时间格式：ms, s
     */
    private String timeUnit = "ms";

    public boolean isEnabled() {
        return enabled;
    }

    public void setEnabled(boolean enabled) {
        this.enabled = enabled;
    }

    public String getTimeUnit() {
        return timeUnit;
    }

    public void setTimeUnit(String timeUnit) {
        this.timeUnit = timeUnit;
    }
}

启动时间监听器public class StartupStartListener implements ApplicationListener&lt;ApplicationStartingEvent> {

    @Override
    public void onApplicationEvent(ApplicationStartingEvent event) {
        StartupCostTimeRecorder.recordStart();
    }
}

时间记录实体类public class StartupCostTimeRecorder {

    private static Long startTime = null;

    public static void recordStart() {
        startTime = System.currentTimeMillis();
    }

    public static long cost() {
        return System.currentTimeMillis() - startTime;
    }
}

配置文件
META-INF&#x2F;spring.factories
org.springframework.context.ApplicationListener=\
site.shanzhao.startup.logger.config.StartupStartListener

# 还是兼容下2.7.x版本以下的自动配置
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
site.shanzhao.startup.logger.config.StartupLoggerAutoConfiguration


META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports
site.shanzhao.startup.logger.config.StartupLoggerAutoConfiguration



pom&lt;dependencies>
    &lt;dependency>
        &lt;groupId>org.springframework.boot&lt;/groupId>
        &lt;artifactId>spring-boot-starter&lt;/artifactId>
    &lt;/dependency>
    &lt;dependency>
        &lt;groupId>org.springframework.boot&lt;/groupId>
        &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId>
        &lt;optional>true&lt;/optional>
    &lt;/dependency>
    &lt;dependency>
        &lt;groupId>org.springframework.boot&lt;/groupId>
        &lt;artifactId>spring-boot-autoconfigure-processor&lt;/artifactId>
        &lt;optional>true&lt;/optional>
    &lt;/dependency>

&lt;/dependencies>

相关链接
从ClassLoader的classpath读取指定资源
starter示例完整代码

]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>starter</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot（一）— fatJar启动和LaunchedURLClassLoader加载class的原理</title>
    <url>/2022-02-15/springboot-fatjar-qi-dong-he-launchedurlclassloader-jia-zai-class-de-yuan-li/</url>
    <content><![CDATA[​	基于 Spring Boot 2.7.x，从整体架构角度出发，梳理并串联了 fatjar 模式下的关键组件：Archive、JarFile、JarEntry、Handler、JarURLConnection，重点分析它们在类加载过程中的职责与协作关系。全文不聚焦具体 jar 包结构解析细节，而是深入源码层面解析 fatjar 启动流程及 LaunchedURLClassLoader#loadClass 实现机制，并辅以实际测试用例进行debug和验证。


fatjar结构​	SpringBoot 使用 spring-boot-maven-plugin 插件可以将项目打包成一个可执行的 fatjar，其内部结构不仅符合标准的 jar 规范，还增加了 SpringBoot 特有的扩展结构，以支持其定制的类加载机制
├── BOOT-INF
│   ├── classes/               # 你的 class 文件和 resource 资源
│   └── lib/                   # 所有依赖 jar 包
│       ├── spring-context-5.3.31.jar
│       ├── spring-web-5.3.31.jar
├── META-INF
│   └── MANIFEST.MF            # 包含 Main-Class 配置（默认指向 JarLauncher）
├── org
│   └── springframework
│       └── boot
│           └── loader         # SpringBoot 提供的加载器逻辑
│               ├── JarLauncher.class
│               ├── LaunchedURLClassLoader.class
│               ├── ExecutableArchiveLauncher.class
│               ├── Launcher.class
│               ├── MainMethodRunner.class

fatjar解压后如上，其中包含：

当前项目编译后的 .class 文件和资源
项目的所有依赖 jar 文件
SpringBoot 提供的启动器和类加载器（位于 org.springframework.boot.loader 包下）

标准jar部分
&#x2F;META-INF&#x2F;MANIFEST.MF文件：jar的元信息文件（包含项目结构和启动类）。比如java -jar命令就是执行其中Main-Class的main方法
SpringBoot Loader 相关类放在 jar 根路径：让LaunchedURLClassLoader相关依赖可以直接被AppClassLoader加载，无需特殊处理

特有的拓展
所有业务资源都被封装在 /BOOT-INF/ 下而不直接在跟路径：这部分资源不是标准的JVM classpath路径，不能被AppClassLoader加载，只能由SpringBoot提供的LaunchedURLClassLoader加载
jar嵌套：标准jar不支持嵌套结构。SpringBoot拓展了一系列组件的功能来支持&#x2F;BOOT-INF&#x2F;lib&#x2F;下嵌套jar的解析

核心组件在正式进入源码前，先了解一些fatjar相关的核心组件和作用，对后续源码debug会有帮助。我这里主要关注fatjar启动方式，就不考虑exploded模式了
Archive​	是SpringBoot Loader 模块中的一个抽象接口。可以表示 fatjar 本身，也可以表示 fatjar 内部的某个嵌套 jar（BOOT-INF/lib/*.jar），或特定目录（ BOOT-INF/classes/），此时其实现为org.springframework.boot.loader.archive.JarFileArchive。两个核心方法如下：

Archive#getUrl：返回当前资源的URL，用于构造classpath。比如：

jar:file:&#x2F;Users&#x2F;reef&#x2F;IdeaProjects&#x2F;soil&#x2F;target&#x2F;soil-1.0.0.jar!&#x2F;BOOT-INF&#x2F;classes!&#x2F;
jar:file:&#x2F;Users&#x2F;reef&#x2F;IdeaProjects&#x2F;soil&#x2F;target&#x2F;soil-1.0.0.jar!&#x2F;BOOT-INF&#x2F;lib&#x2F;spring-core-5.3.31.jar!&#x2F;


Archive#getNestedArchives(EntryFilter filter)：遍历当前 Archive 内部结构，筛选出所有符合条件的子 Archive

如SpringBoot中默认过滤出嵌套 jar（BOOT-INF&#x2F;lib&#x2F;*.jar文件）和指定目录（BOOT-INF&#x2F;classes&#x2F;）



JarFile​	JDK 提供的java.util.jar.JarFile 类表示一个标准的 jar 文件，其本质是一个 classpath 元素，内部通常只包含 .class 文件和资源文件，不支持嵌套 jar结构。
​	为了支持 fatjar 的结构，SpringBoot 自定义了 org.springframework.boot.loader.jar.JarFile 类，它同样表示一个 jar 文件，但支持访问 fatjar 内部嵌套的 jar（例如 BOOT-INF/lib/*.jar），并提供对嵌套 jar 内容的解包与访问能力。核心方法如下：

JarFile#getInputStream(java.util.zip.ZipEntry)：获取指定 entry 的InputStream，可用于读取 .class 文件、配置文件、资源等内容
JarFile#getJarEntry(java.lang.String)：获取当前jar内部的指定资源对象（JarEntry）。支持查找 class 文件、配置文件、嵌套 jar 等
JarFile#getNestedJarFile(JarEntry)：将fatjar内部某个嵌套 jar转换为一个新的 JarFile 对象，实现对嵌套 jar 的透明访问

JarEntry​	jdk 提供的 java.util.jar.JarEntry 表示 jar 文件中的一个具体条目，可以是 .class 文件、配置文件、目录等。并支持通过 JarFile#getInputStream(entry) 读取其内容
​	但fatjar是一种嵌套的复杂结构，标准的 JarEntry无法支持对内部嵌套 jar 的进一步解析，所以SpringBoot对其拓展，定义了自己的org.springframework.boot.loader.jar.JarEntry 类，增加表示了fatjar 中嵌套的 jar 文件。其配合JarFile#getNestedJarFile(JarEntry entry) 方法，能够将某个嵌套 jar 条目转换为新的 JarFile 对象，实现对嵌套 jar 的透明访问
URLStreamHandler​	是 JDK 提供的抽象类，用于处理特定协议（如 http、file、jar）的 URL，并生成对应的 URLConnection 对象，以实现对资源的读取。
​	对于 jar 协议，JDK 默认使用 sun.net.www.protocol.jar.Handler 创建标准的 JarURLConnection，用于读取普通 jar 文件中的资源。
​	SpringBoot 自定义了 org.springframework.boot.loader.jar.Handler，用于替代 JDK 默认的 Handler。该 Handler 会创建支持嵌套 jar 的 JarURLConnection，以满足 fatjar 场景下的资源访问需求
​	SpringBoot通过设置如下系统属性，确保了当构造jar协议的URL时，会使用org.springframework.boot.loader.jar.Handler作为当前URL的URLStreamHandler
// org.springframework.boot.loader.jar.JarFile#registerUrlProtocolHandler方法里
System.setProperty("java.protocol.handler.pkgs", "org.springframework.boot.loader");

JarURLConnection表示jar协议URL的连接对象，但标准的java.net.JarURLConnection不支持解析多层嵌套的资源，如

 jar:file:&#x2F;soil-1.0.0.jar!&#x2F;BOOT-INF&#x2F;lib&#x2F;demo.jar!&#x2F;site.shanzhao.Demo.class

为此，SpringBoot 提供了替代实现 org.springframework.boot.loader.jar.JarURLConnection，可直接在不解压 fatjar 的情况下访问嵌套 jar 内部的 class 和配置资源。核心方法如下

JarURLConnection#getJarEntry：将当前URL资源解析为JarEntry
JarURLConnection#getInputStream：通过JarFile获取该资源对应的InputStream，以直接读取 .class 文件或配置资源

fatjar启动流程​	入口为JarLauncher#main方法，JarLauncher继承了ExecutableArchiveLauncher
ExecutableArchiveLauncher实例化主要做两件事：

Launcher#createArchive：确定当前启动类是jar包还是目录启动，jar启动使用JarFileArchive，目录启动则使用ExplodedArchive
加载classpath.idx文件：只有目录启动模式（exploded）才会使用&#x2F;BOOF-INF&#x2F;classpath.idx文件来加速classpath URL的构建

Launcher#launch启动器的核心入口，主要完成以下三项工作：

fatjar启动才注册JarFile.registerUrlProtocolHandler（exploded为解压模式下启动，这种不存在嵌套jar）。让jar协议的URL使用SpringBoot提供的Handler，去创建支持解析嵌套jar内容的URLConnection
解析classpath URL，并创建相关的LaunchedURLClassLoader
绑定LaunchedURLClassLoader到当前线程上下文，并反射启动Start-Class

protected void launch(String[] args) throws Exception {
        if (!isExploded()) {
            // fatjar模式启动，注册一个 java.protocol.handler.pkgs=org.springframework.boot.loader 的系统属性
            // 以便让jar protocol的URL使用org.springframework.boot.loader.jar.Handler来创建URLConnection
            JarFile.registerUrlProtocolHandler();
        }
        // 遍历并筛选 fatjar 内部的 BOOT-INF/lib 和 BOOT-INF/classes，构建 URL 列表并创建LaunchedURLClassLoader
        ClassLoader classLoader = createClassLoader(getClassPathArchivesIterator());
        String jarMode = System.getProperty("jarmode");
        // 获取Start-Class，也就是我们主程序的启动类
        String launchClass = (jarMode != null &amp;&amp; !jarMode.isEmpty()) ? fatjar_MODE_LAUNCHER : getMainClass();
        // 绑定LaunchedURLClassLoader到当前thread（即main线程）里，以便在后续加载class时使用到。并启动项目的主启动类
        launch(args, launchClass, classLoader);
    }

ExecutableArchiveLauncher#getClassPathArchivesIterator是fatjar启动模式下构建classpath URL的关键代码，其定义的EntryFilter会构建出如下的Archive

BOOT-INF&#x2F;lib&#x2F; 下所有jar分别各自对应一个Archive
BOOT-INF&#x2F;classes 文件夹对应一个Archive

    @Override
    protected Iterator&lt;Archive> getClassPathArchivesIterator() throws Exception {
        // 以 BOOT-INF/ 开头
        Archive.EntryFilter searchFilter = this::isSearchCandidate;
        // 当存在 BOOT-INF/classpath.idx 文件时，跳过其中已列出的 jar 文件，不再走常规的扫描构建 Archive 路径。
        // 会在后续步骤里（ExecutableArchiveLauncher.createClassLoader方法）直接通过 BOOT-INF/classpath.idx 文件把这些jar转成URL加入classpath，从而提升启动效率。
        // 重点注意：只有在exploded模式下（解压了），才会使用BOOT-INF/classpath.idx。以java -jar启动使用的JarFileArchive是不会用到 BOOT-INF/classpath.idx 文件的
        Iterator&lt;Archive> archives = this.archive.getNestedArchives(searchFilter,
                (entry) -> isNestedArchive(entry) &amp;&amp; !isEntryIndexed(entry));
        if (isPostProcessingClassPathArchives()) {
            archives = applyClassPathArchivePostProcessing(archives);
        }
        return archives;
    }

总结从 JarLauncher#main 启动到反射调用 Start-Class 的 main 方法，主要完成以下工作：

​	解析 fatjar，将其中的依赖 jar 和项目 class 封装为 jar 协议的 URL，并用这些 URL 构造 LaunchedURLClassLoader；随后将该类加载器绑定到 main 线程的上下文，确保在应用启动过程中可以加载所有 class 和资源

测试用例可以跟着debug看看fatjar到底解析出了那些Archive，和这些Archive的URL格式
public class FatJarResolveArchiveDemo {


    public static void main(String[] args) throws Exception {
        String fatJarPath = System.getProperty("user.home") + "/IdeaProjects/soil/target/soil-1.0.0.jar";
        JarFileArchive soilJar = new JarFileArchive(new File(fatJarPath));
        Archive.EntryFilter searchFilter = entry -> entry.getName().startsWith("BOOT-INF/");
        // fatjar启动下ExecutableArchiveLauncher.classPathIndex字段为null，ExecutableArchiveLauncher.isEntryIndexed就默认返回true了
        Iterator&lt;Archive> archives = soilJar.getNestedArchives(searchFilter, NESTED_ARCHIVE_ENTRY_FILTER);
        while (archives.hasNext()) {
            System.out.println(archives.next());
        }

        soilJar.close();
    }


    private static final Archive.EntryFilter NESTED_ARCHIVE_ENTRY_FILTER = (entry) -> {
        if (entry.isDirectory()) {
            return entry.getName().equals("BOOT-INF/classes/");
        }
        return entry.getName().startsWith("BOOT-INF/lib/");
    };
}

LaunchedURLClassLoader这是SpringBoot项目的真正类加载器，主要关注其loadClass方法，顺着这个方法看看一个class文件是如何被找的
definePackage在当前类完成，随后真正loadClass还是调用父类URLClassLoader#loadClass方法
核心源码protected Class&lt;?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
    // 先单独处理jarmode
    if (name.startsWith("org.springframework.boot.loader.jarmode.")) {
        try {
            Class&lt;?> result = loadClassInLaunchedClassLoader(name);
            if (resolve) {
                resolveClass(result);
            }
            return result;
        } catch (ClassNotFoundException ex) {
        }
    }
    if (this.exploded) { // exploded解压模式，不是fatjar。可直接用传统的方式查找class
        return super.loadClass(name, resolve);
    }
    Handler.setUseFastConnectionExceptions(true);
    try {
        try {
            // 遍历所有可用的jar，并匹配到当前的name，最后定义为可用的Package
            definePackageIfNecessary(name);
        } catch (IllegalArgumentException ex) {
            if (getPackage(name) == null) {
                throw new AssertionError("Package " + name + " has already been defined but it could not be found");
            }
        }
        // 直接用父类URLClassLoader方法loadClass
        return super.loadClass(name, resolve);
    } finally {
        Handler.setUseFastConnectionExceptions(false);
    }
}

private void definePackageIfNecessary(String className) {
    int lastDot = className.lastIndexOf('.');
    if (lastDot >= 0) {
        // 截掉class的simpleName,只留下包名
        String packageName = className.substring(0, lastDot);
        if (getPackage(packageName) == null) { // 缓存中没查到，就define
            try {
                definePackage(className, packageName);
            } catch (IllegalArgumentException ex) {
                if (getPackage(packageName) == null) {
                    throw new AssertionError(
                            "Package " + packageName + " has already been defined but it could not be found");
                }
            }
        }
    }
}

private void definePackage(String className, String packageName) {
    try {
        AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object>) () -> {
            // 例：site/shanzhao/common/bean/
            String packageEntryName = packageName.replace('.', '/') + "/";
            // 例：site/shanzhao/common/bean/Demo.class
            String classEntryName = className.replace('.', '/') + ".class";
            for (URL url : getURLs()) { // 遍历jar协议的URL（fatjar内的所有BOOT-INF/lib/*.jar和/BOOT-INF/classes/）
                try {
                    // 通过Handler创建JarURLConnection（返回的connection不会为空）
                    URLConnection connection = url.openConnection();
                    if (connection instanceof JarURLConnection) {
                        // 如果不存在，内部会抛FileNotFoundException异常
                        JarFile jarFile = ((JarURLConnection) connection).getJarFile();
                        if (jarFile.getEntry(classEntryName) != null &amp;&amp; jarFile.getEntry(packageEntryName) != null
                                &amp;&amp; jarFile.getManifest() != null) { // 找到了，定义这个Package并缓存
                            definePackage(packageName, jarFile.getManifest(), url);
                            return null;
                        }
                    }
                } catch (IOException ex) {
                    // 当前的classpath URL没找到className，忽略异常
                }
            }
            return null;
        }, AccessController.getContext());
    } catch (java.security.PrivilegedActionException ex) {
        // Ignore
    }
}

URLClassLoader​	其loadClass仍遵循双亲委派模型并优先查找缓存，这里聚焦其核心的 findClass 方法，分析如何通过 URL 加载资源并定义类。
findClass核心逻辑总结：

通过内部的URLClassPath查找指定类名对应的资源，封装为 Resource
从Resource 中获InputStream，并转换为ByteBuffer 来读取 .class 字节，最终调用 defineClass 完成类的定义

protected Class&lt;?> findClass(final String name)
        throws ClassNotFoundException {
    final Class&lt;?> result;
    try {
        result = AccessController.doPrivileged(
                new PrivilegedExceptionAction&lt;>() {
                    public Class&lt;?> run() throws ClassNotFoundException {
                        // 将类名转换为资源路径
                        String path = name.replace('.', '/').concat(".class");
                        // 使用内部的URLClassPath加载资源
                        Resource res = ucp.getResource(path, false);
                        if (res != null) {
                            try {
                                // 定义class
                                return defineClass(name, res);
                            } catch (IOException e) {
                                throw new ClassNotFoundException(name, e);
                            } catch (ClassFormatError e2) {
                                if (res.getDataError() != null) {
                                    e2.addSuppressed(res.getDataError());
                                }
                                throw e2;
                            }
                        } else {
                            return null;
                        }
                    }
                }, acc);
    } catch (java.security.PrivilegedActionException pae) {
        throw (ClassNotFoundException) pae.getException();
    }
    if (result == null) {
        throw new ClassNotFoundException(name);
    }
    return result;
}

private Class&lt;?> defineClass(String name, Resource res) throws IOException {
    long t0 = System.nanoTime();
    int i = name.lastIndexOf('.');
    URL url = res.getCodeSourceURL();
    if (i != -1) {
        String pkgname = name.substring(0, i);
        Manifest man = res.getManifest();
        // 校验资源的Package
        if (getAndVerifyPackage(pkgname, man, url) == null) {
            try {
                if (man != null) {
                    definePackage(pkgname, man, url);
                } else {
                    definePackage(pkgname, null, null, null, null, null, null, null);
                }
            } catch (IllegalArgumentException iae) {
                if (getAndVerifyPackage(pkgname, man, url) == null) {
                    throw new AssertionError("Cannot find package " +
                            pkgname);
                }
            }
        }
    }
    // 内部使用Resource#getInputStream，获取ByteBuffer，开始真正的数据读取和class定义
    java.nio.ByteBuffer bb = res.getByteBuffer();
    if (bb != null) {
        CodeSigner[] signers = res.getCodeSigners();
        CodeSource cs = new CodeSource(url, signers);
        PerfCounter.getReadClassBytesTime().addElapsedTimeFrom(t0);
        return defineClass(name, bb, cs);
    } else {
        byte[] b = res.getBytes();
        CodeSigner[] signers = res.getCodeSigners();
        CodeSource cs = new CodeSource(url, signers);
        PerfCounter.getReadClassBytesTime().addElapsedTimeFrom(t0);
        return defineClass(name, b, 0, b.length, cs);
    }
}

URLClassPath​	配合 URLClassLoader 使用，负责在所有 classpath URL 中懒加载并定位资源（如 .class 或配置文件）。其核心方法 getResource 的处理流程如下：

延迟创建并缓存每个 URL 对应的 Loader
Loader构造具体目标资源的 URL，并通过其协议的 URLStreamHandler 创建URLConnection
若连接有效，返回封装好的 Resource 对象（包含 InputStream 等）
若未命中资源，继续遍历下一个 Loader


public class URLClassPath {
    // URLClassLoader里所有classpath下的URL
    private final ArrayList&lt;URL> path;

    // // 尚未初始化的 URL 列表（懒加载机制）
    private final ArrayDeque&lt;URL> unopenedUrls;

    // loader缓存，1个loader对应一个URL
    private final ArrayList&lt;Loader> loaders = new ArrayList&lt;>();

    // loader和URL的关系缓存
    // key比如
    // jar://file:/Users/reef/IdeaProjects/soil/target/soil-1.0.0.jar!/BOOT-INF/lib/spring-context-5.3.31.jar!/
    private final HashMap&lt;String, Loader> lmap = new HashMap&lt;>();

    public Resource getResource(String name, boolean check) {

        Loader loader;
        for (int i = 0; (loader = getLoader(i)) != null; i++) {
            Resource res = loader.getResource(name, check);
            if (res != null) {
                return res;
            }
        }
        return null;
    }

    private synchronized Loader getLoader(int index) {
        if (closed) {
            return null;
        }
        // 遍历完了loaders，尝试增加未open的URL
        while (loaders.size() &lt; index + 1) {
            final URL url;
            synchronized (unopenedUrls) {
                url = unopenedUrls.pollFirst();
                // url为null则表示所有URL都以open了
                if (url == null)
                    return null;
            }
            String urlNoFragString = URLUtil.urlNoFragString(url);
            if (lmap.containsKey(urlNoFragString)) {
                continue;
            }
            Loader loader;
            try {
                // 创建URL的Loader
                loader = getLoader(url);

                URL[] urls = loader.getClassPath();
                if (urls != null) {
                    push(urls);
                }
            } catch (IOException e) {
                continue;
            } catch (SecurityException se) {
                if (DEBUG) {
                    System.err.println("Failed to access " + url + ", " + se);
                }
                continue;
            }
            // loader缓存
            loaders.add(loader);
            lmap.put(urlNoFragString, loader);
        }
        return loaders.get(index);
    }

    private Loader getLoader(final URL url) throws IOException {
        try {
            return AccessController.doPrivileged(
                    new PrivilegedExceptionAction&lt;>() {
                        public Loader run() throws IOException {
                            String protocol = url.getProtocol();
                            String file = url.getFile();
                            if (file != null &amp;&amp; file.endsWith("/")) {
                                if ("file".equals(protocol)) {
                                    return new FileLoader(url);
                                } else if ("jar".equals(protocol) &amp;&amp;
                                        isDefaultJarHandler(url) &amp;&amp;
                                        file.endsWith("!/")) {
                                    // JarHandler为jdk默认的sun.net.www.protocol.jar.Handler才会进入
                                    URL nestedUrl = new URL(file.substring(0, file.length() - 2));
                                    return new JarLoader(nestedUrl, jarHandler, lmap, acc);
                                } else {
                                    // SpringBoot fatjar会创建这个Loader
                                    return new Loader(url);
                                }
                            } else {
                                return new JarLoader(url, jarHandler, lmap, acc);
                            }
                        }
                    }, acc);
        } catch (PrivilegedActionException pae) {
            throw (IOException) pae.getException();
        }
    }

    private static class Loader implements Closeable {
        Resource getResource(final String name, boolean check) {
            final URL url;
            try {
                // 构造具体资源的URL，举例
                // base为 jar:file:/Users/reef/IdeaProjects/soil/target/soil-1.0.0.jar!/BOOT-INF/lib/hutool-core-5.8.25.jar!/
                // spec为 cn/hutool/core/thread/AsyncUtil.class
                url = new URL(base, ParseUtil.encodePath(name, false));
            } catch (MalformedURLException e) {
                throw new IllegalArgumentException("name");
            }
            final URLConnection uc;
            try {
                if (check) {
                    URLClassPath.check(url);
                }
                // 通过URL内部的Handler构造URLConnection
                uc = url.openConnection();
                // SpringBoot的JarURLConnection如果不存在指定的资源，这里面会抛异常
                InputStream in = uc.getInputStream();
                if (uc instanceof JarURLConnection) {
                    /*
                     * Need to remember the jar file so it can be closed
                     * in a hurry.
                     */
                    JarURLConnection juc = (JarURLConnection) uc;

                    boolean firstLoad = jarfile == null;

                    jarfile = JarLoader.checkJar(juc.getJarFile());

                    if (firstLoad &amp;&amp; JarLoadEvent.isEnabled()) {
                        Tooling.notifyEvent(JarLoadEvent.jarLoadEvent(url, jarfile));
                    }
                }
            } catch (Exception e) {
                return null;
            }
            // 找到了资源，构造对应的Resource
            return new Resource() {
                public String getName() {
                    return name;
                }

                public URL getURL() {
                    return url;
                }

                public URL getCodeSourceURL() {
                    return base;
                }

                public InputStream getInputStream() throws IOException {
                    return uc.getInputStream();
                }

                public int getContentLength() throws IOException {
                    return uc.getContentLength();
                }
            };
        }
    }
}

测试用例可以跟着这个用例debug一下，看看整体的LaunchedURLClassLoader的loadClass流程
public class LaunchedURLClassLoaderDemo {

    public static void main(String[] args) throws Exception {
        String fatJarPath = System.getProperty("user.home") + "/IdeaProjects/soil/target/soil-1.0.0.jar";
        File fatJar = new File( fatJarPath);
        Assert.isTrue(fatJar.exists(), "Fat jar not found");
        JarFile jarFile = new JarFile(fatJar);
        JarFile nestedJar = jarFile.getNestedJarFile(jarFile.getJarEntry("BOOT-INF/lib/hutool-json-5.8.25.jar"));
        // 内部会直接创建org.springframework.boot.loader.jar.handler，所以在这里可以先不注册java.protocol.handler.pkgs
        URL jsonUrl = nestedJar.getUrl();
        // ======== 此时必须注册jar包处理器org.springframework.boot.loader.jar.handler，才能读取fatjar =========
        JarFile.registerUrlProtocolHandler();
        // eg: jar:file:/Users/reef/IdeaProjects/soil/target/soil-1.0.0.jar!/BOOT-INF/lib/hutool-core-5.8.25.jar!/
        URL coreUrl = new URL("jar:file:" + fatJarPath + "!/BOOT-INF/lib/hutool-core-5.8.25.jar!/");
        // 创建 LaunchedURLClassLoader
        ClassLoader appClassLoader = LaunchedURLClassLoaderDemo.class.getClassLoader();
        try (LaunchedURLClassLoader classLoader = new LaunchedURLClassLoader(new URL[]{jsonUrl, coreUrl}, appClassLoader)) {
            String coreJarClass = "cn.hutool.core.thread.AsyncUtil";
            String jsonJarClass = "cn.hutool.json.JSONUtil";
            // 确保当前运行环境的classpath没有指定的class
            Assertions.assertThrows(ClassNotFoundException.class, () -> appClassLoader.loadClass(coreJarClass));
            Assertions.assertThrows(ClassNotFoundException.class, () -> appClassLoader.loadClass(jsonJarClass));
            // 使用自定义的LaunchedURLClassLoader加载class
            loadAndAssert(classLoader, coreJarClass);
            loadAndAssert(classLoader, jsonJarClass);
        }
        jarFile.close();
    }


    private static void loadAndAssert(ClassLoader loader, String className) throws Exception {
        Class&lt;?> clazz = loader.loadClass(className);
        Assertions.assertNotNull(clazz);
        Assertions.assertSame(loader, clazz.getClassLoader(), "Class not loaded from expected classloader");
        System.out.printf("Loaded class: %-40s → %s%n", className, clazz.getProtectionDomain().getCodeSource().getLocation());
    }

}

总结通过上诉启动流程和LaunchedURLClassLoader#loadClass源码的分析，现在可以对前面的核心组件进行串联一下

Archive组件仅在fatjar启动阶段使用，负责将fatjar内所有资源解析为jar协议的classpath URL，并用其构造LaunchedURLClassLoader，用于后续类加载的使用

JarFile &#x2F; JarEntry &#x2F; URLStreamHandler &#x2F; JarURLConnection：用于类加载阶段，流程如下

​	LaunchedURLClassLoader#loadClass  →  URLClassPath#getResource → URL#openConnection → URLStreamHandler 创建 JarURLConnection → 解析和获取 JarFile 和 JarEntry → JarURLConnection#getInputStream -&gt; InputStream加载 .class 字节 → defineClass



]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>fatjar</tag>
        <tag>LaunchedURLClassLoader</tag>
        <tag>URLClassLoader</tag>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot（三）— 自动配置源码解析</title>
    <url>/2022-03-26/springboot-zi-dong-pei-zhi-yuan-ma-jie-xi/</url>
    <content><![CDATA[​	基于 Spring Boot 2.7.x 版本，深入剖析了 @EnableAutoConfiguration 注解的实现原理，重点解析了其背后通过 DeferredImportSelector 实现的自动配置机制。特别对 @AutoConfigureBefore 与 @AutoConfigureAfter 所涉及的 DFS 拓扑排序逻辑 进行了详细的分析，揭示了自动配置类加载顺序的核心控制机制
​	最后，还分析了 2.7.0 版本新增的 @AutoConfiguration 注解的特殊语义，包括其与新的 .imports SPI 文件的绑定、默认排除扫描机制（AutoConfigurationExcludeFilter）。并给出了自己的使用建议


@EnableAutoConfiguration​	Spring Boot 之所以能实现开箱即用，核心在于其自动配置机制，具体体现在 @EnableAutoConfiguration 注解的作用上。该注解会为项目注册大量默认的 Bean，从而简化开发的配置工作
​	@EnableAutoConfiguration 本身并不直接生效，它是依赖了如下这个元注解（Spring 在处理配置类时会通过 AnnotationUtils递归解析所有注解的元注解，从而将所有元注解的功能集成到一个组合注解上）
@Import(AutoConfigurationImportSelector.class)

​	通过前面分析的章节，可知@Import注解会在ConfigurationClassPostProcessor解析配置类阶段生效。其注册的AutoConfigurationImportSelector这才是真正的获取自动配置类的核心，它实现了DeferredImportSelector
​	与其它 @Import 导入的class不同，DeferredImportSelector会在所有常规的配置类（包括 @Configuration 的 full和@Component和lite模式）处理完成之后，再统一处理并解析其导入的相关配置类，这机制确保了自动配置不会抢占开发者自定义的配置解析和注册Bean的顺序，始终遵循用户配置优先原则
DeferredImportSelector​	DeferredImportSelector 是 ImportSelector 的一个子接口，它扩展了一个关键方法 getImportGroup()，用于支持按Group延迟导入配置类
​	getImportGroup()会返回 DeferredImportSelector.Group 对象，这才是真正处理用来DeferredImportSelector逻辑，这个Group包含了如下特征

Group加载的class可以理解为一个包，其中的类会在一起做过滤、排序等操作
最终返回结果交给上层 ConfigurationClassParser 统一执行其配置类的解析

​	到现在2.7.x版本位置，也就只有一个Group为AutoConfigurationImportSelector.AutoConfigurationGroup，是SpringBoot 为自动配置机制专门提供的 Group 实现，用于处理.imports和spring.factories里的自动配置类，并应用 AutoConfigurationImportFilter、排序等核心逻辑
AutoConfigurationImportSelector其核心方法为getAutoConfigurationEntry，主要逻辑如下。在此之前，可以先看看SPI机制这篇文章

利用SPI机制，加载如下配置类


META-INF&#x2F;spring.factories配置文件里的org.springframework.boot.autoconfigure.EnableAutoConfiguration
从2.7.0新增的 META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports获取配置类



去重和排除excluded相关类

应用AutoConfigurationImportFilter逻辑，对自动配置类部分Condition进行校验并过滤（AutoConfigurationImportFilter实例也是配置在spring.factories里的）


核心代码public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware,
        ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {

    @Override
    public String[] selectImports(AnnotationMetadata annotationMetadata) {
        if (!isEnabled(annotationMetadata)) {
            return NO_IMPORTS;
        }
        AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(annotationMetadata);
        return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
    }

    protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) {
        // 判断spring.boot.enableautoconfiguration配置是否开启
        if (!isEnabled(annotationMetadata)) {
            return EMPTY_ENTRY;
        }
        AnnotationAttributes attributes = getAttributes(annotationMetadata);
        // 1. 从 META-INF/spring.factories配置文件里获取org.springframework.boot.autoconfigure.EnableAutoConfiguration
        // 2. 从2.7.0新增的 META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports获取配置类
        List&lt;String> configurations = getCandidateConfigurations(annotationMetadata, attributes);
        // 去重
        configurations = removeDuplicates(configurations);
        // apply excluded逻辑
        Set&lt;String> exclusions = getExclusions(annotationMetadata, attributes);
        checkExcludedClasses(configurations, exclusions);
        configurations.removeAll(exclusions);
        /*
         通过配置在spring.factories里的AutoConfigurationImportFilter过滤一遍，提前剔除明显不满足条件的配置类，提高启动性能。有如下三个Filter：
             1. org.springframework.boot.autoconfigure.condition.OnBeanCondition：apply @ConditionalOnSingleCandidate和@ConditionalOnBean逻辑
             2. org.springframework.boot.autoconfigure.condition.OnClassCondition：apply @ConditionalOnClass逻辑
             3. org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition：apply @ConditionalOnWebApplication逻辑
         */
        configurations = getConfigurationClassFilter().filter(configurations);
        // 发布AutoConfigurationImportEvent
        fireAutoConfigurationImportEvents(configurations, exclusions);
        return new AutoConfigurationEntry(configurations, exclusions);
    }

}

AutoConfigurationGroup是自动配置类导入的最终调度执行者，由 ConfigurationClassParser 在配置类解析流程的最后阶段统一触发，调用链如下：：


ConfigurationClassParser#parse
ConfigurationClassParser.DeferredImportSelectorHandler#process
ConfigurationClassParser.DeferredImportSelectorGroupingHandler#processGroupImports
ConfigurationClassParser.DeferredImportSelectorGrouping#getImports


其主要有两个方法：

AutoConfigurationGroup#process：主要是利用AutoConfigurationImportSelector获取自动配置类，并缓存到其内部的entries中

AutoConfigurationGroup#selectImports：使用AutoConfigurationSorter对自动配置类进行排序，排序的优先级为：

@AutoConfigureBefore和@AutoConfigureAfter &gt; @AutoConfigureOrder



核心代码private static class AutoConfigurationGroup
        implements DeferredImportSelector.Group, BeanClassLoaderAware, BeanFactoryAware, ResourceLoaderAware {

    @Override
    public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) {
        Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector,
                () -> String.format("Only %s implementations are supported, got %s",
                        AutoConfigurationImportSelector.class.getSimpleName(),
                        deferredImportSelector.getClass().getName()));
        // 获取自动配置类并缓存到entries里
        AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector)
                .getAutoConfigurationEntry(annotationMetadata);
        this.autoConfigurationEntries.add(autoConfigurationEntry);
        for (String importClassName : autoConfigurationEntry.getConfigurations()) {
            this.entries.putIfAbsent(importClassName, annotationMetadata);
        }
    }

    @Override
    public Iterable&lt;Entry> selectImports() {
        if (this.autoConfigurationEntries.isEmpty()) {
            return Collections.emptyList();
        }
        Set&lt;String> allExclusions = this.autoConfigurationEntries.stream()
                .map(AutoConfigurationEntry::getExclusions)
                .flatMap(Collection::stream)
                .collect(Collectors.toSet());
        Set&lt;String> processedConfigurations = this.autoConfigurationEntries.stream()
                .map(AutoConfigurationEntry::getConfigurations)
                .flatMap(Collection::stream)
                .collect(Collectors.toCollection(LinkedHashSet::new));
        // 排除excluded配置类
        processedConfigurations.removeAll(allExclusions);
        // 关键排序：@AutoConfigureBefore和@AutoConfigureAfter优先级 > @AutoConfigureOrder
        return sortAutoConfigurations(processedConfigurations, getAutoConfigurationMetadata()).stream()
                .map((importClassName) -> new Entry(this.entries.get(importClassName), importClassName))
                .collect(Collectors.toList());
    }

}

AutoConfigurationSorter​	自动配置类的解析顺序是非常重要的，尤其是在使用 @ConditionalOnBean、@ConditionalOnMissingBean 等条件注解时，先加载的配置类有优先对Bean的注册决定权，从而影响后续自动配置类中相同类型Bean的注册。且由于所有自动配置类都统一通过 DeferredImportSelector 延迟导入，因此必须在导入前进行统一排序，保证顺序稳定且可控。
​	所以，SpringBoot提供了如下三个注解，来决定自动配置类解析的先后顺序


@AutoConfigureBefore：当前配置类应当 在指定类之前加载
@AutoConfigureAfter：当前配置类应当 在指定类之后加载
@AutoConfigureOrder：指定一个整数顺序值，数字越小，优先级越高


@AutoConfigureAfter和@AutoConfigureBefore这两个注解构成了一个类之间的依赖图，SpringBoot 会对这些依赖关系进行拓扑排序。不同于常见的入度统计法，SpringBoot用了深度优先遍历（DFS）+ 判环的方式实现排序。
排序原理
按 @AutoConfigureOrder 初步排序

​	所有配置类根据注解的数值顺序进行一次粗排序，为后续 DFS 提供遍历顺序。 


依赖链补齐

​	收集所有声明在 @AutoConfigureBefore和 @AutoConfigureAfter 中提到的类（尽管它们可能被excluded），将其一并加入拓扑图，保证排序图完整


执行 DFS 拓扑排序（带判环）

​	对每个配置类递归处理其前置依赖类（**@AutoConfigureAfter直接解析当前配置类就行，但@AutoConfigureBefore需要解析所有的自动配置类。我上一篇讲的starter优化器在这里会发挥作用，获取相关注解的预解析结果，间接提升启动速度），在递归中动态构造有向图，并检测循环依赖**（若存在环则抛出异常）


过滤出最终导入的配置类

​	拓扑排序后将得到一个全有序列表，SpringBoot 再从中筛选出当前实际需要导入的类，作为最终结果返回。



核心代码class AutoConfigurationSorter {

    List&lt;String> getInPriorityOrder(Collection&lt;String> classNames) {
        AutoConfigurationClasses classes = new AutoConfigurationClasses(this.metadataReaderFactory,
                this.autoConfigurationMetadata, classNames);
        List&lt;String> orderedClassNames = new ArrayList&lt;>(classNames);
        // Initially sort alphabetically
        Collections.sort(orderedClassNames);
        // Then sort by order
        // 先按@AutoConfigureOrder排序
        orderedClassNames.sort((o1, o2) -> {
            int i1 = classes.get(o1).getOrder();
            int i2 = classes.get(o2).getOrder();
            return Integer.compare(i1, i2);
        });
        // Then respect @AutoConfigureBefore @AutoConfigureAfter
        orderedClassNames = sortByAnnotation(classes, orderedClassNames);
        return orderedClassNames;
    }

    private List&lt;String> sortByAnnotation(AutoConfigurationClasses classes, List&lt;String> classNames) {
        // 待排列表
        List&lt;String> toSort = new ArrayList&lt;>(classNames);
        // 加入所有参与排序的相关类。比如说某个配置类的@AutoConfigureBefore中的value不是配置类或者被excluded了，此时也要加入进来，使拓扑排序的链路更完整
        toSort.addAll(classes.getAllNames());
        // 已排序列表
        Set&lt;String> sorted = new LinkedHashSet&lt;>();
        // 处理中（检测循环依赖）
        Set&lt;String> processing = new LinkedHashSet&lt;>();
        // 开始排序
        while (!toSort.isEmpty()) {
            doSortByAfterAnnotation(classes, toSort, sorted, processing, null);
        }
        // 排序完毕，按顺序只保留classNames相关类
        sorted.retainAll(classNames);
        return new ArrayList&lt;>(sorted);
    }

    /**
     * 拓扑排序的dfs实现方案（非统计入度方式实现）
     * 排序规则：
     *   1. 若类 A 上标注 @AutoConfigureAfter(B)，则 B 必须排在 A 之前
     *   2. 若类 A 上标注 @AutoConfigureBefore(B)，则 A 必须排在 B 之前
     */
    private void doSortByAfterAnnotation(AutoConfigurationClasses classes, List&lt;String> toSort, Set&lt;String> sorted,
            Set&lt;String> processing, String current) {
        if (current == null) {
            current = toSort.remove(0);
        }
        processing.add(current);
        // 依次处理每个current类的依赖类（也就是说需要确保current 排在 after 之后）
        for (String after : classes.getClassesRequestedAfter(current)) {
            // 拓扑排序中判环操作，避免循环依赖
            checkForCycles(processing, current, after);
            // 只有当该类还没被排序，且在待排序列表中，才递归处理依赖类after
            if (!sorted.contains(after) &amp;&amp; toSort.contains(after)) {
                doSortByAfterAnnotation(classes, toSort, sorted, processing, after);
            }
        }
        processing.remove(current);
        // current的依赖都已处理完毕，此时可以放入current了
        sorted.add(current);
    }

    private void checkForCycles(Set&lt;String> processing, String current, String after) {
        Assert.state(!processing.contains(after),
                () -> "AutoConfigure cycle detected between " + current + " and " + after);
    }

    private static class AutoConfigurationClasses {

        /**
         * 获取某个类的所有排序依赖类（即必须排在className之前的类）
         */
        Set&lt;String> getClassesRequestedAfter(String className) {
            // @AutoConfigureAfter处理
            Set&lt;String> classesRequestedAfter = new LinkedHashSet&lt;>(get(className).getAfter());
            // @AutoConfigureBefore只能遍历所有的配置类，依次判断是否包含当前的className
            this.classes.forEach((name, autoConfigurationClass) -> {
                if (autoConfigurationClass.getBefore().contains(className)) {
                    classesRequestedAfter.add(name);
                }
            });
            return classesRequestedAfter;
        }

    }

}

@AutoConfiguration@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Configuration(proxyBeanMethods = false)
@AutoConfigureBefore
@AutoConfigureAfter
public @interface AutoConfiguration {
  // ... 省略
}

是2.7.0版本新增的自动配置相关的注解，专门用于声明自动配置类。从定义上看，它是一个组合注解，整合了：

@Configuration：标识该类是一个配置类
@AutoConfigureBefore &#x2F; @AutoConfigureAfter：用于声明自动配置类之间的依赖顺序

但它并不只是简单的注解组合，而是具备了特殊语义
特殊语义新的SPI​	支持新的 SPI 加载机制（.imports 文件），可以从META-INF&#x2F;spring&#x2F;org.springframework.boot.autoconfigure.AutoConfiguration.imports文件里加载自动配置类。从另一方面来说，其把自动配置类从spring.factories文件里解耦出来了
AutoConfigurationExcludeFilter@SpringBootApplication有如下这个元注解，对包扫描器增加了AutoConfigurationExcludeFilter这个过滤器
@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
        @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })

AutoConfigurationExcludeFilter会自动排出满足一下任意条件的类：


有@AutoConfiguration注解
SPI文件里的自动配置类


也就是说：所有使用 @AutoConfiguration 的类将被默认包扫描排除，不会参与常规的组件扫描逻辑
核心代码private boolean isAutoConfiguration(MetadataReader metadataReader) {
    // @AutoConfiguration注解是否存在
    boolean annotatedWithAutoConfiguration = metadataReader.getAnnotationMetadata()
            .isAnnotated(AutoConfiguration.class.getName());
    return annotatedWithAutoConfiguration
            || getAutoConfigurations().contains(metadataReader.getClassMetadata().getClassName());
}

protected List&lt;String> getAutoConfigurations() {
    if (this.autoConfigurations == null) {
        // spring.factories里的自动配置类
        List&lt;String> autoConfigurations = new ArrayList&lt;>(
                SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, this.beanClassLoader));
        // .imports文件里的自动配置类
        ImportCandidates.load(AutoConfiguration.class, this.beanClassLoader).forEach(autoConfigurations::add);
        this.autoConfigurations = autoConfigurations;
    }
    return this.autoConfigurations;
}

总结​	从源码来反推@AutoConfiguration的使用场景，可以得出一个明确的使用约定：

@AutoConfiguration 注解的类必须通过 SPI文件注册，不能依赖常规的包扫描导入。

​	无论该类是来自第三方 starter 还是当前项目模块，只要标注了 @AutoConfiguration，就不会被@SpringBootApplication 自动注册，而只能走自动配置的延迟导入机制（DeferredImportSelector）流程。
​	所以，在当前SpringBoot启动项目中，谨慎使用@AutoConfiguration，尽管它内部组合了 @Configuration，但它不等价于普通的配置类
相关链接
@Import处理
SPI机制

]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>拓扑排序</tag>
        <tag>自动配置</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot（四） — Condition相关原理</title>
    <url>/2022-04-21/springboot-conditional-zhu-jie-xiang-guan-yuan-li/</url>
    <content><![CDATA[​	基于Spring Boot 2.7.x 版本，深入分析了OnBean、OnClass、OnProperty这三类常见Condition的源码实现，在此基础上，探讨了 @Conditional 注解的组合用法（与、或、非逻辑）的处理机制。
​	同时，分析了Condition匹配结果的debug支持实现，以及 ConfigurationClassPostProcessor 中Condition判断的触发流程，重点关注其通过 importedBy 链支持的 TrackedConditionEvaluator 回溯与剪枝优化策略
​	最后，提供了逻辑或@Conditional组合与 importedBy路径 skip 判定的测试用例，以验证整体逻辑的正确性


Conditional注解​	项目中常用的@ConditionalOnBean，@ConditionalOnClass，@ConditionalOnProperty等注解都有一个共同的元注解@Conditional，Spring通过这个元注解@Conditional中指定的Condition类来判断某个配置类或Bean 是否应该被加载。Condition接口定义如下
@FunctionalInterface
public interface Condition {
    boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);
}

​	其中参数作用如下：

ConditionContext：提供**Condition评估所需的上下文环境**。包括BeanFactory，BeanDefinitionRegistry和Environment等组件
AnnotatedTypeMetadata：当前@Conditional所标注的类或方法上的所有注解元信息

我这里只分析了常用的bean，properties，和class相关的Condition。套路都一样，剩下的可自行分析
OnBeanCondition​	是@ConditionalOnBean、@ConditionalOnSingleCandidate、@ConditionalOnMissingBean专用的Condition实现类，核心作用是根据注解中指定的 type &#x2F; name &#x2F; annotation 等参数，判断当前容器中是否存在匹配的 Bean，并根据注解功能来解析结果
Spec​	是对上述三个注解的统一解析封装结构，用于抽象出注解中的条件信息，每一个配置类或方法上存在的相关注解，最终都会被解析为一个 Spec 实例，其具体参数如下
private static class Spec&lt;A extends Annotation> {

    private final ClassLoader classLoader;

    private final Class&lt;? extends Annotation> annotationType;

    private final Set&lt;String> names;

    private final Set&lt;String> types;

    private final Set&lt;String> annotations;

    private final Set&lt;String> ignoredTypes;

    private final Set&lt;Class&lt;?>> parameterizedContainers;

    private final SearchStrategy strategy;

    Spec(ConditionContext context, AnnotatedTypeMetadata metadata, MergedAnnotations annotations,
            Class&lt;A> annotationType) {
        MultiValueMap&lt;String, Object> attributes = annotations.stream(annotationType)
                .filter(MergedAnnotationPredicates.unique(MergedAnnotation::getMetaTypes))
                .collect(MergedAnnotationCollectors.toMultiValueMap(Adapt.CLASS_TO_STRING));
        MergedAnnotation&lt;A> annotation = annotations.get(annotationType);
        this.classLoader = context.getClassLoader();
        this.annotationType = annotationType;
        // name属性解析，即beanName
        this.names = extract(attributes, "name");
        // annotation属性，即bean上的注解
        this.annotations = extract(attributes, "annotation");
        this.ignoredTypes = extract(attributes, "ignored", "ignoredType");
        this.parameterizedContainers = resolveWhenPossible(extract(attributes, "parameterizedContainer"));
        this.strategy = annotation.getValue("search", SearchStrategy.class).orElse(null);
        // value和type解析，即bean class
        Set&lt;String> types = extractTypes(attributes);
        BeanTypeDeductionException deductionException = null;
        // 未配置value和type时，对@Bean方法使用其returnType作为types
        if (types.isEmpty() &amp;&amp; this.names.isEmpty()) {
            try {
                types = deducedBeanType(context, metadata);
            } catch (BeanTypeDeductionException ex) {
                deductionException = ex;
            }
        }
        this.types = types;
        // 校验types，names，annotations至少要有存在一个
        validate(deductionException);
    }
}

MatchResult​	表示某个 Spec 在指定容器上下文中的匹配结果，不同类型的注解会根据自身定义对 MatchResult 的结果进行判断，来决定是否匹配成功
private static final class MatchResult {

    /**
     * annotation对应的bean集合（在容器里）
     */
    private final Map&lt;String, Collection&lt;String>> matchedAnnotations = new HashMap&lt;>();

    /**
     * 在容器里的beanName
     */
    private final List&lt;String> matchedNames = new ArrayList&lt;>();
    /**
     * type对应的bean集合（在容器里）
     */
    private final Map&lt;String, Collection&lt;String>> matchedTypes = new HashMap&lt;>();

    /**
     * annotation对应的bean不在容器中
     */
    private final List&lt;String> unmatchedAnnotations = new ArrayList&lt;>();

    /**
     * beanName对应的bean不在容器中
     */
    private final List&lt;String> unmatchedNames = new ArrayList&lt;>();

    /**
     * type对应的bean不在容器中
     */
    private final List&lt;String> unmatchedTypes = new ArrayList&lt;>();

    private final Set&lt;String> namesOfAllMatches = new HashSet&lt;>();
}

getMatchingBeans​	getMatchingBeans是根据 Spec 提供的条件，在容器里找出符合要求 Bean 的核心方法。可通过如下代码总结出OnBeanCondition支持的核心匹配能力包括：

按type、beanName、annotation搜索对应的bean是否存在
支持搜索父容器（SpringCloud中存在）
支持泛型
支持忽略指定type的bean（等价于搜索结果会remove掉这些ignoreType的bean）

protected final MatchResult getMatchingBeans(ConditionContext context, Spec&lt;?> spec) {
    ClassLoader classLoader = context.getClassLoader();
    ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();
    // 父容器搜索判断（比如SpringCloud环境下存在父容器）
    boolean considerHierarchy = spec.getStrategy() != SearchStrategy.CURRENT;
    // 泛型判断支持（示例：@ConditionalOnMissingFilterBean）
    Set&lt;Class&lt;?>> parameterizedContainers = spec.getParameterizedContainers();
    if (spec.getStrategy() == SearchStrategy.ANCESTORS) {
        BeanFactory parent = beanFactory.getParentBeanFactory();
        Assert.isInstanceOf(ConfigurableListableBeanFactory.class, parent,
                "Unable to use SearchStrategy.ANCESTORS");
        beanFactory = (ConfigurableListableBeanFactory) parent;
    }
    // 匹配结果
    MatchResult result = new MatchResult();
    // 获取需要被忽略的bean的beanName
    Set&lt;String> beansIgnoredByType = getNamesOfBeansIgnoredByType(classLoader, beanFactory, considerHierarchy,
            spec.getIgnoredTypes(), parameterizedContainers);
    // ----------------- 处理类型匹配部分 ------------------
    for (String type : spec.getTypes()) {
        // 获取类型对应的beanName
        Collection&lt;String> typeMatches = getBeanNamesForType(classLoader, considerHierarchy, beanFactory, type,
                parameterizedContainers);
        // 移除被忽略的 Bean 以及scope的代理bean
        typeMatches.removeIf((match) -> beansIgnoredByType.contains(match) || ScopedProxyUtils.isScopedTarget(match));
        if (typeMatches.isEmpty()) { // type过滤后没有对应的bean在容器中，记录为不匹配
            result.recordUnmatchedType(type);
        } else {
            result.recordMatchedType(type, typeMatches);
        }
    }
    // ----------------- 处理注解匹配部分 ------------------
    for (String annotation : spec.getAnnotations()) {
        // 获取被指定注解标记的beanName
        Set&lt;String> annotationMatches = getBeanNamesForAnnotation(classLoader, beanFactory, annotation,
                considerHierarchy);
        // 移除掉被忽略的 bean
        annotationMatches.removeAll(beansIgnoredByType);
        if (annotationMatches.isEmpty()) {// annotation过滤后没有对应的bean在容器中，记录为不匹配
            result.recordUnmatchedAnnotation(annotation);
        } else {
            result.recordMatchedAnnotation(annotation, annotationMatches);
        }
    }
    // ----------------- 处理按beanName匹配部分 ------------------
    for (String beanName : spec.getNames()) {

        if (!beansIgnoredByType.contains(beanName) &amp;&amp; containsBean(beanFactory, beanName, considerHierarchy)) {
            // 没被忽略，切在容器中存在这个beanName。匹配命中
            result.recordMatchedName(beanName);
        } else { // 匹配失败
            result.recordUnmatchedName(beanName);
        }
    }
    return result;
}

getMatchOutcome​	getMatchOutcome会拿 Spec 的匹配结果，结合具体是哪种 @ConditionalOn* 注解，来决定条件是否满足。我这里对getMatchOutcome方法按注解拆分一下，不影响其逻辑
@ConditionalOnBean​	要求所有指定的参数都必须存在对应的bean（即全匹配）。如果有任意一个参数没有对应的bean存在于指定容器中，则不匹配，返回noMatch
public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
    ConditionMessage matchMessage = ConditionMessage.empty();
    MergedAnnotations annotations = metadata.getAnnotations();
    if (annotations.isPresent(ConditionalOnBean.class)) {
        Spec&lt;ConditionalOnBean> spec = new Spec&lt;>(context, metadata, annotations, ConditionalOnBean.class);
        // 进行匹配
        MatchResult matchResult = getMatchingBeans(context, spec);
        if (!matchResult.isAllMatched()) { // 任意一个条件没匹配到bean，则返回noMatch
            String reason = createOnBeanNoMatchReason(matchResult);
            return ConditionOutcome.noMatch(spec.message().because(reason));
        }
        matchMessage = spec.message(matchMessage)
                .found("bean", "beans")
                .items(Style.QUOTE, matchResult.getNamesOfAllMatches());
    }
    // matched
    return ConditionOutcome.match(matchMessage);
}

@ConditionalOnSingleCandidate​	校验指定参数对应的bean在容器中只存在一个bean或一个primary bean，所以@ConditionalOnSingleCandidate的参数也是单个的，仅支持type匹配
public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
    ConditionMessage matchMessage = ConditionMessage.empty();
    MergedAnnotations annotations = metadata.getAnnotations();
    if (metadata.isAnnotated(ConditionalOnSingleCandidate.class.getName())) {
        Spec&lt;ConditionalOnSingleCandidate> spec = new SingleCandidateSpec(context, metadata, annotations);
        MatchResult matchResult = getMatchingBeans(context, spec);
        if (!matchResult.isAllMatched()) {
            return ConditionOutcome.noMatch(spec.message().didNotFind("any beans").atAll());
        }
        Set&lt;String> allBeans = matchResult.getNamesOfAllMatches();
        if (allBeans.size() == 1) { // 只匹配到一个bean，则matched
            matchMessage = spec.message(matchMessage).found("a single bean").items(Style.QUOTE, allBeans);
        } else {
            // 多个bean，再校验是否只有一个primary bean
            List&lt;String> primaryBeans = getPrimaryBeans(context.getBeanFactory(), allBeans,
                    spec.getStrategy() == SearchStrategy.ALL);
            if (primaryBeans.isEmpty()) {
                return ConditionOutcome
                        .noMatch(spec.message().didNotFind("a primary bean from beans").items(Style.QUOTE, allBeans));
            }
            if (primaryBeans.size() > 1) {
                return ConditionOutcome
                        .noMatch(spec.message().found("multiple primary beans").items(Style.QUOTE, primaryBeans));
            }
            matchMessage = spec.message(matchMessage)
                    .found("a single primary bean '" + primaryBeans.get(0) + "' from beans")
                    .items(Style.QUOTE, allBeans);
        }
    }
    // matched
    return ConditionOutcome.match(matchMessage);
}

@ConditionalOnMissingBean和@ConditionalOnBean完全相反，所有参数都不能存在对应的bean在指定容器里（全不匹配）才matched
public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
    ConditionMessage matchMessage = ConditionMessage.empty();
    MergedAnnotations annotations = metadata.getAnnotations();
    // -------------- @ConditionalOnMissingBean 注解处理 --------------
    if (metadata.isAnnotated(ConditionalOnMissingBean.class.getName())) {
        Spec&lt;ConditionalOnMissingBean> spec = new Spec&lt;>(context, metadata, annotations,
                ConditionalOnMissingBean.class);
        MatchResult matchResult = getMatchingBeans(context, spec);
        if (matchResult.isAnyMatched()) { // 任意一个条件匹配到了bean，apply注解逻辑返回noMatch
            String reason = createOnMissingBeanNoMatchReason(matchResult);
            return ConditionOutcome.noMatch(spec.message().because(reason));
        }
        matchMessage = spec.message(matchMessage).didNotFind("any beans").atAll();
    }
    // matched
    return ConditionOutcome.match(matchMessage);
}

OnClassCondition​	被@ConditionalOnClass和@ConditionalOnMissingClass使用，用来判断指定的class是否存在于指定ClassLoader的classpath里
ClassNameFilter两个Filter，PRESENT和MISSING，内部通过Class#forName方法判断指定的class能否被指定的ClassLoader加载（即在其classpath下）
protected enum ClassNameFilter {

    PRESENT {

        @Override
        public boolean matches(String className, ClassLoader classLoader) {
            return isPresent(className, classLoader);
        }

    },

    MISSING {

        @Override
        public boolean matches(String className, ClassLoader classLoader) {
            return !isPresent(className, classLoader);
        }

    };

    abstract boolean matches(String className, ClassLoader classLoader);

    static boolean isPresent(String className, ClassLoader classLoader) {
        if (classLoader == null) {
            classLoader = ClassUtils.getDefaultClassLoader();
        }
        try {
            // 使用Class.forName检测class是否存在。
            if (classLoader != null) {
                Class.forName(className, false, classLoader);
            } else {
                Class.forName(className);
            }
            return true;
        } catch (Throwable ex) {
            // 不存的在会抛ClassNotFoundException，被异常捕获返回false
            return false;
        }
    }

}

getMatchOutcome@ConditionalOnClass利用ClassNameFilter.MISSING校验指定的class都必须存在
public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
    ClassLoader classLoader = context.getClassLoader();
    ConditionMessage matchMessage = ConditionMessage.empty();
    // 解析@ConditionalOnClass的value和name
    List&lt;String> onClasses = getCandidates(metadata, ConditionalOnClass.class);
    if (onClasses != null) {
        // ClassNameFilter.MISSING过滤器得到的结果表示 在指定ClassLoader下不存在对应的class
        List&lt;String> missing = filter(onClasses, ClassNameFilter.MISSING, classLoader);
        if (!missing.isEmpty()) { // 任意一个class不存在，不满足@ConditionalOnClass逻辑，返回noMatch
            return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class)
                    .didNotFind("required class", "required classes")
                    .items(Style.QUOTE, missing));
        }
        matchMessage = matchMessage.andCondition(ConditionalOnClass.class)
                .found("required class", "required classes")
                .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader));
    }
    return ConditionOutcome.match(matchMessage);
}

@ConditionalOnMissingClass利用ClassNameFilter.PRESENT校验指定的class都不能存在
public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
    ClassLoader classLoader = context.getClassLoader();
    ConditionMessage matchMessage = ConditionMessage.empty();
    // 解析@ConditionalOnMissingClass的value和name
    List&lt;String> onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class);
    if (onMissingClasses != null) {
        // ClassNameFilter.PRESENT过滤器得到的结果表示 在指定ClassLoader下存在对应的class
        List&lt;String> present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader);
        if (!present.isEmpty()) { // 任意一个class存在，不满足@ConditionalOnMissingClass逻辑，返回noMatch
            return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class)
                    .found("unwanted class", "unwanted classes")
                    .items(Style.QUOTE, present));
        }
        matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class)
                .didNotFind("unwanted class", "unwanted classes")
                .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader));
    }
    return ConditionOutcome.match(matchMessage);
}

OnPropertyCondition被@ConditionalOnProperty使用，可根据指定的属性判断是否存在对应的value在Spring的Environment中
Spec是对@ConditionalOnProperty注解的统一解析封装结构，并通过内部的collectProperties方法进行配置匹配
private static class Spec {

    private final String prefix;

    private final String havingValue;

    private final String[] names;

    private final boolean matchIfMissing;

    private void collectProperties(PropertyResolver resolver, List&lt;String> missing, List&lt;String> nonMatching) {
        for (String name : this.names) {
            // 对每个属性添加prefix
            String key = this.prefix + name;
            if (resolver.containsProperty(key)) {
                // 有这个属性，根据value是否匹配校验
                if (!isMatch(resolver.getProperty(key), this.havingValue)) {
                    nonMatching.add(name);
                }
            } else {
                // 没这个属性，则根据matchIfMissing来判断
                if (!this.matchIfMissing) {
                    missing.add(name);
                }
            }
        }
    }

    private boolean isMatch(String value, String requiredValue) {
        if (StringUtils.hasLength(requiredValue)) {
            return requiredValue.equalsIgnoreCase(value);
        }
        // havingValue未配值时
        return !"false".equalsIgnoreCase(value);
    }

}

getMatchOutcome只关注内部核心determineOutcome方法，并根据其对配置匹配结果的处理，可总结出如下规则（满足任意规则都会返回noMatch）：

不存在对应配置key时：matchIfMissing&#x3D;false
存在对应配置key时：其value和havingValue不匹配


private ConditionOutcome determineOutcome(AnnotationAttributes annotationAttributes, PropertyResolver resolver) {
    Spec spec = new Spec(annotationAttributes);
    List&lt;String> missingProperties = new ArrayList&lt;>();
    List&lt;String> nonMatchingProperties = new ArrayList&lt;>();
    spec.collectProperties(resolver, missingProperties, nonMatchingProperties);
    if (!missingProperties.isEmpty()) {// 没对应的属性，且matchIfMissing=false。返回noMatch
        return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnProperty.class, spec)
                .didNotFind("property", "properties")
                .items(Style.QUOTE, missingProperties));
    }
    if (!nonMatchingProperties.isEmpty()) { // 有对应的属性，但其value不匹配。也返回noMatch
        return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnProperty.class, spec)
                .found("different value in property", "different value in properties")
                .items(Style.QUOTE, nonMatchingProperties));
    }
    return ConditionOutcome
            .match(ConditionMessage.forCondition(ConditionalOnProperty.class, spec).because("matched"));
}

Conditional组合​	前面介绍的条件注解默认是与逻辑：多个 @Conditional 注解应用在同一个配置类或方法上时，只有全部满足，才会注册对应的 Bean
​	但在某些场景下，我们可能需要更复杂的组合判断逻辑（任意满足 -&gt; 或，全部不满足 -&gt; 非）。SpringBoot 为此提供了一个通用的组合条件抽象工具：AbstractNestedCondition，并基于它提供了三种常用组合实现
AbstractNestedCondition这是一个抽象类，SpringBoot 用它来实现条件组合的能力。它的核心逻辑为：

查找该当前Condition类中所有的内部类
对内部类上定义的 Condition 逐个执行 matches 匹配
收集每个内部类整体的匹配结果（内部类上多个 Condition 是与逻辑）
最终调用模板方法 getFinalMatchOutcome()，由子类决定这些匹配结果是否通过（实现“与”、“或”、“非”逻辑）

​	需要注意的是在收集某个内部类的ConditionOutcome结果时调用了getUltimateOutcome这个方法，其会对内部类所有的ConditionOutcome做与逻辑判断并返回成一个ConditionOutcome。因此要想实现更细粒度的组合，应将每个Conditional注解拆分到不同的内部类中

public abstract class AbstractNestedCondition extends SpringBootCondition implements ConfigurationCondition {

    private final ConfigurationPhase configurationPhase;

    @Override
    public ConfigurationPhase getConfigurationPhase() {
        return this.configurationPhase;
    }

    @Override
    public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {
        String className = getClass().getName();
        // 构造内部条件集合（每个内部类及其 @Condition）
        MemberConditions memberConditions = new MemberConditions(context, this.configurationPhase, className);
        // 获取所有内部条件的匹配结果
        MemberMatchOutcomes memberOutcomes = new MemberMatchOutcomes(memberConditions);
        // 委托给子类决定最终结果（与、或、非逻辑）
        return getFinalMatchOutcome(memberOutcomes);
    }

    /**
     * 留给子类实现的逻辑，参数为内部所有 Condition 的匹配结果集合。
     */
    protected abstract ConditionOutcome getFinalMatchOutcome(MemberMatchOutcomes memberOutcomes);

    protected static class MemberMatchOutcomes {

        // 全部结果
        private final List&lt;ConditionOutcome> all;

        // 匹配成功的
        private final List&lt;ConditionOutcome> matches;

        // 匹配失败的
        private final List&lt;ConditionOutcome> nonMatches;

    }

    private static class MemberConditions {

        private final ConditionContext context;

        private final MetadataReaderFactory readerFactory;

        private final Map&lt;AnnotationMetadata, List&lt;Condition>> memberConditions;

        // key：内部类的注解元数据；value：其上声明的所有 Condition 实例
        MemberConditions(ConditionContext context, ConfigurationPhase phase, String className) {
            this.context = context;
            this.readerFactory = new SimpleMetadataReaderFactory(context.getResourceLoader());
            // 获取这个className所有的内部类
            String[] members = getMetadata(className).getMemberClassNames();
            // 实例化内部类上的所有Condition
            this.memberConditions = getMemberConditions(members, phase, className);
        }

        // 进行Condition的匹配并返回结果
        List&lt;ConditionOutcome> getMatchOutcomes() {
            List&lt;ConditionOutcome> outcomes = new ArrayList&lt;>();
            // 处理每个内部类对应的所有Condition
            this.memberConditions.forEach((metadata, conditions) -> outcomes
                    .add(new MemberOutcomes(this.context, metadata, conditions).getUltimateOutcome()));
            return Collections.unmodifiableList(outcomes);
        }

    }

    private static class MemberOutcomes {

        private final ConditionContext context;

        private final AnnotationMetadata metadata;

        private final List&lt;ConditionOutcome> outcomes;

        MemberOutcomes(ConditionContext context, AnnotationMetadata metadata, List&lt;Condition> conditions) {
            this.context = context;
            this.metadata = metadata;
            this.outcomes = new ArrayList&lt;>(conditions.size());
            for (Condition condition : conditions) {
                this.outcomes.add(getConditionOutcome(metadata, condition));
            }
        }

        private ConditionOutcome getConditionOutcome(AnnotationMetadata metadata, Condition condition) {
            if (condition instanceof SpringBootCondition) {
                return ((SpringBootCondition) condition).getMatchOutcome(this.context, metadata);
            }
            return new ConditionOutcome(condition.matches(this.context, metadata), ConditionMessage.empty());
        }

        /**
         * 将某个内部类中所有 Condition 的匹配结果整合为一个最终结果：
         * - 全部匹配才算 match
         * - 否则 noMatch
         */
        ConditionOutcome getUltimateOutcome() {
            ConditionMessage.Builder message = ConditionMessage
                    .forCondition("NestedCondition on " + ClassUtils.getShortName(this.metadata.getClassName()));
            if (this.outcomes.size() == 1) {
                ConditionOutcome outcome = this.outcomes.get(0);
                return new ConditionOutcome(outcome.isMatch(), message.because(outcome.getMessage()));
            }
            List&lt;ConditionOutcome> match = new ArrayList&lt;>();
            List&lt;ConditionOutcome> nonMatch = new ArrayList&lt;>();
            for (ConditionOutcome outcome : this.outcomes) {
                (outcome.isMatch() ? match : nonMatch).add(outcome);
            }
            if (nonMatch.isEmpty()) {
                return ConditionOutcome.match(message.found("matching nested conditions").items(match));
            }
            return ConditionOutcome.noMatch(message.found("non-matching nested conditions").items(nonMatch));
        }

    }

}

AllNestedConditions​	内部逻辑很简单就不展示源码了，就是个与逻辑，全部的内部类match才算match。它的逻辑其实和这个Conditional注解一起用在某个配置类上一样，都是与逻辑。
​	但SpringBoot还是提供了这个类，试想一下，现在有个极其复杂的与逻辑Conditional注解组合要用在多个配置类上，我们就可以用AllNestedConditions来组合这些Conditional注解，将公共的功能抽出来作为一个共享的逻辑模块，就是一种模块化的思想，不论是还是功能熟悉还是后期维护，都更加的方便
AnyNestedCondition​	只要任意一个内部类的条件匹配，就返回 match，实现的是或逻辑。是最常用的一个Condition组合工具
​	正如前面提到的，内部类的ConditionOutcome计算是与逻辑，所以在使用AnyNestedCondition时，建议每个内部类只写一个 @Conditional 注解
NoneNestedConditions​	只有所有内部类的条件都不匹配时，才返回 match，相当于非逻辑
Report和Listener​	在SpringBoot中可以通过如下配置，开启Condition的匹配详情日志。其对于排查Condition未生效的问题非常有帮助，是调试 SpringBoot 自动装配机制的重要手段。其原理主要依赖于ConditionEvaluationReport（ConditionOutcome缓存）和ConditionEvaluationReportLoggingListener（ConditionOutcome日志打印）
logging:
  level:
    org.springframework.boot.autoconfigure.logging: debug

ConditionEvaluationReport在 Spring Boot 中，所有的 Condition 实现类都继承自抽象类 SpringBootCondition。其中：

各个子类通过实现 getMatchOutcome() 模板方法，完成具体的匹配逻辑判断，并生成标准化的 ConditionOutcome（用于描述匹配结果及原因）
SpringBootCondition 会将这些 ConditionOutcome 缓存到ConditionEvaluationReport这个单例bean中

​	这个 ConditionEvaluationReport 用于汇总记录所有条件的匹配结果。SpringBoot 的日志监听器（ConditionEvaluationReportLoggingListener）正是基于这个 bean，在日志级别为 debug 时，输出详细的自动配置条件匹配情况
ConditionEvaluationReportLoggingListener​	这是一个配置在 spring.factories 里的 ApplicationContextInitializer，启动时会往容器里注册一个 ConditionEvaluationReportListener，专门监听 ContextRefreshedEvent 和 ApplicationFailedEvent 事件
​	一旦这两个事件有一个触发，它就会根据配置的 logLevelForReport（默认是 DEBUG）把所有Condition匹配情况打印出来。打印的数据来自 ConditionEvaluationReport 这个 Bean 里缓存的内容，也就是每个配置类的@Conditional 条件到底有没有命中的原因
Condition触发机制ConditionEvaluator​	ConditionEvaluator 是匹配某个配置类或 @Bean 方法上 Condition 条件注解的核心入口。它依据传入的 ConfigurationPhase 参数来判断当前所处的处理阶段（ 解析配置类 或 注册 Bean 阶段）
其核心方法shouldSkip逻辑如下：

实例化并排序该元素上声明的所有 Condition 类
匹配当前phase或不存在phase 的 Condition
匹配过程中，只要有一个 Condition 不满足，即返回 true 表示需要跳过，该元素将不会被进一步处理（不再解析配置或注册Bean）



class ConditionEvaluator {
    public boolean shouldSkip(@Nullable AnnotatedTypeMetadata metadata, @Nullable ConfigurationPhase phase) {
        // 没有@Conditional注解，则表示不需要skip
        if (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) {
            return false;
        }

        // 解析phase，决定当前配置类是在哪个阶段应用的Condition（解析阶段 or 注册bean阶段）
        if (phase == null) {
            if (metadata instanceof AnnotationMetadata &amp;&amp;
                    ConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) {
                return shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION);
            }
            return shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN);
        }

        List&lt;Condition> conditions = new ArrayList&lt;>();
        for (String[] conditionClasses : getConditionClasses(metadata)) {
            for (String conditionClass : conditionClasses) {
                // 实例化Condition
                Condition condition = getCondition(conditionClass, this.context.getClassLoader());
                conditions.add(condition);
            }
        }
        // 根据@Order排序Condition
        AnnotationAwareOrderComparator.sort(conditions);

        for (Condition condition : conditions) {
            // 判断 Condition 的作用阶段
            ConfigurationPhase requiredPhase = null;
            if (condition instanceof ConfigurationCondition) {
                requiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase();
            }
            // 不存在phase（即不论什么作用阶段，都需要进行匹配）或phase等于指定的阶段才进行匹配
            // 但凡任意一个Condition匹配失败，则返回true，表示需要skip
            if ((requiredPhase == null || requiredPhase == phase) &amp;&amp; !condition.matches(this.context, metadata)) {
                return true;
            }
        }

        return false;
    }

}

TrackedConditionEvaluator​	这是 Spring 在注册配置类 Bean 之前，用于评估 @Conditional 是否匹配的辅助工具。与普通 ConditionEvaluator 不同，它特殊的支持了根据导入当前配置类的其他配置类（即 importedBy）的Condition匹配情况，来共同决定当前类是否应跳过注册（skip）
​	其核心方法shouldSkip是一个基于 记忆搜索优化 + 剪枝的回溯算法（我们将参数configClass想象为当前节点，其importedBy想象为子节点，形成一棵由导入关系构成的树形结构），其核心逻辑为：

某个节点其任意一个importedBy不需要skip时，转而直接判断当前节点配置类的Condition决定其是否skip（break进行剪枝，不再判断其它importedBy的skip情况）
某个节点所有importedBy都skip时，则不再判断当前节点的Condition，直接确认skip

private class TrackedConditionEvaluator {

    private final Map&lt;ConfigurationClass, Boolean> skipped = new HashMap&lt;>();

    public boolean shouldSkip(ConfigurationClass configClass) {
        Boolean skip = this.skipped.get(configClass);
        if (skip == null) {
            // 若该配置类是通过 @Import 导入的，优先判断导入它的配置类是否应被skip
            if (configClass.isImported()) {
                boolean allSkipped = true;
                for (ConfigurationClass importedBy : configClass.getImportedBy()) {
                    // 回溯
                    if (!shouldSkip(importedBy)) {
                        // 但凡有一个导入者不需要skip，转而判断自身并剪枝
                        allSkipped = false;
                        break;
                    }
                }
                if (allSkipped) {
                    // 所有导入者都被跳过，则让当前配置类直接skip
                    skip = true;
                }
            }
            if (skip == null) {
                // 判断自己的Condition，决定是否需要skip
                skip = conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN);
            }
            // 缓存优化
            this.skipped.put(configClass, skip);
        }
        return skip;
    }

触发地点前置文章：ConfigurationClassPostProcessor解析配置类

ConditionEvaluator触发

ConfigurationClassParser#processConfigurationClass

 ​	所有配置类解析的起点，此处触发 ConfigurationPhase.PARSE_CONFIGURATION 阶段的 Condition 判断


ConfigurationClassParser#doProcessConfigurationClass：

 ​	解析配置类上的 @ComponentScan 注解时触发。该注解所扫描的组件将直接注册为 Bean，此阶段对应 ConfigurationPhase.REGISTER_BEAN


ConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForBeanMethod

​	在注册配置类中的 @Bean 方法时触发。每个 BeanMethod 都根据其方法上的 Condition进行匹配，为 ConfigurationPhase.REGISTER_BEAN 阶段



	

TrackedConditionEvaluator触发

ConfigurationClassBeanDefinitionReader#loadBeanDefinitionsForConfigurationClass

​	在注册配置类内部所有 Bean（包括 @Bean 方法、通过 @Import 引入的 ImportBeanDefinitionRegistrar、以及 @ImportResource 导入的 XML Bean）前，会调用 TrackedConditionEvaluator 判断该配置类是否整体满足 Condition，从而决定是否跳过整个类的 Bean 注册流程。





测试用例Condition组合-AnyNestedCondition​	这是一个组合Condition（或逻辑）的测试用例，只要condition.or.enable&#x3D;true或condition.or.use&#x3D;yes任意条件满足，则可注册C对象到容器中
@Configuration(proxyBeanMethods = false)
public class NestedOrConditionDemo {

    static class OrCondition extends AnyNestedCondition {

        public OrCondition() {
            super(ConfigurationPhase.REGISTER_BEAN);
        }
        @ConditionalOnProperty(value = "condition.or.enable", havingValue = "true")
        static class PropertyOrEnable{}

        @ConditionalOnProperty(value = "condition.or.use", havingValue = "yes")
        static class PropertyOrUse{}

    }

    public static class C{
        public void init(){
            System.out.println("NestedOrConditionDemo$C initialized");
        }
    }

    @Bean(initMethod = "init")
    @Conditional(OrCondition.class)
    public C buildC(){
        return new C();
    }

}

配置condition:
  or:
    enable: "false"
    use: "yes"

TrackedConditionEvaluator测试@Configuration(proxyBeanMethods = false)
@Import(D.class)
public class ImportTrackedConditionDemo {

}
@ConditionalOnMissingBean(A.class)
class A{}

@Import(A.class)
@ConditionalOnMissingBean(B.class)
class B{}

@Import(B.class)
@ConditionalOnBean(C.class)
class C{}

@Import(value = {C.class, A.class})
@ConditionalOnMissingBean(D.class)
class D{}

​	这个测试用例用来验证 TrackedConditionEvaluator#shouldSkip 的执行逻辑，能完整模拟它的skip机制，并覆盖到 记忆搜索、剪枝等优化逻辑。A对象的整个importBy链路图如下，其整体流程可以总结为：

C 的 Condition 不满足（@ConditionalOnBean 没匹配上），直接标记为 skip
B 是被唯一一个C  @Import 的，发现 C 被 skip 后，B 自己也不再判断 Condition，直接也 skip
然后判断 A，因为 A -&gt; B 这条链断了，就继续看 A -&gt; D
由于D的结果已被缓存为不被skip，所以A转而判断自身的Condition，最终得到不需要skip的结果



打开condition debug，也能从日志看出：

A 和 D 都走了 Condition 匹配逻辑
C 被判定不匹配
B 根本没触发 Condition 判断

A matched:
   - @ConditionalOnMissingBean (types: site.shanzhao.soil.spring.config.A; SearchStrategy: all) did not find any beans (OnBeanCondition)
D matched:
   - @ConditionalOnMissingBean (types: site.shanzhao.soil.spring.config.D; SearchStrategy: all) did not find any beans (OnBeanCondition)
      
C Did not match:
   - @ConditionalOnBean (types: site.shanzhao.soil.spring.config.C; SearchStrategy: all) did not find any beans of type site.shanzhao.soil.spring.config.C (OnBeanCondition)


感想​	本来只是打算简单写写几个常见的 @Conditional 注解实现，结果一深入源码，才发现背后藏着这么多细节。不知不觉间内容越写越多，也越写越上头
​	让我感慨的是，这不过是 Spring 中一个小小的功能点，却被设计得这么精巧。像灵活的条件组合机制，几乎能支持任何类型的 Condition 实现；又比如通过模板方法模式抽象出的 ConditionOutcome，不仅解耦了逻辑判断，还天然支持调试信息输出；再比如 importedBy 链路配合 TrackedConditionEvaluator 做到的递归判断与算法优化，每个功能看起来简单，但组合在一起就是工程化的思路体现
​	写到最后，不得不感叹一句：麻雀虽小，五脏俱全。只能说越看越觉得厉害，代码之路任重而道远啊
相关链接
ConfigurationClassPostProcessor解析配置类

]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Condition</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-Context,ContextConfig和Wrapper</title>
    <url>/2021-10-03/tomcat-context-contextconfig-he-wrapper/</url>
    <content><![CDATA[
​	StandardContext、ContextConfig以及StandardWrapper的核心逻辑源码解析及总结




Context​	Context 是 Tomcat 中最关键的容器组件，默认实现为 StandardContext。每一个 Context 实例代表一个独立的 Web 应用。在内部，Context 承担了大量与 Web 应用生命周期相关的工作，比如类加载器的初始化、web.xml 的解析、Servlet&#x2F;Filter&#x2F;Listener 的注册与实例化等。
​	每个 Context 对应一个唯一的 ServletContext，用于代表当前 Web 应用的上下文环境。通过 StandardContext 的 startInternal 方法，我们可以深入了解 Tomcat 是如何逐步构建一个 Web 应用的，并是在哪一步触发Spring启动的。
start核心流程总结
初始化和设置类加载器
设置StandardContext.loader为WebappLoader（和当前Context的使用的类加载器有关）
启动WebappLoader（内部会创建ParallelWebappClassLoader）
切换当前线程的类加载器为上述的ParallelWebappClassLoader，为后续类的隔离加载做准备（尤其是 SPI 加载）


触发配置解析流程
发布 Lifecycle.CONFIGURE_START_EVENT 事件，触发内部的 ContextConfig 监听器
ContextConfig开始解析当前项目的web.xml和其他jar包里的web-fragment.xml，并将解析后的结果合并放到StandardContext中（比如将servlet配置构造成Warpper添加到Context中作为其子容器）


tomcat 内部组件设置与启动
启动Warpper（StandardWrapper启动阶段不会做什么，不是实例化关联的Servlet）
触发当前contxet的Pipeline#start
创建StandardManager作为session的默认管理器


实例和初始化关键Servlet相关组件
调用ServletContainerInitializer#onStartup
实例化并调用ServletContextListener#contextInitialized（Spring + Tomcat组合时用到的ContextLoaderListener就会在这时启动。所以，这里就是spring开始实例化的开始）
调用Manager#start（内部会恢复上一次context中持久化的session）
实例化所有 Filter，并调用其init()方法
实例全部loadOnStartup &gt;&#x3D; 0的Servlet，并调用其init()方法



核心源码public class StandardContext extends ContainerBase
        implements Context, NotificationEmitter {

    public StandardContext() {

        super();
        pipeline.setBasic(new StandardContextValve());
    }

    // web.xml里的listener标签里配置的各种监听器className
    private String applicationListeners[] = new String[0];

    // ServletContextListener集和
    private final Set&lt;Object> noPluggabilityListeners = new HashSet&lt;>();

    // ServletContext实现
    protected ApplicationContext context = null;

    // 在当前tomcat实例中，是否允许javax.servlet.ServletContext#getContext方法跨context获取当前context的ServletContext
    private boolean crossContext = false;

    // 当前web的path（即 URL 前缀）
    private String path = null;

    // Filter 实例与其配置类之间的映射（FilterConfig），用于实际调用
    private HashMap&lt;String, ApplicationFilterConfig> filterConfigs = new HashMap&lt;>();
    // Filter配置的抽象集和（在wel.xml里配置的Filter）
    private HashMap&lt;String, FilterDef> filterDefs = new HashMap&lt;>();
    // 默认为StandardManager（管理和持久化Session）
    protected Manager manager = null;
    // 是否开启可重新加载的检测
    // 为true时，当当前环境的Class文件或jar有改变时（增加或修改），会重新加载当前Context
    private boolean reloadable = false;
    // Servlet 映射关系，key 为 URL pattern，value 为 Servlet 名称
    private HashMap&lt;String, String> servletMappings = new HashMap&lt;>();
    // session超时事件（分钟单位）
    private int sessionTimeout = 30;
    // ============ Cookie相关配置 ================
    private String sessionCookieName;
    private boolean useHttpOnly = true;
    private String sessionCookieDomain;
    private String sessionCookiePath;
    // 是否在cookie1路径最后面添加/，默认否（比如路径为/foo，避免请求/foobar也带上这个cookie）
    private boolean sessionCookiePathUsesTrailingSlash = false;
    // 是否接受客户端提供的（但服务端不存在的）Session ID 并创建新的 Session。设为false和context path为 / 才会生效
    private boolean validateClientProvidedNewSessionId = true;

    /**
     * start方法，可以说是整个tomcat中最关键的部分
     */
    protected synchronized void startInternal() throws LifecycleException {

        boolean ok = true;

        // 初始化资源对象：WebResourceRoot（提供静态资源访问、JAR管理等），Loader会用到
        if (getResources() == null) {
            try {
                setResources(new StandardRoot(this));
            } catch (IllegalArgumentException e) {
                ok = false;
            }
        }
        if (ok) {
            // 启动资源对象，确保资源可用
            resourcesStart();
        }

        // 设置Loader。这时当前组件的state为STARTING_PREP，不会触发Loader的start
        if (getLoader() == null) {
            WebappLoader webappLoader = new WebappLoader();
            webappLoader.setDelegate(getDelegate());
            setLoader(webappLoader);
        }

        // 初始化 Cookie 解析器（符合 RFC6265）
        if (cookieProcessor == null) {
            cookieProcessor = new Rfc6265CookieProcessor();
        }

        // 绑定ClassLoader到当前线程，并返回旧的classLoader
        ClassLoader oldCCL = bindThread();

        try {
            if (ok) {
                // 启动 WebappLoader，内部会创建 ParallelWebappClassLoader
                Loader loader = getLoader();
                if (loader instanceof Lifecycle) {
                    ((Lifecycle) loader).start();
                }

                unbindThread(oldCCL);
                // 将ParallelWebappClassLoader绑定到当前线程上线文里，作为当前context的类加载器
                oldCCL = bindThread();

                // 通知 ContextConfig 进行 web.xml（当前项目）、web-fragment.xml（其他依赖jar包） 等配置解析和组合
                fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);

                // ================ 走到这，xml里的所有Servlet,Filter,Listener等配置都解析完毕，放置到当前Context内部中了

                // 启动所有Wrapper（内部基本不会做什么）
                for (Container child : findChildren()) {
                    if (!child.getState().isAvailable()) {
                        child.start();
                    }
                }

                // 启动当前context的pipeline
                if (pipeline instanceof Lifecycle) {
                    ((Lifecycle) pipeline).start();
                }

                // 创建并设置 Session 管理器（如 StandardManager）
                Manager contextManager = new StandardManager();
                if (contextManager != null) {
                    setManager(contextManager);
                }
            }

            // 检查配置是否成功（由 ContextConfig 设置）
            if (!getConfigured()) {
                log.error(sm.getString("standardContext.configurationFail"));
                ok = false;
            }

            // 调用所有的ServletContainerInitializer
            for (Map.Entry&lt;ServletContainerInitializer, Set&lt;Class&lt;?>>> entry : initializers.entrySet()) {
                try {
                    entry.getKey().onStartup(entry.getValue(),
                            getServletContext());
                } catch (ServletException e) {
                    ok = false;
                    break;
                }
            }

            if (ok) {
                // 调用ServletContextListener的contextInitialized方法
                if (!listenerStart()) {
                    log.error(sm.getString("standardContext.listenerFail"));
                    ok = false;
                }
            }

            try {
                // 启动 Session 管理器
                Manager manager = getManager();
                if (manager instanceof Lifecycle) {
                    ((Lifecycle) manager).start();
                }
            } catch (Exception e) {
                ok = false;
            }

            // 实例化并配置好当前context的全部Filter，并触发其init方法
            if (ok) {
                if (!filterStart()) {
                    ok = false;
                }
            }

            // 加载并实例化各种loadOnStartup > 0 的Servlet（并执行init方法）
            if (ok) {
                if (!loadOnStartup(findChildren())) {
                    ok = false;
                }
            }

            // 默认不会启动Context的backgroundProcessor（由Engine处理）
            super.threadStart();
        } finally {
            // 恢复线程上下文类加载器
            unbindThread(oldCCL);
        }

        // 清理 Web 资源缓存（避免 JAR 文件句柄未释放）
        getResources().gc();

        // 设置最终状态
        if (!ok) {
            setState(LifecycleState.FAILED);
            // Send j2ee.object.failed notification
            if (this.getObjectName() != null) {
                Notification notification = new Notification("j2ee.object.failed",
                        this.getObjectName(), sequenceNumber.getAndIncrement());
                broadcaster.sendNotification(notification);
            }
        } else {
            setState(LifecycleState.STARTING);
        }
    }
}

ContextConfig​	当 HostConfig 实例化并部署 Context 时，会自动注册 ContextConfig 作为 Context 的一个 LifecycleListener。其主要职责是在 Context 启动（startInternal()）期间解析各种配置（web.xml、注解、SCI 等），并将解析结果装配到 StandardContext 中，以保证 Web 应用能完整启动
​	核心方法主要在ContextConfig#webConfig()中，被调用的链路为:


StandardContext#startInternal()中触发Lifecycle.CONFIGURE_START_EVENT事件
ContextConfig#lifecycleEvent
ContextConfig#configureStart
ContextConfig#webConfig


webConfig()核心逻辑
web.xml解析

${catalina.base}&#x2F;conf&#x2F;web.xml：server级别，即全局级别
${catalina.base}&#x2F;conf&#x2F;Catalina&#x2F;{hostname}&#x2F;web.xml.default：host级别
WEB-INF&#x2F;web.xml：当前context级，在context根目录下
WEB-INF&#x2F;lib&#x2F;*.jar!&#x2F;META-INF&#x2F;web-fragment.xml：fragment级别，当前web的依赖jar（WEB-INF&#x2F;lib&#x2F;目录）包里


Servlet 3.0特性支持

识别并加载 ServletContainerInitializer（WEB-INF&#x2F;lib&#x2F;*.jar!&#x2F;META-INF&#x2F;services&#x2F;javax.servlet.ServletContainerInitializer）

使用字节码技术解析项目class和jar包里的@WebServlet, @WebFilter, @WebListener，@HandlesType等注解，避免无用的class被加载进JVM



web.xml合并注册

将第1步里解析到的全部WebXml按优先级合并为一个WebXml对象，优先级： context &gt; fragment &gt; host &gt; server
将合并后的WebXml注册到StandardContext中（Filter、Listener、Wrapper、Session config、欢迎页等）



webConfig()源码protected void webConfig() {
    // web.xml的解析器
    WebXmlParser webXmlParser = new WebXmlParser(context.getXmlNamespaceAware(),
            context.getXmlValidation(), context.getXmlBlockExternal());

    Set&lt;WebXml> defaults = new HashSet&lt;>();

    // 1. 解析全局默认的web.xml，即conf/web.xml文件
    // 2. 解析host级别默认的web.xml，即conf/Catalina/{hostname}/web.xml.default 文件
    defaults.add(getDefaultWebXmlFragment(webXmlParser));

    // web.xml的解析结果
    WebXml webXml = createWebXml();

    // 将当前context级别的 WEB-INF/web.xml文件解析到webXml对象里
    InputSource contextWebXml = getContextWebXmlSource();
    if (!webXmlParser.parseWebXml(contextWebXml, webXml, false)) {
        ok = false;
    }

    ServletContext sContext = context.getServletContext();

    // 将Web应用中的所有jar包（即WEB-INF/lib/ 目录）里的META-INF/web-fragment.xml 解析为一个个的WebXml对象
    Map&lt;String,WebXml> fragments = processJarsForWebFragments(webXml, webXmlParser);

    // 排序
    Set&lt;WebXml> orderedFragments = null;
    orderedFragments =
            WebXml.orderWebFragments(webXml, fragments, sContext);

    // 实例化META-INF/services/javax.servlet.ServletContainerInitializer文件里的SCI
    if (ok) {
        processServletContainerInitializers();
    }

    if  (!webXml.isMetadataComplete() || typeInitializerMap.size() > 0) {
        // 1. 使用字节码方式解析class文件并处理相关注解（@WebServlet, @WebFilter, @WebListener等）
        // 2. 找出符合 @HandlesType 的类
        processClasses(webXml, orderedFragments);
    }

    if (!webXml.isMetadataComplete()) {
        if (ok) {
            // 先合并jar包里web-fragment.xml配置到当前context的web.xml里
            ok = webXml.merge(orderedFragments);
        }

        // 再将全局默认和host的合并到当前context的web.xml里
        webXml.merge(defaults);

        if (ok) {
            convertJsps(webXml);
        }

        if (ok) {
            // 将合并完成的web.xml信息注册到当前StandardContext中
            configureContext(webXml);
        }
    } else {
        webXml.merge(defaults);
        convertJsps(webXml);
        configureContext(webXml);
    }

    if (ok) {
        // 暴露出jar包中META-INF/resources/的静态资源，让其可以直接通过url访问
        Set&lt;WebXml> resourceJars = new LinkedHashSet&lt;>(orderedFragments);
        for (WebXml fragment : fragments.values()) {
            if (!resourceJars.contains(fragment)) {
                resourceJars.add(fragment);
            }
        }
        processResourceJARs(resourceJars);
    }

    // 注册 ServletContainerInitializer 到 Context
    if (ok) {
        for (Map.Entry&lt;ServletContainerInitializer,
                Set&lt;Class&lt;?>>> entry :
                    initializerClassMap.entrySet()) {
            if (entry.getValue().isEmpty()) {
                context.addServletContainerInitializer(
                        entry.getKey(), null);
            } else {
                context.addServletContainerInitializer(
                        entry.getKey(), entry.getValue());
            }
        }
    }
}

Wrapper​	Wrapper即Servlet，默认实现为StandardWrapper，其主要任务为：


管理 Servlet 的 生命周期（加载、初始化、分配和销毁）
支持 线程安全策略（如 SingleThreadModel）


​	Servlet 的实例化不依赖 StandardWrapper的 init() 或 start() 方法，而是由 loadOnStartup字段决定。也就没必要分析着两个生命周期方法


loadOnStartup &gt;&#x3D; 0：在应用启动阶段就会实例化并初始化 Servlet（StandardContext内的start阶段）
loadOnStartup &lt; 0（默认）：延迟到首次请求时才实例化


​	值得关注allocate()方法，这是在http请求到来时分配当前Wrapper的Servlet方法，其实现了SingleThreadModel（即STM，尽管已被废弃）逻辑的支持。内部利用栈进行缓存，让每个运行在当前STM Servlet里的线程能独享一个Servlet，默认最多20个缓存，到达最大数量时当前请求会被阻塞，只能等deallocate()方法（归还Servlet）来唤醒。
​	所以，可以得出一个关键结论：对STM Servlet来说，其http请求的最大并发数为Min(StandardWrapper.maxInstances, tomcat的worker线程池最大线程数)
核心源码public class StandardWrapper extends ContainerBase
        implements ServletConfig, Wrapper, NotificationEmitter {
    public StandardWrapper() {
        // 向pipeline添加StandardWrapperValve，这个valve主要实例化servlet并构造filter来处理请求
        swValve = new StandardWrapperValve();
        pipeline.setBasic(swValve);

    }

    // servlet实例（针对多线程共用时的）
    protected volatile Servlet instance = null;
    // 当前servlet是否已经初始化（就是调用了init接口）
    protected volatile boolean instanceInitialized = false;

    protected int loadOnStartup = -1;
    // 当前servlet的InitParam参数缓存
    protected HashMap&lt;String, String> parameters = new HashMap&lt;>();
    // 是否是单线程模式。默认false，表示为单例Servlet。如果为true，代表Servlet在每个运行的线程中是不同的，即多例
    protected volatile boolean singleThreadModel = false;
    // 单线程模式下默认最多20个单线程servlet
    protected int maxInstances = 20;
    // 单线程模式下servlet的实例树
    protected int nInstances = 0;
    // 单线程模式下基于栈实现的servlet实例池
    protected Stack&lt;Servlet> instancePool = null;

     /**
     * 根据singleThreadModel采用不同的分配策略，进行Servlet实例的分配
     */
    public Servlet allocate() throws ServletException {


        boolean newInstance = false;

        // 非STM的，每次都返回相同的servlet（多线程共用这个对象）
        if (!singleThreadModel) {
            if (instance == null || !instanceInitialized) {
                synchronized (this) {
                    if (instance == null) {
                        try {
                            // 实例化
                            instance = loadServlet();
                            newInstance = true;
                            if (!singleThreadModel) {
                                countAllocated.incrementAndGet();
                            }
                        } catch (ServletException e) {
                            throw e;
                        } catch (Throwable e) {
                            ExceptionUtils.handleThrowable(e);
                            throw new ServletException(sm.getString("standardWrapper.allocate"), e);
                        }
                    }
                    // 如果未初始化，则调用Servlet#init方法
                    if (!instanceInitialized) {
                        initServlet(instance);
                    }
                }
            }
            // 再次检测STM（Servlet第一次实例化时才会设置这个值），如果是STM则先入栈（即缓存）
            if (singleThreadModel) {
                if (newInstance) {
                    synchronized (instancePool) {
                        instancePool.push(instance);
                        nInstances++;
                    }
                }
            } else {
                // 非STM则直接返回
                if (!newInstance) {
                    countAllocated.incrementAndGet();
                }
                return instance;
            }
        }
        // ================== 走到这，表示为STM Servlet ==================
        synchronized (instancePool) {
            while (countAllocated.get() >= nInstances) { // 缓存的STM Servlet不够分
                if (nInstances &lt; maxInstances) {
                    // 没到上限，则进行实例化
                    try {
                        instancePool.push(loadServlet());
                        nInstances++;
                    } catch (ServletException e) {
                        throw e;
                    } catch (Throwable e) {
                        ExceptionUtils.handleThrowable(e);
                        throw new ServletException(sm.getString("standardWrapper.allocate"), e);
                    }
                } else {
                    try {
                        // 超过上限，则阻塞等待归还Servlet时的唤醒
                        instancePool.wait();
                    } catch (InterruptedException e) {
                        // Ignore
                    }
                }
            }
            // 增加servlet正在使用的数量
            countAllocated.incrementAndGet();
            return instancePool.pop();
        }
    }

     /**
     * 释放已使用完的Servlet实例
     */
    public void deallocate(Servlet servlet) throws ServletException {

        if (!singleThreadModel) {
            countAllocated.decrementAndGet();
            return;
        }

        // 归还到栈中，让其可以重复使用
        synchronized (instancePool) {
            countAllocated.decrementAndGet();
            instancePool.push(servlet);
            instancePool.notify();
        }

    }
}

]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-Engine,Host和HostConfig</title>
    <url>/2021-09-23/tomcat-engine-host-he-hostconfig/</url>
    <content><![CDATA[
​	从源码分析了ContainerBase，StandardEngine，StandardHost和HostConfig的实现逻辑。需要重点注意HostConfig的作用和部署流程




ContainerBase​	是所有容器（Engine、Host、Context、Wrapper）的核心抽象基类，定义并维护了容器通用的结构、生命周期管理机制和后台任务调度能力。核心职责如下：

init
构建一个可过期的核心线程数为1的线程池（生命周期短，仅用来启动子容器），准备用于并发start子容器


start
并发启动所有子容器，阻塞等待其完成
启动自身的 Pipeline（包含所有 Valve）
根据 backgroundProcessorDelay 的配置，决定是否启动后台线程 ContainerBackgroundProcessor（默认仅 Engine 容器会设置该值（为 10 秒），其它容器默认不启动），用于周期性执行后台任务（如 session 过期清理）



核心源码public abstract class ContainerBase extends LifecycleMBeanBase implements Container {
    // 子容器集合，key 为容器名，每个Container都有唯一name
    protected final HashMap&lt;String, Container> children = new HashMap&lt;>();
    /**
     * 后台处理线程执行间隔（秒），用于处理如 session 过期等后台任务。
     * - 默认值为 -1，表示不启动后台线程。
     * - 仅 Engine 容器会设置为 10，其它容器（Host、Context、Wrapper）默认不设置。
     * - ContainerBackgroundProcessor 线程由 Engine 启动，并递归处理其所有子容器的后台任务。
     */
    protected int backgroundProcessorDelay = -1;
    // 容器监听器（用于监听子容器结构或状态变更）
    protected final List&lt;ContainerListener> listeners = new CopyOnWriteArrayList&lt;>();
    // 当前容器名
    protected String name = null;
    // 当前容器的父容器（Engine为最顶层的容器，所以为null）
    protected Container parent = null;
    // 当前容器的 Pipeline，用于处理请求链路（Valve）
    protected final Pipeline pipeline = new StandardPipeline(this);

    // 后台线程引用（用于执行 backgroundProcessor）
    private Thread thread = null;
    // 启动/停止子容器的线程数（默认 1）
    private int startStopThreads = 1;
    // 启动或暂停当前容器的子容器线程池（默认线程数就为上面的1，且允许核心线程过期。一般只有在启动才需要用到，所以启动完毕后这个线程池就没啥用了，让里面的线程过期）
    protected ThreadPoolExecutor startStopExecutor;

    @Override
    protected void initInternal() throws LifecycleException {
        BlockingQueue&lt;Runnable> startStopQueue = new LinkedBlockingQueue&lt;>();
        // 默认一个线程
        startStopExecutor = new ThreadPoolExecutor(
                getStartStopThreadsInternal(),
                getStartStopThreadsInternal(), 10, TimeUnit.SECONDS,
                startStopQueue,
                new StartStopThreadFactory(getName() + "-startStop-"));
        // 允许核心线程过期
        startStopExecutor.allowCoreThreadTimeOut(true);
        super.initInternal();
    }

    @Override
    protected synchronized void startInternal() throws LifecycleException {

        // 先启动Cluster和Realm
        logger = null;
        getLogger();
        Cluster cluster = getClusterInternal();
        if (cluster instanceof Lifecycle) {
            ((Lifecycle) cluster).start();
        }
        Realm realm = getRealmInternal();
        if (realm instanceof Lifecycle) {
            ((Lifecycle) realm).start();
        }

        // 并发启动所有子容器
        Container children[] = findChildren();
        List&lt;Future&lt;Void>> results = new ArrayList&lt;>();
        for (Container child : children) {
            results.add(startStopExecutor.submit(new StartChild(child)));
        }

        MultiThrowable multiThrowable = null;

        // 阻塞等待所有子容器启动完成
        for (Future&lt;Void> result : results) {
            try {
                result.get();
            } catch (Throwable e) {
                log.error(sm.getString("containerBase.threadedStartFailed"), e);
                if (multiThrowable == null) {
                    multiThrowable = new MultiThrowable();
                }
                multiThrowable.add(e);
            }

        }
        if (multiThrowable != null) {
            throw new LifecycleException(sm.getString("containerBase.threadedStartFailed"),
                    multiThrowable.getThrowable());
        }

        // 等所有子容器启动完毕，再启动当前容器的Pipeline（包括 Basic Valve）
        if (pipeline instanceof Lifecycle) {
            ((Lifecycle) pipeline).start();
        }

        // 触发当前组件里监听器lifecycleListeners的start事件
        setState(LifecycleState.STARTING);

        // 启动后台线程（如配置，线程也是daemon）
        threadStart();
    }
}

Engine​	Engine是Tomcat最顶层的容器（没有父容器），和Service是一对一的关系，在他们内部互相保存了对方的引用，默认实现类时StandardEngine。
​	该容器本身不负责具体请求处理，核心职责是承载多个 Host 子容器，因此其初始化和启动过程直接复用了父类 ContainerBase 的逻辑。
​	需要注意的是，构造方法中设置了 backgroundProcessorDelay = 10，这会启动一个后台线程，周期性执行所有子容器的后台任务（如 session 过期清理等）。Tomcat 默认仅在 Engine 层启用此功能，从而递归驱动整个容器树的后台处理流程。
核心源码public class StandardEngine extends ContainerBase implements Engine {

    public StandardEngine() {
        super();
        // 设置当前容器的basic value, 此 Valve 会作为 Pipeline 中的最后一个节点。
        pipeline.setBasic(new StandardEngineValve());

        // 设置后台处理线程的执行间隔（单位：秒）
        // 用于周期性执行容器级的后台任务，如 session 清理等，仅 Engine 层默认启用
        backgroundProcessorDelay = 10;
    }

    /**
     * 默认主机名。
     * 当请求url的host未匹配到任何具体的 Host 容器时，将路由到该默认 Host
     * 对应 server.xml 中 &lt;Engine> 的 defaultHost 属性，默认值通常为 localhost
     */
    private String defaultHost = null;

    /**
     * 当前 Engine 所绑定的 Service（Engine 和 Service 是一对一关系）。
     */
    private Service service = null;
}

Host​	Host 是 Engine 的子容器，默认实现为 StandardHost，表示对 HTTP 请求中 host 的抽象。请求到达时，Tomcat 会根据请求的 host 名（域名）查找匹配的 Host 实例；若无匹配项，则使用默认 Host（即 defaultHost，通常为 localhost）
​	StandardHost 的初始化和启动逻辑沿用 ContainerBase 的通用流程，本身没有特殊处理。 真正负责扫描部署目录、创建并启动子容器 Context 的工作，实际上由其监听器 HostConfig 完成。
核心源码public class StandardHost extends ContainerBase implements Host {
    public StandardHost() {
        // StandardHostValve也会作为当前容器的pipeline的last value
        pipeline.setBasic(new StandardHostValve());

    }

    // 当前Host的别名，匹配别名也能匹配到当前Host
    private String[] aliases = new String[0];

    // 当前Host下的Web应用部署根目录，相对路径默认值为webapps
    private String appBase = "webapps";

    // 默认：${catalina.base}/webapps
    private volatile File appBaseFile = null;

    // 默认为：conf/Catalina/localhost目录
    private volatile File hostConfigBase = null;

    // 是否自动部署
    private boolean autoDeploy = true;

    // 添加到当前Host的子容器Context里的监听器（ContextConfig）
    private String configClass = "org.apache.catalina.startup.ContextConfig";

    // 当前Host的子容器Context的实现类
    private String contextClass = "org.apache.catalina.core.StandardContext";

    // 启动时部署Context
    private boolean deployOnStartup = true;

    // （应该被忽略的Context）默认为null
    private Pattern deployIgnore = null;

}

HostConfig​	在默认的 server.xml 配置中，&lt;Host&gt; 元素下并没有显式配置 &lt;Context&gt; 子元素，因此在解析 server.xml 时并不会为 Host 创建任何 Context 子容器。尽管如此，Tomcat 仍能在启动时自动部署 $&#123;catalina.base&#125;/webapps/ 目录下的应用，这正是由 HostConfig 这个 LifecycleListener 完成的。

注册方式

​	在 Tomcat 启动期间，通过 Digester 解析 server.xml 时，会由 HostRuleSet#addRuleInstances() 方法为每个 Host 元素注册默认的生命周期监听器org.apache.catalina.startup.HostConfig，其会被实例化添加为Host的LifecycleListener


启动时机

​         StandardHost在startInternal()期间中的子容器启动完成后（默认没有子容器），但后台线程还未启动时，会触发lifecycle的START_EVENT事件，从而触发HostConfig的start，来解析目标文件夹下webapps的项目，自动部署所有符合规则的 Web 应用。


三种部署方式

XML 配置部署（conf&#x2F;Catalina&#x2F;{hostname}&#x2F;*.xml）
每个xml文件即为一个Context（IDEA的war exploded就是这种方式）


WAR 包部署（webapps&#x2F;*.war）
每个war包即为一个Context


directory部署（webapps&#x2F;{dir}）
每个目录被当作一个Context，是项目中最常用的一种




路径问题

​	上诉三种部署方式都遵循相同的路径规则。即Context的name和path为去除拓展名后的部分。对于特殊的ROOT，则表示为根路径/ 。



核心源码
public class HostConfig implements LifecycleListener {

    // context默认实现类
    protected String contextClass = "org.apache.catalina.core.StandardContext";

    // 当前绑定的 Host 容器
    protected Host host = null;

    // 已部署的应用（用于记录当前 host 下部署的 context 状态）
    protected final Map&lt;String, DeployedApplication> deployed = new ConcurrentHashMap&lt;>();

    // 正在处理部署/卸载操作的 Context 名集合（用于防止重复并发部署）
    private Set&lt;String> servicedSet = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean>());

    /**
     * Host 生命周期监听方法，根据不同生命周期阶段执行对应操作：
     * - BEFORE_START：确认所需目录存在
     * - START：执行部署流程
     * - PERIODIC：周期性检查（autoDeploy 场景下可能重新部署）
     * - STOP：停止并清理部署
     */
    @Override
    public void lifecycleEvent(LifecycleEvent event) {

        if (event.getType().equals(Lifecycle.PERIODIC_EVENT)) {
            // 周期任务（例如监测部署目录变更）
            check();
        } else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) {
            // StandardHost启动前触发
            // 确保 ${catalina.base}/webapps和conf/Catalina/localhost目录存在（不存在也只会打日志）
            beforeStart();
        } else if (event.getType().equals(Lifecycle.START_EVENT)) {
            // StanardHost正在启动
            start();
        } else if (event.getType().equals(Lifecycle.STOP_EVENT)) {
            stop();
        }
    }

    public void start() {
        // 默认：${catalina.base}/webapps
        if (!host.getAppBaseFile().isDirectory()) { // app文件目录不是文件夹，代表不需要部署
            log.error(sm.getString("hostConfig.appBase", host.getName(),
                    host.getAppBaseFile().getPath()));
            host.setDeployOnStartup(false);
            host.setAutoDeploy(false);
        }
        if (host.getDeployOnStartup()) {
            // 默认为true，开始部署
            deployApps();
        }
    }

    protected void deployApps() {
        File appBase = host.getAppBaseFile();
        File configBase = host.getConfigBaseFile();
        // 过滤器默认为null，所以还是返回全部
        String[] filteredAppPaths = filterAppPaths(appBase.list()); // 过滤webapps文件夹下的所有文件
        // conf/Catalina/localhost目录下所有的xml方式部署（IDEA的war exploded就是这种方式）
        // 每一个xml其实就是一个context，文件名就是context的ptah。ROOT.xml就是默认的context，即path为空字符串
        deployDescriptors(configBase, configBase.list());
        // war包的形式部署
        // 部署${catalina.base}/webapps目录下的所有war包
        deployWARs(appBase, filteredAppPaths);
        // 直接以文件夹的形式部署
        // 部署${catalina.base}/webapps目录下的所有文件夹形式的context
        deployDirectories(appBase, filteredAppPaths);
    }

}

directory部署​	重点解析下directory部署方式，毕竟这是最常用的。其会在当前host的startStop线程池中异步部署，根据如下源码总结出核心流程

优先使用 META-INF&#x2F;context.xml 配置（如果存在）
解析并构造出Context实例
设置Context的一些基础属性（name和path等，以项目目录名为准）
将Context添加为对应Host的子容器（此时会触发Context的start）


/**
 * 以文件夹方式部署应用（appBase 下的目录结构）
 * - 忽略 META-INF、WEB-INF
 * - 忽略已存在的部署
 * - 支持异步并发部署（通过 Host 提供的线程池）
 */
protected void deployDirectories(File appBase, String[] files) {

    if (files == null) {
        return;
    }

    ExecutorService es = host.getStartStopExecutor();
    List&lt;Future&lt;?>> results = new ArrayList&lt;>();

    for (String file : files) {
        // META-INF和WEB-INF文件加不部署
        if (file.equalsIgnoreCase("META-INF")) {
            continue;
        }
        if (file.equalsIgnoreCase("WEB-INF")) {
            continue;
        }

        File dir = new File(appBase, file);
        if (dir.isDirectory()) {
            // ROOT文件夹会被解析为 根context，也就是path为空字符串
            ContextName cn = new ContextName(file, false);

            if (tryAddServiced(cn.getName())) {
                try {
                    if (deploymentExists(cn.getName())) {
                        removeServiced(cn.getName());
                        continue;
                    }

                    // 异步部署
                    results.add(es.submit(new DeployDirectory(this, cn, dir)));
                } catch (Throwable t) {
                    ExceptionUtils.handleThrowable(t);
                    removeServiced(cn.getName());
                    throw t;
                }
            }
        }
    }

    // 同步等待
    for (Future&lt;?> result : results) {
        try {
            result.get();
        } catch (Exception e) {
            log.error(sm.getString("hostConfig.deployDir.threaded.error"), e);
        }
    }
}

// ================ 开始部署 ==================
protected void deployDirectory(ContextName cn, File dir) {

    Context context = null;
    // Web 应用目录下的META-INF/context.xml 文件
    File xml = new File(dir, Constants.ApplicationContextXml);
    // 将META-INF/context.xml拷贝到的目标位置：conf/Catalina/localhost/${contextName}.xml
    File xmlCopy = new File(host.getConfigBaseFile(), cn.getBaseName() + ".xml");

    DeployedApplication deployedApp;
    // 是否拷贝 META-INF/context.xml 到 conf 目录（Host 默认 false，可被 Context 覆盖）
    boolean copyThisXml = isCopyXML();
    // 是否允许部署该 META-INF/context.xml（默认true）
    boolean deployThisXML = isDeployThisXML(dir, cn);

    try {
        if (deployThisXML &amp;&amp; xml.exists()) {
            // 存在有效 META-INF/context.xml 且支持部署这个xml，则通过 digester 解析生成 Context
            synchronized (digesterLock) {
                context = (Context) digester.parse(xml);
            }

            // 如果 host 设置不允许拷贝xml，则再次通过 context的copyXML 判断一次
            if (copyThisXml == false &amp;&amp; context instanceof StandardContext) {
                copyThisXml = ((StandardContext) context).getCopyXML();
            }

            // 根据是否拷贝，设置 context 的配置文件位置（conf 目录 or 原始目录）
            if (copyThisXml) {
                Files.copy(xml.toPath(), xmlCopy.toPath());
                context.setConfigFile(xmlCopy.toURI().toURL());
            } else {
                context.setConfigFile(xml.toURI().toURL());
            }
        } else if (!deployThisXML &amp;&amp; xml.exists()) {
            // 禁止部署，但 META-INF/context.xml 存在 —— 为安全考虑，阻止启动（避免绕过配置）
            context = new FailedContext();
        } else {
            // 没有 META-INF/context.xml文件，则手动 new 一个 context 实例
            context = (Context) Class.forName(contextClass).getConstructor().newInstance();
        }
        // 为 Context 添加生命周期监听器（默认是 ContextConfig，用于触发解析 web.xml等）
        Class&lt;?> clazz = Class.forName(host.getConfigClass());
        LifecycleListener listener = (LifecycleListener) clazz.getConstructor().newInstance();
        context.addLifecycleListener(listener);

        // 设置 Context 的一些基础信息
        context.setName(cn.getName());
        context.setPath(cn.getPath());
        context.setWebappVersion(cn.getVersion());
        context.setDocBase(cn.getBaseName());
        // 将 Context 添加到当前 Host，并自动触发生命周期（start/init）
        host.addChild(context);
    } catch (Throwable t) {
        ExceptionUtils.handleThrowable(t);
        log.error(sm.getString("hostConfig.deployDir.error", dir.getAbsolutePath()), t);
    } finally {
        // 部署完成后记录已部署信息，构建 DeployedApplication（省略细节）
        // ...

    }
    deployed.put(cn.getName(), deployedApp);
}

]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Container</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-Server和Service</title>
    <url>/2021-09-04/tomcat-server-he-service/</url>
    <content><![CDATA[
​	对Tomcat中Server，Service的init和start方法 + 核心字段进行了分析，并重点分析了Connector-NioEndpoint内部的Acceptor和Poller线程，并用图文的方法做了总结。并简单总结了Mapper和MapperListener的作用




Server​	Server 表示 Tomcat 的顶层容器，默认实现为 StandardServer。它的职责相对简单，主要包括

负责管理整个 Tomcat 的生命周期事件（如 start()、stop() 等），并将其传递给所有子组件 Service

监听关闭端口：默认会在 8005 端口监听本地连接，用于接收特定的 SHUTDOWN 命令，从而实现优雅关闭

监听行为可通过配置项（如 port 和 shutdown）启用、关闭或修改shutdown命令

当监听到SHUTDOWN命令，await()则返回，main线程会退出。可以推测出，tomcat启动的其他线程池应该是daemon线程的，否则整个进程是不会退出的。后续我会陆续验证这个猜想


核心源码​	我这里只展示了部分优化后的核心源码，不重要的我都删了
public final class StandardServer extends LifecycleMBeanBase implements Server {

    // shutdown监听端口
    private int port = 8005;

    private String address = "localhost";

    // 内部所有的Service
    private Service services[] = new Service[0];
    private final Object servicesLock = new Object();

    // shutdown命令，默认就是SHUTDOWN
    private String shutdown = "SHUTDOWN";

    private volatile boolean stopAwait = false;

    private Catalina catalina = null;

    // 监听shutdown端口的ServerSocket
    private volatile ServerSocket awaitSocket = null;

    @Override
    protected void startInternal() throws LifecycleException {

        fireLifecycleEvent(CONFIGURE_START_EVENT, null);
        setState(LifecycleState.STARTING);

        globalNamingResources.start();

        // 依次启动内部所有的Service
        synchronized (servicesLock) {
            for (Service service : services) {
                service.start();
            }
        }
    }

    @Override
    public void await() {
        // -2：完全不等待（可用于嵌入式）
        if (port == -2) {
            return;
        }
        // -1：无限睡眠轮询（用于不想用端口，但主线程又不能退出的场景）
        if (port == -1) {
            try {
                awaitThread = Thread.currentThread();
                while (!stopAwait) {
                    try {
                        Thread.sleep(10000);
                    } catch (InterruptedException ex) {
                        // continue and check the flag
                    }
                }
            } finally {
                awaitThread = null;
            }
            return;
        }

        // 启动ServerSocket，监听本地端口（默认8005），用于接收 SHUTDOWN 命令
        try {
            awaitSocket = new ServerSocket(port, 1, InetAddress.getByName(address));
        } catch (IOException e) {
            return;
        }

        try {
            awaitThread = Thread.currentThread();
            // 循环
            while (!stopAwait) {
                ServerSocket serverSocket = awaitSocket;
                if (serverSocket == null) {
                    break;
                }

                Socket socket = null;
                StringBuilder command = new StringBuilder();
                try {
                    InputStream stream;
                    long acceptStartTime = System.currentTimeMillis();
                    // 阻塞，等待连接建立（当返回时表示已获取到客户端的连接）
                    socket = serverSocket.accept();
                    socket.setSoTimeout(10 * 1000); // Ten seconds
                    stream = socket.getInputStream();

                    // 安全防御：预设最大读取长度，防止 DOS 攻击
                    int expected = 1024;
                    while (expected &lt; shutdown.length()) {
                        if (random == null) {
                            random = new Random();
                        }
                        expected += (random.nextInt() % 1024);
                    }
                    // 读取字符，直到遇到控制字符/EOF
                    while (expected > 0) {
                        int ch = stream.read();
                        if (ch &lt; 32 || ch == 127)
                            break;
                        command.append((char) ch);
                        expected--;
                    }
                } finally {
                    // 接受完一次请求就关闭客户端的连接
                    if (socket != null) {
                        socket.close();
                    }
                }

                // 判断是否是合法的 SHUTDOWN 命令
                boolean match = command.toString().equals(shutdown);
                if (match) { // 跳出循环，结束main
                    break;
                }
            }
        } finally {
            // 清理资源
            ServerSocket serverSocket = awaitSocket;
            awaitThread = null;
            awaitSocket = null;

            if (serverSocket != null) {
                try {
                    serverSocket.close();
                } catch (IOException e) {
                    // Ignore
                }
            }
        }
    }

}

Service​	Service 是 Tomcat 中的一个核心组件，其默认实现类为 StandardService，表示一个具体的服务实例。它与最顶层的容器 Engine 是一对一的
​	一个 Service 通常包含多个 Connector，每个 Connector 监听一个本地端口，支持特定协议（如 HTTP、AJP），接收客户端请求。请求经过 Mapper 映射到对应的 Host、Context、Wrapper，最终交由目标 Servlet 处理
核心生命周期方法
initInternal()
初始化绑定的 Engine 容器
等待 Engine 及其子容器完成初始化后，注册相关 MBean（用于 JMX 监控）
初始化所有 Connector（主要是是创建并绑定 ServerSocketChannel 到指定端口）


startInternal()
启动关联的 Engine
启动 MapperListener（用于监听容器结构变化并更新路由）
启动所有 Connector（主要是启动Acceptor和Poller线程，开始监听端口并接受请求）



核心源码
public class StandardService extends LifecycleMBeanBase implements Service {
    // 当前Service名名
    private String name = null;
    // 关联的Server
    private Server server = null;
    // 当前 Service 管理的所有 Connector（支持 HTTP、AJP 等协议）
    protected Connector connectors[] = new Connector[0];
    private final Object connectorsLock = new Object();
    // 当前 Service 下配置的所有线程池 Executor（一般为空，由 Connector 自带）
    protected final ArrayList&lt;Executor> executors = new ArrayList&lt;>();
    // 当前 Service 使用的 Engine（容器的顶层容器，代表整个虚拟主机群）
    private Engine engine = null;

    /**
     * 我把它叫请求路由器，用于将请求映射到对应的 Wrapper（最终的 Servlet）。
     * 由 Connector 配置协议解析后交给 Mapper 做 URI 到容器层级的映射。
     */
    protected final Mapper mapper = new Mapper();

    // Mapper 的生命周期监听器。主要注册 MBean，不参与请求处理。
    protected final MapperListener mapperListener = new MapperListener(this);

    @Override
    protected void initInternal() throws LifecycleException {

        super.initInternal();

        // 初始化容器结构
        if (engine != null) {
            engine.init();
        }

        // Service下的Executor节点，默认没有
        for (Executor executor : findExecutors()) {
            if (executor instanceof JmxEnabled) {
                ((JmxEnabled) executor).setDomain(getDomain());
            }
            executor.init(); // 没做啥有用的事，仅仅注册个MBean
        }

        // 没做啥有用的事，仅仅注册个MBean
        mapperListener.init();

        // Initialize our defined Connectors
        synchronized (connectorsLock) {
            for (Connector connector : connectors) {
                try {
                    // 构建ProtocolHandler和Endpoint，绑定服务器端口
                    connector.init();
                } catch (Exception e) {
                    if (Boolean.getBoolean("org.apache.catalina.startup.EXIT_ON_INIT_FAILURE")) {
                        throw new LifecycleException(message);
                    }
                }
            }
        }
    }

    @Override
    protected void startInternal() throws LifecycleException {

        setState(LifecycleState.STARTING);

        // 启动容器 Engine，进而递归启动 Host、Context、Wrapper
        if (engine != null) {
            synchronized (engine) {
                engine.start();
            }
        }

        // 启动所有线程池 Executor（默认为空）
        synchronized (executors) {
            for (Executor executor : executors) {
                executor.start();
            }
        }

        mapperListener.start();

        synchronized (connectorsLock) {
            for (Connector connector : connectors) {
                if (connector.getState() != LifecycleState.FAILED) {
                    // 启动底层 ProtocolHandler 和 Acceptor 线程
                    connector.start();
                }
            }
        }
    }

}

Connector​	用来处理Socket的抽象，主要关注内部的ProtocolHandler和Adapter
ProtocolHandler​	用来处理具体协议，默认处理http1.1协议使用的是Http11NioProtocol这个类，内部通过NioEndpoint来真正操作Soeket，封装了Socket的相关操作Mapper
NioEndpointAcceptor（连接处理器）​	一个处理连接的专用线程（默认线程名为 http-nio-8080-Acceptor），负责监听客户端连接，职责类似 Netty 中的 ServerBootstrapAcceptor。其核心流程如下：

阻塞监听客户端连接请求（调用 ServerSocketChannel.accept()）
建立连接后，封装为 SocketChannel，并设置相应的 socket 参数（如非阻塞、超时等）
构造 PollerEvent 对象，设为对 OP_READ 事件感兴趣
将事件投递至 Poller 线程，由其负责后续的事件注册和处理


补充说明：Acceptor 只负责连接建立，不处理任何 I&#x2F;O 数据交互，也不触发SocketChannel向Selector注册感兴趣的事件

// Acceptor线程核心源码，只保留了一些核心逻辑

public void run() {
    // 主循环：阻塞接收客户端连接请求
    while (running) {
        try {

            // 连接限制计数（默认10000）
            countUpOrAwaitConnection();

            SocketChannel socket = null;

            // 阻塞等待客户端连接（accept）
            socket = serverSock.accept();

            if (running &amp;&amp; !paused) {
                // 初始化客户端连接并注册到 Poller
                // 若失败则关闭 socket 并增加可用的LimitLatch
                if (!setSocketOptions(socket)) {
                    closeSocket(socket);
                }
            } else {
                closeSocket(socket);
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
        }
    }
}

protected boolean setSocketOptions(SocketChannel socket) {
    try {
        // 设置客户端 socket 为非阻塞模式
        socket.configureBlocking(false);
        Socket sock = socket.socket();
        // 设置Socket参数
        socketProperties.setProperties(sock);

        // 从缓存中获取或创建 NioChannel（用于封装 SocketChannel + Buffer）
        NioChannel channel = nioChannels.pop();
        if (channel == null) {
            SocketBufferHandler bufhandler = new SocketBufferHandler(
                    socketProperties.getAppReadBufSize(),
                    socketProperties.getAppWriteBufSize(),
                    socketProperties.getDirectBuffer());
            if (isSSLEnabled()) {
                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);
            } else {
                channel = new NioChannel(socket, bufhandler);
            }
        } else { // 有缓存，就重置
            channel.setIOChannel(socket);
            channel.reset();
        }
        // 注册到 Poller，由其负责后续事件驱动处理
        getPoller0().register(channel);
    } catch (Throwable t) {
        return false;
    }
    return true;
}

public void register(final NioChannel socket) {
    // 绑定所属 poller
    socket.setPoller(this);
    // 包装为 NioSocketWrapper，承载 socket 的 I/O 状态管理
    NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this);
    socket.setSocketWrapper(ka);
    ka.setPoller(this);
    // socket参数设置（超时等）
    ka.setReadTimeout(getSocketProperties().getSoTimeout());
    ka.setWriteTimeout(getSocketProperties().getSoTimeout());
    ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());
    ka.setReadTimeout(getConnectionTimeout());
    ka.setWriteTimeout(getConnectionTimeout());
    PollerEvent r = eventCache.pop();
    // 设置其能监听的可读事件（当SocketChannel可读时触发）
    ka.interestOps(SelectionKey.OP_READ);
    if (r == null) {
        r = new PollerEvent(socket, ka, OP_REGISTER);
    } else {
        r.reset(socket, ka, OP_REGISTER);
    }
    // 投递到 Poller 的事件队列，等待 selector 执行注册
    addEvent(r);
}

Poller（事件轮询器）​	Poller 是 NIO 模型中负责事件监听的线程，线程名一般为 http-nio-8080-ClientPoller。它持续轮询 Selector，将感兴趣的 IO 事件分发出去，核心流程如下：

接收来自 Acceptor 的 SocketChannel，将其注册到 Selector 中，关注 OP_READ 等事件
循环调用 Selector.select() 等待事件就绪
对于就绪事件，将对应连接封装为 SocketProcessor，提交给 Worker 线程池处理（负责请求解析与响应）

// Poller关键部分源码
public class Poller implements Runnable {

    private Selector selector;
    // PollerEvent事件队列
    private final SynchronizedQueue&lt;PollerEvent> events = new SynchronizedQueue&lt;>();

    private AtomicLong wakeupCounter = new AtomicLong(0);

    public Poller() throws IOException {
        this.selector = Selector.open();
    }

    /**
     * 添加 PollerEvent 到事件队列，并根据 wakeupCounter 唤醒 Selector，
     * 以确保 selector 能及时处理注册/取消等变更
     */
    private void addEvent(PollerEvent event) {
        events.offer(event);
        if (wakeupCounter.incrementAndGet() == 0) {
            selector.wakeup();
        }
    }

    @Override
    public void run() {
        // 循环处理事件监听
        while (true) {
            boolean hasEvents = false;

            if (!close) {
                // 处理事件队列中的注册/取消请求
                hasEvents = events();
                if (wakeupCounter.getAndSet(-1) > 0) {
                    // wakeupCounter值大于0，代表Acceptor向事件队列里push了新对象，
                    // 说明有新的连接，则立即执行非阻塞 select
                    keyCount = selector.selectNow();
                } else {
                    // 否则阻塞等待一定时间（默认1秒）以监听 I/O 事件
                    keyCount = selector.select(selectorTimeout);
                }
                // 重置
                wakeupCounter.set(0);
            }
            // 如果没有事件触发，检查是否还有待处理的注册事件
            if (keyCount == 0) {
                hasEvents = (hasEvents | events());
            }

            // 遍历触发的事件（如 OP_READ）
            Iterator&lt;SelectionKey> iterator = keyCount > 0 ? selector.selectedKeys().iterator() : null;
            while (iterator != null &amp;&amp; iterator.hasNext()) {
                SelectionKey sk = iterator.next();
                iterator.remove();
                NioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment();
                if (socketWrapper != null) {
                    /**
                     * 将就绪事件交由 Worker 线程处理（例如封装为 SocketProcessor 执行 OP_READ）
                     * 实际业务处理在 Processor 中完成
                     */
                    processKey(sk, socketWrapper);
                }
            }
            // 扫描并关闭超时连接
            timeout(keyCount, hasEvents);
        }

        getStopLatch().countDown();
    }

}

init()初始化阶段会触发的方法，调用路径：StandardService#init -&gt; Connector#init -&gt; ProtocolHandler#init -&gt; AbstractEndpoint#init -&gt; NioEndpoint#bind，核心作用如下

创建 ServerSocketChannel，并绑定至指定端口（默认 8080）
将 ServerSocketChannel 配置为 阻塞模式（accept() 会阻塞直到有连接）
初始化 Selector 池，管理 I&#x2F;O 多路复用
启动 BlockPoller  后台线程，异步检测空闲连接、关闭已超时 socket 等后台任务

public void bind() throws Exception {

    // 若未启用继承的 channel（默认如此），则创建新的 ServerSocketChannel
    if (!getUseInheritedChannel()) {
        serverSock = ServerSocketChannel.open();
        socketProperties.setProperties(serverSock.socket());
        InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort()));
        serverSock.socket().bind(addr,getAcceptCount());
    } else {
        Channel ic = System.inheritedChannel();
        if (ic instanceof ServerSocketChannel) {
            serverSock = (ServerSocketChannel) ic;
        }
        if (serverSock == null) {
            throw new IllegalArgumentException(sm.getString("endpoint.init.bind.inherited"));
        }
    }
    // 配置为阻塞模式，accept时期阻塞（重要）
    serverSock.configureBlocking(true);

    // 合理化接收线程数（默认为 1）
    if (acceptorThreadCount == 0) {
        acceptorThreadCount = 1;
    }
    // 合理化Poller线程数
    if (pollerThreadCount &lt;= 0) {
        pollerThreadCount = 1;
    }
    // 初始化关闭控制器，用于 await Poller 线程退出
    setStopLatch(new CountDownLatch(pollerThreadCount));

    initialiseSsl();

    // 初始化 Selector 池，启动BlockPoller线程
    selectorPool.open();
}

start()启动阶段触发的核心方法，调用路径：StandardService#start -&gt; Connector#start -&gt; ProtocolHandler#start -&gt; AbstractEndpoint#start，核心步骤如下

用栈的数据结构初始化Processor、Event、Nio缓存池
初始化 Worker 线程池（事件处理线程池）
初始化LimitLatch，用来限制连接个数
创建并启动Poller线程（Poller是事件轮询器，SocketChannel会将READ事件注册，并让其轮询）
创建并启动Acceptor线程（连接接收器），专用来处理连接

public void startInternal() throws Exception {

    if (!running) {
        running = true;
        paused = false;

        // =========== 初始化各类缓存栈（预分配池），提升对象复用效率，减少 GC 压力 ================
        // 请求处理器缓存池
        processorCache = new SynchronizedStack&lt;>(SynchronizedStack.DEFAULT_SIZE, socketProperties.getProcessorCache());
        // 事件对象缓存池
        eventCache = new SynchronizedStack&lt;>(SynchronizedStack.DEFAULT_SIZE, socketProperties.getEventCache());
        // NIO Channel 缓存池
        nioChannels = new SynchronizedStack&lt;>(SynchronizedStack.DEFAULT_SIZE, socketProperties.getBufferPool());

        /*
         * 初始化工作线程池（Worker Thread Pool）
         * - 若 server.xml里的Connector 节点未指定 executor，则使用默认实现。
         * - 实际线程为 daemon，线程名格式：http-nio-端口号-exec-索引
         * - 线程池大小由 AbstractEndpoint 的 minSpareThreads 和 maxThreads 控制
         */
        if (getExecutor() == null) {
            createExecutor();
        }
        // 初始化连接限制器（内部用 Semaphore 控制最大连接数）
        initializeConnectionLatch();

        // 启动 Poller 线程（其数量可通过 server.xml 中 Connector 属性 `pollerThreadCount`配置）
        pollers = new Poller[getPollerThreadCount()];
        for (int i = 0; i &lt; pollers.length; i++) {
            pollers[i] = new Poller();
            Thread pollerThread = new Thread(pollers[i], getName() + "-ClientPoller-" + i);
            pollerThread.setPriority(threadPriority);
            pollerThread.setDaemon(true); // 也是daemon线程
            pollerThread.start();
        }

        // 启动 Acceptor 线程
        startAcceptorThreads();
    }
}

MapperListener​	这个组件理解其作用就行，源码不值得深入分析，价值不大。它是一个用于监听容器结构变化、并同步更新到Mapper 组件中映射关系的辅助组件。其核心作用如下：

启动时注册
在 startInternal() 中：
将自身注册为 Engine、Host、Context、Wrapper 容器的 ContainerListener
遍历并将当前 Engine 及其所有子容器的路由信息（如 host name、context path、wrapper mapping 等）注册进 Mapper




监听容器事件
实现 containerEvent() 方法，监听容器结构变化事件（如 Host 增加 alias、Context 增加&#x2F;移除 Wrapper 等），当结构变更时，自动将变化同步更新到 Mapper，保证路由信息的时效性



Mapper​	同上面的MapperListener，理解作用即可，源码深入分析的价值不大。我把它叫做路由器，其负责将 HTTP 请求路径快速匹配到对应的 Servlet。其本身不参与请求处理，仅提供路径与容器结构之间的高性能映射机制。
​	内部通过 MapperListener 监听容器层级（Engine → Host → Context → Wrapper）的结构变更，动态构建和维护内部的映射模型。其内部将Container抽象为轻量级MapElement结构体并按层级关系嵌套组织，构建出一棵用于快速匹配的树状结构。当请求到来时，根据url从左至右快速的查找到对应唯一的Host -&gt; Context -&gt; Wrapper，让它们来处理对应的请求。
总结
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Acceptor</tag>
        <tag>Poller</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-Session管理</title>
    <url>/2022-01-09/tomcat-session-guan-li/</url>
    <content><![CDATA[
​	本文从源码出发，剖析 Tomcat 中 Session 的懒加载、保活与生命周期控制机制，并解析了 StandardManager 如何借助序列化完成热部署场景下的 Session 持久化与自动恢复


​	在 StandardContext#start() 阶段，Tomcat 会默认创建一个 StandardManager 实例作为 Session 管理器。它是一个基于本地 JVM 内存的实现，负责：

实例化和缓存Session
定期检查并清理过期的 Session
在 Context 热加载触发时，将 Session 序列化持久化到磁盘。并在启动后，尝试从磁盘恢复上一次的 Session 数据

那么这些功能具体是怎么实现的呢？我们接下来结合源码逐一分析，也顺便看看有没有什么值得优化的地方。
Session创建、缓存和刷新获取和创建Tomcat 中的 Session 采用 懒加载策略，即只有在显式调用 HttpServletRequest#getSession()时，才会触发 Session 的获取或创建、绑定到当前Request等操作。该逻辑核心实现位于 org.apache.catalina.connector.Request#doGetSession 方法，其处理流程如下：

已绑定有效 Session：若当前 Request 已绑定有效 Session，直接返回；
尝试查找已有 Session：从全局缓存中查找session，如果存在则刷新访问时间，在绑定到当前Request并返回
按需创建新 Session：create&#x3D;true才创建session。先进行sessionId的校验（避免伪造攻击），再创建默认的StandardSession并全局缓存，记录访问时间后返回

protected Session doGetSession(boolean create) {

    Context context = getContext();
    if (context == null) {
        return null;
    }
    // 当前request中已获取过session切session有效，则直接返回
    if ((session != null) &amp;&amp; !session.isValid()) {
        session = null;
    }
    if (session != null) {
        return session;
    }

    Manager manager = context.getManager();
    if (manager == null) {
        return null; 
    }
    if (requestedSessionId != null) {
        try {
            // 从缓存中找session
            session = manager.findSession(requestedSessionId);
        } catch (IOException e) {
            session = null;
        }
        if ((session != null) &amp;&amp; !session.isValid()) {
            session = null;
        }
         // session找到了且有效，刷新访问时间后返回
        if (session != null) {
            session.access();
            return session;
        }
    }

    // 不许要创建则直接返回
    if (!create) {
        return null;
    }
    boolean trackModesIncludesCookie = context.getServletContext().getEffectiveSessionTrackingModes()
            .contains(SessionTrackingMode.COOKIE);
    if (trackModesIncludesCookie &amp;&amp; response.getResponse().isCommitted()) {
        throw new IllegalStateException(sm.getString("coyoteRequest.sessionCreateCommitted"));
    }
    // ====================== 到这里，表示需要创建session ================

    // 对客户端提供的sessionId进行校验，一般来说是不允许使用客户端提供的sessionId创建session的
    String sessionId = getRequestedSessionId();
    if (requestedSessionSSL) { // 一般不会走这

    } else if (("/".equals(context.getSessionCookiePath())
            &amp;&amp; isRequestedSessionIdFromCookie())) {
        // 支持跨 Context 共享 sessionId（必须配置 cookiePath="/" 且启用校验，默认已启用）
        if (context.getValidateClientProvidedNewSessionId()) {
            boolean found = false;
            for (Container container : getHost().findChildren()) {
                Manager m = ((Context) container).getManager();
                if (m != null) {
                    try {
                        if (m.findSession(sessionId) != null) {
                            found = true;
                            break;
                        }
                    } catch (IOException e) {
                    }
                }
            }
            if (!found) {
                // 未找到则清空，避免伪造攻击
                sessionId = null;
            }
        }
    } else {
        sessionId = null;
    }

    // 新建session（默认StandardSession）
    session = manager.createSession(sessionId);
    // 设置cookie到response中
    if (session != null &amp;&amp; trackModesIncludesCookie) {
        Cookie cookie = ApplicationSessionCookieConfig.createSessionCookie(
                context, session.getIdInternal(), isSecure());

        response.addSessionCookieInternal(cookie);
    }

    if (session == null) {
        return null;
    }
    session.access();
    return session;
}

/**
 * org.apache.catalina.session.ManagerBase#createSession中真正创建session
 */
public Session createSession(String sessionId) {

    // session数量较校验（默认-1无上限）
    if ((maxActiveSessions >= 0) &amp;&amp;
            (getActiveSessions() >= maxActiveSessions)) {
        rejectedSessions++;
        throw new TooManyActiveSessionsException(
                sm.getString("managerBase.createSession.ise"),
                maxActiveSessions);
    }

    Session session = createEmptySession();
    session.setNew(true);
    session.setValid(true);
    session.setCreationTime(System.currentTimeMillis());
    // session最大不活跃的时间（默认30分钟）
    session.setMaxInactiveInterval(getContext().getSessionTimeout() * 60);
    String id = sessionId;
    if (id == null) {
        id = generateSessionId();
    }
    // 设置id并将这个session缓存到ManagerBase#sessions里
    session.setId(id);
    sessionCounter++;

    SessionTiming timing = new SessionTiming(session.getCreationTime(), 0);
    synchronized (sessionCreationTiming) {
        sessionCreationTiming.add(timing);
        sessionCreationTiming.poll();
    }
    return session;
}

刷新只有在一次 HTTP 请求中真正访问了 Session，Tomcat 才会刷新它的访问时间，具体如下：


当请求中第一次调用 request.getSession() 或相关方法时，会触发 org.apache.catalina.Session#access()，记录这次访问的时间
而在请求结束的时候，会调用 Session#endAccess() 来记录会话访问的结束时间。调用链为： CoyoteAdapter#service（方法最后部分） → Request#recycle → Request#recycleSessionInfo → Session#endAccess()


通过这套机制，Tomcat 仅在真正使用了Session的请求中才刷新它的访问时间，从而实现只在用到时才保活
Session过期清理入口被StandardEngine的backgroundThread定期触发，调用路径为：ContainerBackgroundProcessor#run -&gt; ContainerBackgroundProcessor#processChildren -&gt; StandardContext.backgroundProcess -&gt; Manager#backgroundProcess -&gt; ManagerBase#processExpires
public void processExpires() {

    long timeNow = System.currentTimeMillis();
    // 所有session
    Session sessions[] = findSessions();
    int expireHere = 0;
    for (Session session : sessions) {
        // 对session校验是否式或并清理
        if (session != null &amp;&amp; !session.isValid()) {
            expireHere++;
        }
    }
    long timeEnd = System.currentTimeMillis();
    processingTime += (timeEnd - timeNow);

}

校验清理StandardSession#isValid为校验session是否有效，如果无效则进行清理。整体逻辑比较简单，稍微关注下会被触发的如下三个EventListener，如果有session和其attribute的监听需求就可以用到：

HttpSessionListener#sessionDestroyed：Session 被销毁时触发。适合用于监听整体 Session 生命周期的结束
HttpSessionBindingListener#valueUnbound：当某个属性从 Session 中移除，且该属性实现了该接口时触发。偏个体
HttpSessionAttributeListener#attributeRemoved：Session 中的属性被移除时触发，属性可以不实现这个Listener。偏集中

public boolean isValid() {

    if (!this.isValid) {
        return false;
    }

    if (this.expiring) {
        return true;
    }

    if (ACTIVITY_CHECK &amp;&amp; accessCount.get() > 0) {
        return true;
    }

    if (maxInactiveInterval > 0) {
        // 判断空闲时间是否超过最大不活跃时间，并进行清理
        int timeIdle = (int) (getIdleTimeInternal() / 1000L);
        if (timeIdle >= maxInactiveInterval) {
            expire(true);
        }
    }

    return this.isValid;
}

/*
 *  使session过期（从缓存中移除），并根据是否notify决定是否通知相关EventListener
 */
public void expire(boolean notify) {
    if (!isValid) {
        return;
    }

    synchronized (this) {

        if (expiring || !isValid) {
            return;
        }

        if (manager == null) {
            return;
        }

        expiring = true;

        Context context = manager.getContext();
        // 是否通知相关Listener
        if (notify) {
            ClassLoader oldContextClassLoader = null;
            try {
                oldContextClassLoader = context.bind(Globals.IS_SECURITY_ENABLED, null);
                Object listeners[] = context.getApplicationLifecycleListeners();
                if (listeners != null &amp;&amp; listeners.length > 0) {
                    HttpSessionEvent event = new HttpSessionEvent(getSession());
                    for (int i = 0; i &lt; listeners.length; i++) {
                        // 触发HttpSessionListener的sessionDestroyed事件
                        int j = (listeners.length - 1) - i;
                        if (!(listeners[j] instanceof HttpSessionListener)) {
                            continue;
                        }
                        HttpSessionListener listener = (HttpSessionListener) listeners[j];
                        try {
                            context.fireContainerEvent("beforeSessionDestroyed",
                                    listener);
                            listener.sessionDestroyed(event);
                            context.fireContainerEvent("afterSessionDestroyed",
                                    listener);
                        } catch (Throwable t) {
                            manager.getContext().getLogger().error(sm.getString("standardSession.sessionEvent"), t);
                        }
                    }
                }
            } finally {
                context.unbind(Globals.IS_SECURITY_ENABLED, oldContextClassLoader);
            }
        }

        if (ACTIVITY_CHECK) {
            accessCount.set(0);
        }

        // 从缓存中移除
        manager.remove(this, true);

        if (notify) {
            fireSessionEvent(Session.SESSION_DESTROYED_EVENT, null);
        }

        setValid(false);
        expiring = false;

        String keys[] = keys();
        ClassLoader oldContextClassLoader = null;
        try {
            oldContextClassLoader = context.bind(Globals.IS_SECURITY_ENABLED, null);
            // 触发session key相关Listener
            for (String key : keys) {
                removeAttributeInternal(key, notify);
            }
        } finally {
            context.unbind(Globals.IS_SECURITY_ENABLED, oldContextClassLoader);
        }
    }

}

Session持久化众所周知，Tomcat 中Web 应用支持热部署，在热加载过程中，原来的Context会被卸载，它所持有的所有对象（包括HttpSession）都会被销毁。
但从业务逻辑角度来看，session 的生命周期不应该被应用自身的重部署打断。客户端用户都没登出，如果仅因为服务端代码热更新就丢失session数据，用户会难以接受
所以为了解决这个问题，Tomcat 的StandardManager实现了 session 的持久化机制。核心思想是：

在 Context 停止前（如热部署时），将内存中的所有有效 session 序列化写入磁盘
在 Context 启动时，尝试从磁盘加载这些 session，并恢复到内存中

两个核心方法如下：

StandardManager#doUnload：context#stop时触发，将session序列化到磁盘
StandardManager#doLoad：context#start时触发，将磁盘的session文件反序列化到内存

protected void doUnload() throws IOException {


    if (sessions.isEmpty()) {
        return; // nothing to do
    }

    // 默认为当前context的 ${javax.servlet.context.tempdir}/SESSIONS.ser 文件
    File file = file();
    if (file == null) {
        return;
    }

    // 即将被卸载的 session 实例
    List&lt;StandardSession> list = new ArrayList&lt;>();

    try (FileOutputStream fos = new FileOutputStream(file.getAbsolutePath());
            BufferedOutputStream bos = new BufferedOutputStream(fos);
            ObjectOutputStream oos = new ObjectOutputStream(bos)) {

        synchronized (sessions) {
            oos.writeObject(Integer.valueOf(sessions.size()));
            // 将session序列化到磁盘
            for (Session s : sessions.values()) {
                StandardSession session = (StandardSession) s;
                list.add(session);
                session.passivate();
                session.writeObjectData(oos);
            }
        }
    }

    // 清楚session，但不触发通知（毕竟未真正失活）
    for (StandardSession session : list) {
        try {
            session.expire(false);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
        } finally {
            session.recycle();
        }
    }

}

protected void doLoad() throws ClassNotFoundException, IOException {

    sessions.clear();

    File file = file();
    // 没有就返回
    if (file == null) {
        return;
    }
    Loader loader = null;
    ClassLoader classLoader = null;
    Log logger = null;
    try (FileInputStream fis = new FileInputStream(file.getAbsolutePath());
            BufferedInputStream bis = new BufferedInputStream(fis)) {
        Context c = getContext();
        loader = c.getLoader();
        logger = c.getLogger();
        // 使用当前contxet的WebappClassLoader，加载session
        if (loader != null) {
            classLoader = loader.getClassLoader();
        }
        if (classLoader == null) {
            classLoader = getClass().getClassLoader();
        }

        synchronized (sessions) {
            try (ObjectInputStream ois = new CustomObjectInputStream(bis, classLoader, logger,
                    getSessionAttributeValueClassNamePattern(),
                    getWarnOnSessionAttributeFilterFailure())) {
                Integer count = (Integer) ois.readObject();
                int n = count.intValue();
                for (int i = 0; i &lt; n; i++) {
                    // 反序列化到内存
                    StandardSession session = getNewSession();
                    session.readObjectData(ois);
                    session.setManager(this);
                    sessions.put(session.getIdInternal(), session);
                    // 通知 session 已激活
                    session.activate();
                    if (!session.isValidInternal()) {
                        session.setValid(true);
                        session.expire();
                    }
                    sessionCounter++;
                }
            } finally {
                if (file.exists()) {
                    // 删除持久化文件，避免重复加载
                    if (!file.delete()) {
                        log.warn(sm.getString("standardManager.deletePersistedFileFail", file));
                    }
                }
            }
        }
    } catch (FileNotFoundException e) {
        return;
    }

}

]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
  </entry>
  <entry>
    <title>Tomcat-启动流程和http请求流程</title>
    <url>/2021-10-18/tomcat-qi-dong-liu-cheng-he-http-qing-qiu-liu-cheng/</url>
    <content><![CDATA[
​	分析并总结了tomcat的启动流程和整个http请求流程，重点可关注启动流程的UML图和请求流程图




启动流程通过前面几篇的铺垫，现在终于可以进入到tomcat的启动流程了


架构和Lifecycle
Server,Service,Conncector,ProtocolHandler和NioEndpoint
Engine,Host和HostConfig
Context,ContextConfig和Wrapper


​	Tomcat 的启动通常通过执行 catalina.sh start 命令完成。通过如下脚本可知是调用 org.apache.catalina.startup.Bootstrap#main(String[] args) 方法，并传入了 start 参数。

Bootstrap#main
启动流程UML

Bootstrap 初始化​	主要是初始化三个类加载器（Common、Catalina、Shared），并实例化Catalina对象，为后续的load和start方法做准备
Catalina#load()​	解析 conf/server.xml 配置文件，构建出一个Server树，并初始化Server（Server#init）
Catalina#start()​	启动Server组件（Server#start）
重点
容器的init() 并不会向子容器递归传播

​	除了 Engine 容器在 load() 阶段被显式初始化外，其余子容器（如 Host、Context、Wrapper）的初始化会延迟到 start() 阶段。也就是说，start() 阶段才是触发完整容器结构构建的关键时机


Socket 层组件的启动滞后于容器启动

​	只有整个容器启动完毕，确保业务逻辑准备完毕，然后才启动 Connector 及其内部的 ProtocolHandler 和 Endpoint（负责监听端口与处理 Socket 请求）。避免http请求到来时，容器还不可用的状态


Context 容器由 HostConfig 解析生成

​	Host 启动时会触发其绑定的 LifecycleListener — HostConfig，来解析和构造StandardContext子容器


Wrapper、Filter、Listener 由 ContextConfig 解析构建

​	Context启动中会触其绑定的 LifecycleListener — ContextConfig，来进行全部的web.xml解析，完成对 Wrapper（即 Servlet）、Filter、Listener 等组件的构建与注册



请求流程
流程总结
Acceptor线程（监听并接受连接）


Acceptor线程监听到8080端口产生的连接，将其构造为PollerEvent提交到Poller 的事件队列中



Poller线程（事件注册和监听）


轮询处理事件队列，将 PollerEvent 注册到 Java NIO 的 Selector 中，监听 OP_READ 事件
当某个 channel 上有数据可读时，构造一个 SocketProcessor 实例，并提交给后端的 worker 线程池执行。



Worker线程（处理Socket请求）


SocketProcessor#doRun：进行tcp握手处理
ConnectionHandler#process：从 Processor 缓存池中获取或新建协议处理器（如 Http11Processor），并交由其处理请求
AbstractProcessorLight#process：对不同的socket状态进行分发和处理（SocketEvent.OPEN_READ则走到Http11Processor#service）
Http11Processor#service：通过Http11InputBuffer解析http请求，构造成Request和Response。并分发给CoyoteAdapter#service
CoyoteAdapter#service：通过Mapper组件将请求 URL 映射到对应的 Host、Context、Wrapper并缓存，再调用顶层容器（Engine）的 Pipeline，正式进入容器级别的处理逻辑。
请求通过容器中内部Pipeline里的Valve，从basic Valve流出再流向下一层容器中的first Valve：StandardEngineValve -&gt; StandardHostValve -&gt; StandardContextValve -&gt; StandardWrapperValve
最后一个阀门StandardWrapperValve：先进行Servlet的分配，再构造ApplicationFilterChain（过滤出对当前url能使用的Filter），依次调用 doFilter() 进行链式处理，全部通过后最终便走到Servlet#service中




重点
Tomcat 使用 责任链（Pipeline + Valve） 模式处理请求流转，清晰解耦了容器级别的处理职责
Processor 实例在请求结束后可被复用，避免重复构造，提升性能
NIO + 多线程池模型实现高并发处理，前端是少量 Acceptor&#x2F;Poller 线程，后端是灵活扩展的 Worker 线程池。

worker线程栈示例
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
  </entry>
  <entry>
    <title>Tomcat-整体架构和Lifecycle</title>
    <url>/2021-08-19/tomcat-zheng-ti-jia-gou-he-lifecycle/</url>
    <content><![CDATA[
​	基于Tomcat-8.5.x版本，简单分析了整体的架构和核心组件。并详细分析和总结了Lifecycle机制




核心组件和架构Tomcat 的架构可以抽象为一棵树，核心组件结构如下：

根节点是 Server，表示整个 Tomcat 实例（即一个 JVM 进程）
Server 下包含一个或多个 Service，代表一组 Web 服务
每个 Service 包含：
一个或多个 Connector，负责监听不同协议&#x2F;端口的请求（如 HTTP、HTTPS）
唯一的一个 Engine，与Service一对一的关系，用于处理由 Connector 接收到的请求


Engine 下包含多个 Host，每个 Host 对应一个虚拟主机（通过域名区分）
每个 Host管理多个 Context，每个 Context 对应一个 Web 应用（即一个 war）
每个 Context 下包含多个 Wrapper，每个 Wrapper 对应一个具体的 Servlet


Lifecycle​	Lifecycle 是 Tomcat 中最核心的接口之一。所有关键组件都实现了该接口，以便在生命周期事件（如init、start、stop等）到来时执行自身的职责，并将事件级联传递给子组件。因此，深入理解 Lifecycle 的作用和机制，是阅读和掌握 Tomcat 源码的基础。
public interface Lifecycle {

    // ======================== 生命周期事件常量 ========================

    String BEFORE_INIT_EVENT = "before_init";
    String AFTER_INIT_EVENT = "after_init";

    String BEFORE_START_EVENT = "before_start";
    String START_EVENT = "start";
    String AFTER_START_EVENT = "after_start";

    String BEFORE_STOP_EVENT = "before_stop";
    String STOP_EVENT = "stop";
    String AFTER_STOP_EVENT = "after_stop";

    String BEFORE_DESTROY_EVENT = "before_destroy";
    String AFTER_DESTROY_EVENT = "after_destroy";

    /** 周期性事件（如后台定时任务触发） */
    String PERIODIC_EVENT = "periodic";

    /** 配置启动事件（内部扩展使用） */
    String CONFIGURE_START_EVENT = "configure_start";
    /** 配置停止事件（内部扩展使用） */
    String CONFIGURE_STOP_EVENT = "configure_stop";

    // ======================== 生命周期监听器相关方法 ========================

    void addLifecycleListener(LifecycleListener listener);

    LifecycleListener[] findLifecycleListeners();

    void removeLifecycleListener(LifecycleListener listener);

    // ======================== 生命周期控制方法 ========================

    /**
     * 初始化组件。组件只能初始化一次，且必须在启动前完成。
     */
    void init() throws LifecycleException;

    /**
     * 启动组件。如果未初始化，会隐式调用 init()
     */
    void start() throws LifecycleException;

    /**
     * 停止组件。可在调用 start() 后再次调用以恢复运行
     */
    void stop() throws LifecycleException;

    /**
     * 销毁组件，释放资源。此操作不可逆。
     */
    void destroy() throws LifecycleException;

    LifecycleState getState();

    String getStateName();

    /**
     * 标记接口：表示该组件只能使用一次（单次使用后即不可重启）
     */
    interface SingleUse {
    }
}

LifecycleState​	组件的生命周期状态枚举。每个状态标记了当前组件是否处于“可用”状态（available），以及对应的生命周期事件名（lifecycleEvent）
public enum LifecycleState {

    // 初始状态，尚未进行任何初始化操作
    NEW(false, null),

    // ================= 初始化阶段 =================

    // 初始化中，调用 init() 时进入此状态，发布 before_init 事件
    INITIALIZING(false, Lifecycle.BEFORE_INIT_EVENT),

    // 初始化完成，进入 INITIALIZED 状态，发布 after_init 事件
    INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT),

    // ================= 启动阶段 =================

    // 启动准备中，准备启动前进入该状态，发布 before_start 事件
    STARTING_PREP(false, Lifecycle.BEFORE_START_EVENT),

    // 正在启动，执行 startInternal() 时进入此状态，发布 start 事件
    STARTING(true, Lifecycle.START_EVENT),

    // 启动完成，组件已处于工作状态，发布 after_start 事件
    STARTED(true, Lifecycle.AFTER_START_EVENT),

    // ================= 停止阶段 =================

    // 停止准备阶段，准备停止时进入该状态，发布 before_stop 事件
    STOPPING_PREP(true, Lifecycle.BEFORE_STOP_EVENT),

    // 正在停止，组件关闭过程中进入该状态，发布 stop 事件
    STOPPING(false, Lifecycle.STOP_EVENT),

    // 停止完成，组件已不可用，发布 after_stop 事件
    STOPPED(false, Lifecycle.AFTER_STOP_EVENT),

    // ================= 销毁阶段 =================

    // 销毁准备阶段，发布 before_destroy 事件
    DESTROYING(false, Lifecycle.BEFORE_DESTROY_EVENT),

    // 销毁完成，组件进入不可恢复终态，发布 after_destroy 事件
    DESTROYED(false, Lifecycle.AFTER_DESTROY_EVENT),

    // ================= 异常状态 =================

    // 异常失败状态，组件启动或运行中发生未处理异常，进入失败态。无生命周期事件发布
    FAILED(false, null);

    /**
     * 当前状态是否为组件的“可用”状态，即是否可对外提供服务（如 STARTING、STARTED 等）
     */
    private final boolean available;

    private final String lifecycleEvent;

    LifecycleState(boolean available, String lifecycleEvent) {
        this.available = available;
        this.lifecycleEvent = lifecycleEvent;
    }

    public boolean isAvailable() {
        return available;
    }

    public String getLifecycleEvent() {
        return lifecycleEvent;
    }
}

LifecycleBase​	LifecycleBase 是 Lifecycle 接口的基础实现类，提供了生命周期控制方法（如 init()、start()、stop()、destroy()）的通用模板逻辑。Tomcat 中绝大多数实现了 Lifecycle 接口的核心组件，都会继承该类，从而复用其统一的状态管理和事件分发机制。
​	核心start方法分析如下，（其余的init，stop等方法差不太多，就不做详细的分析了）
public abstract class LifecycleBase implements Lifecycle {
    /**
     * 启动组件。线程安全，具备幂等性。
     * 
     * 生命周期状态迁移如下：
     * NEW -> INITIALIZED -> STARTING_PREP -> STARTING -> STARTED
     * 如果启动失败，将进入 FAILED 状态。
     */
    public final synchronized void start() throws LifecycleException {

        if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) ||
                LifecycleState.STARTED.equals(state)) {
            // 正在启动中或已启动，无视直接返回
            return;
        }

        // ============= 前置状态判断 =================
        if (state.equals(LifecycleState.NEW)) {
            // 如果还是初始化状态，就先初始化
            init();
        } else if (state.equals(LifecycleState.FAILED)) {
            // 若之前启动失败，先尝试停止，清理资源后重新启动
            stop();
        } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp;
                !state.equals(LifecycleState.STOPPED)) {
            // 其余非法前置状态，直接异常
            invalidTransition(Lifecycle.BEFORE_START_EVENT);
        }
        // ============== 到这表示前置状态处理完毕，可以真正start了 ===================

        try {
            // 设置状态为 STARTING_PREP，并发布 before_start 事件
            setStateInternal(LifecycleState.STARTING_PREP, null, false);
            // 调用子类实现的实际启动逻辑（模板方法模式）
            startInternal();
            // ============ 走到这，正常情况state就应该为STARTING了 =================

            if (state.equals(LifecycleState.FAILED)) {
                // 启动失败，执行stop
                stop();
            } else if (!state.equals(LifecycleState.STARTING)) {
                // 非STARTING（正常不应该出现，避免子类实现不规范的一种fallback），直接抛异常
                invalidTransition(Lifecycle.AFTER_START_EVENT);
            } else {
                // 正常会走到这，状态自动置为STARTED。并发布 after_start 事件
                setStateInternal(LifecycleState.STARTED, null, false);
            }
        } catch (Throwable t) {
            handleSubClassException(t, "lifecycleBase.startFail", toString());
        }
    }

}

总结
Lifecycle状态转换图

状态机核心要点：

启动组件必定要先init，也只会调用一次init
start和stop状态可以循环相互转化（即STOPPED状态不是终态）
NEW可直接到STOPPED状态（很少这么用）
DESTROYED才是终态，不可逆转（FAILED都不是终态，它还可以stop() -&gt; startI()，虽然不一定成功）

]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
  </entry>
  <entry>
    <title>Tomcat-热加载之ThreadLocal内存泄漏篇（二）</title>
    <url>/2021-12-23/tomcat-re-jia-zai-zhi-threadlocal-nei-cun-xie-lou-pian-er/</url>
    <content><![CDATA[
​	通过举例深入的分析了热加载场景下ThreadLocal使用不当造成的内存泄漏。并剖析了Tomcat通过实现无效的ThreadLocalMap.Entry清除、ThreadLocalLeakPreventionListener回收空闲worker线程和TaskQueue对取任务逻辑的重写来兜底剩余worker线程回收这三种策略来优雅的解决ThreadLocal内存泄漏的问题


​	上一篇讨论了Tomcat热加载期间垃圾的产生与分类，并且探讨了对Context线程回收的必要性以及Tomcat的实现。而这篇会来分析一个更棘手的问题：如果项目中ThreadLocal如果使用不当，热加载后是如何引起内存泄漏的，并着重分析基于这个问题，Tomcat的考量以及如何优雅的解决这个问题
问题​	Tomcat 在执行热加载时，会主动停止当前 Context 中由应用创建的线程（通过遍历 JVM 中所有线程并判断其 contextClassLoader 是否为当前 WebappClassLoader 来过滤）。但这并不包括用于处理 HTTP 请求的 Worker 线程。这些线程服务于整个 JVM 生命周期，不会被某个 Context 独占或绑定到某个特定的 WebappClassLoader
​	问题在于，ThreadLocal是和线程绑定的。如果某个应用将其资源（比如 Spring 的上下文、Class、Bean 等）放入了 Worker 线程的 ThreadLocal 中，而该资源又直接或间接引用了 WebappClassLoader，就会导致这个 WebappClassLoader和其加载的所有Class无法被 GC 回收。最终，随着热加载次数增加，最终触发 OOM

换句话说：共享线程+ThreadLocal+Context类资源 &#x3D; 热加载内存泄漏的元凶之一。

案例分析所有案例中MyCounter一致，为计数器。目的是实现对Tomcat worker线程处理了多少次http请求的计数。
分析之前可以看看我的这篇文章，对ThreadLocal要有一个比较深刻的认识最好
demo1public class LeakingServlet extends HttpServlet {

    public final static ThreadLocal&lt;MyCounter> COUNTER_THREAD_LOCAL = ThreadLocal.withInitial(MyCounter::new);

    public static class MyCounter {
        private int count = 0;

        public void increment() {
            count++;
        }

        public int getCount() {
            return count;
        }
    }

    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) {
        MyCounter counter = LeakingServlet.COUNTER_THREAD_LOCAL.get();
        counter.increment();
        // doBusiness...
    }
}

字段COUNTER_THREAD_LOCAL 是一个静态变量，被LeakingServlet.class对象给持有

​	当请求进入后，会触发一个如下的引用链图。ThreadLocal本身被Entry这个虚引用对象持有，但还被另一边的强引用LeakingServlet.class也持有了，会导致ThreadLocal不能触发虚引用的回收作用，致使对应的value（MyCounter对象）也不会回收，而MyCounter间接持有的WebappClassLoader和其所加载的所有class对象也都不能被回收，引发了内存泄漏


demo1引用链

demo2public class LeakingServlet extends HttpServlet {

    public final ThreadLocal&lt;MyCounter> COUNTER_THREAD_LOCAL = ThreadLocal.withInitial(MyCounter::new);

    public static class MyCounter {
        private int count = 0;

        public void increment() {
            count++;
        }

        public int getCount() {
            return count;
        }
    }

    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) {
        MyCounter counter = COUNTER_THREAD_LOCAL.get();
        counter.increment();
        // doBusiness...
    }
}

​	此时COUNTER_THREAD_LOCAL非静态，被LeakingServlet对象持有。引用链图如下，此案例中理论上不会有内存泄漏

​	持有ThreadLocal强引用的LeakingServlet对象会被置为null并被回收，回收后仅被虚引用持有的ThreadLocal就能被回收，那么其value（MyCounter对象）也能在后续ThreadLocalMap对Entry修改时被检测到并被手动释放后回收。上层引用链都断开，那么下面的WebappClassLoader也能被回收了

​	但这并不意味着立即释放，虽然最终是可以回收的，但在回收检测发生之前，ThreadLocalMap中的 value（MyCounter）依旧存活，仍然间接引用着WebappClassLoader及其加载的所有类，就导致这段「悬挂时间」里依旧存在内存压力

demo2引用链

demo3public class LeakingServlet extends HttpServlet {

    public final TransmittableThreadLocal&lt;MyCounter> COUNTER_THREAD_LOCAL = TransmittableThreadLocal.withInitial(MyCounter::new);

    public static class MyCounter {
        private int count = 0;

        public void increment() {
            count++;
        }

        public int getCount() {
            return count;
        }
    }

    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) {
        MyCounter counter = COUNTER_THREAD_LOCAL.get();
        counter.increment();
        // doBusiness...
    }
}

此时COUNTER_THREAD_LOCAL还是非静态且被LeakingServlet对象持有，但ThreadLocal为第三方的TransmittableThreadLocal，其引用链图如下。核心分析其实和demo2一样，TransmittableThreadLocal对象还是能被回收，也同样具备因不能及时回收value而导致WebappClassLoader不能被回收的隐式风险

demo3引用链

解决方案清除ThreadLocalMap$Entry核心方法在WebappClassLoaderBase#checkThreadLocalsForLeaks，调用链为：


WebappLoader#stop
WebappClassLoaderBase#stop
WebappClassLoaderBase#clearReferences 
WebappClassLoaderBase#checkThreadLocalsForLeaks（需要clearReferencesThreadLocals&#x3D;true，默认也为true）


private void checkThreadLocalsForLeaks() {
    // 获取JVM的所有线程
    Thread[] threads = getThreads();

    try {
        // 获取Thread中threadLocals与inheritableThreadLocals两个字段
        Field threadLocalsField = Thread.class.getDeclaredField("threadLocals");
        threadLocalsField.setAccessible(true);
        Field inheritableThreadLocalsField = Thread.class.getDeclaredField("inheritableThreadLocals");
        inheritableThreadLocalsField.setAccessible(true);
        // ThreadLocalMap.table 数组字段（用于存储 Entry 的数组）
        Class&lt;?> tlmClass = Class.forName("java.lang.ThreadLocal$ThreadLocalMap");
        Field tableField = tlmClass.getDeclaredField("table");
        tableField.setAccessible(true);
        // ThreadLocalMap中删除过期Entry方法
        Method expungeStaleEntriesMethod = tlmClass.getDeclaredMethod("expungeStaleEntries");
        expungeStaleEntriesMethod.setAccessible(true);

        for (Thread thread : threads) {
            Object threadLocalMap;
            if (thread != null) {

                // 检查 threadLocals
                threadLocalMap = threadLocalsField.get(thread);
                if (null != threadLocalMap) {
                    // 主动触发清理过期Entry（即key被回收的Entry）
                    expungeStaleEntriesMethod.invoke(threadLocalMap);
                    checkThreadLocalMapForLeaks(threadLocalMap, tableField);
                }

                // 检查 inheritableThreadLocals
                threadLocalMap = inheritableThreadLocalsField.get(thread);
                if (null != threadLocalMap) {
                    expungeStaleEntriesMethod.invoke(threadLocalMap);
                    checkThreadLocalMapForLeaks(threadLocalMap, tableField);
                }
            }
        }
    } catch (Throwable t) {
        // 异常处理...
    }
}

private void checkThreadLocalMapForLeaks(Object map,
        Field internalTableField) throws IllegalAccessException,
        NoSuchFieldException {
    if (map != null) {
        Object[] table = (Object[]) internalTableField.get(map);
        if (table != null) {
            for (Object obj : table) {
                if (obj != null) {
                    boolean keyLoadedByWebapp = false;
                    boolean valueLoadedByWebapp = false;
                    // 检查key（即为ThreadLocal对象或其子类）
                    Object key = ((Reference&lt;?>) obj).get();
                    // loadedByThisOrChild用于检测指定的对象（也支持集合）及其所有父类是否有当前WebappClassLoader所加载
                    if (this.equals(key) || loadedByThisOrChild(key)) {
                        keyLoadedByWebapp = true;
                    }
                    // 检查value（ThreadLocal里真正存放的对象）
                    Field valueField = obj.getClass().getDeclaredField("value");
                    valueField.setAccessible(true);
                    Object value = valueField.get(obj);
                    if (this.equals(value) || loadedByThisOrChild(value)) {
                        valueLoadedByWebapp = true;
                    }
                    // key 或 value 被当前 WebappClassLoader 加载，说明有潜在泄漏
                    if (keyLoadedByWebapp || valueLoadedByWebapp) {
                        Object[] args = new Object[5];
                        args[0] = getContextName();
                        if (key != null) {
                            args[1] = getPrettyClassName(key.getClass());
                            try {
                                args[2] = key.toString();
                            } catch (Exception e) {
                                // ...
                            }
                        }
                        if (value != null) {
                            args[3] = getPrettyClassName(value.getClass());
                            try {
                                args[4] = value.toString();
                            } catch (Exception e) {
                                // ...
                            }
                        }
                        // =========== 仅打日志。value泄漏用error打印，key泄漏则用debug打印 ================
                        if (valueLoadedByWebapp) {
                            log.error(sm.getString(
                                    "webappClassLoader.checkThreadLocalsForLeaks",
                                    args));
                        } else if (value == null) {
                            if (log.isDebugEnabled()) {
                                log.debug(sm.getString(
                                        "webappClassLoader.checkThreadLocalsForLeaksNull",
                                        args));
                            }
                        } else {
                            if (log.isDebugEnabled()) {
                                log.debug(sm.getString(
                                        "webappClassLoader.checkThreadLocalsForLeaksNone",
                                        args));
                            }
                        }
                    }
                }
            }
        }
    }
}

总结其核心逻辑只有两个：

通过反射调用所有线程里ThreadLocalMap#expungeStaleEntry，来主动清除需要被GC的Entry。解决案例中demo2和demo3的隐式隐患
如果Entry里的key（ThreadLocal）和value的相关class由当前WebappClassLoader加载，也仅打日志

为什么仅打日志呢？

​	 因为ThreadLocal中存放的通常是业务线程正在使用的上下文信息（如用户信息、缓存等）。Tomcat 无法判断这些值是否仍然有效或在使用中，如果直接释放掉可能导致运行中的Web程序抛出相关的空指针，因此选择了保守处理，只警告不干预

线程回收ThreadLocalLeakPreventionListener​	Tomcat 默认启用了 ThreadLocalLeakPreventionListener（已在 server.xml 中配置）。在触发热加载时，该Listener 会监听 Lifecycle.AFTER_STOP_EVENT 事件，并在收到该事件后调用所有 Worker 线程池的 contextStopping() 方法，从而优雅地中断并清理空闲线程，避免ThreadLocal导致的内存泄漏问题。
​	可以先看看这篇线程池相关源码解析文章。ThreadPoolExecutor#contextStopping代码如下，核心就1件事：对空闲线程进行中断并退出（通过设置corePoolSize&#x3D;0来保证）
public void contextStopping() {
    // 非常重要：记录当前 Context 停止的时间，用于后续判断线程是否需要回收
    this.lastContextStoppedTime.set(System.currentTimeMillis());

    int savedCorePoolSize = this.getCorePoolSize();
    TaskQueue taskQueue = getQueue() instanceof TaskQueue ? (TaskQueue) getQueue() : null;
    if (taskQueue != null) {
        // 临时设置任务队列剩余容量为0
        // 但ThreadPoolExecutor#setCorePoolSize内部没发现哪里有检查queue.remainingCapacity() ==
        // 0的逻辑，可能是为了兼容其他逻辑吧（offer和poll）？？？
        taskQueue.setForcedRemainingCapacity(0);
    }

    // 将核心线程池设为0：内部会中断所有空闲线程并触发getTask()里的退出逻辑
    this.setCorePoolSize(0);

    // ======== 恢复线程池原始配置，避免影响http请求 ============

    if (taskQueue != null) {
        taskQueue.resetForcedRemainingCapacity();
    }
    this.setCorePoolSize(savedCorePoolSize);
}

TaskQueue​	单靠上述的 ThreadLocalLeakPreventionListener 并不足以关闭运行中的 worker 线程。为此，Tomcat 自定义了一个 TaskQueue 作为线程池的任务队列，并重写了几个关键方法，以精细控制 worker 线程的创建与回收策略。
​	这里重点关注其重写的 poll 和 take 方法 —— 它们是线程池中 worker 线程获取任务的主要途径。Tomcat 在此做了一个巧妙的设计：仅对需要被回收的线程（即线程创建时间早于当前 Context 的上次 stop 时间）应用 fallback 策略

take() 方法原本是阻塞式的，这里被 fallback 到poll()，即允许超时等待，从而避免永久阻塞
poll()若超时返回 null，则直接 fallback 到抛出异常，从而促使线程正常终止

public class TaskQueue extends LinkedBlockingQueue&lt;Runnable> {
    // ================= 重写的offer方法，调整线程的创建策略 ====================

    /**
     * 目的：尽量优先创建线程，而不是把任务直接塞进队列
     * 原因：Tomcat 设计希望在线程数未满时尽可能创建新线程，提高吞吐量。
     */
    @Override
    public boolean offer(Runnable o) {
        if (parent == null) {
            return super.offer(o);
        }
        // 如果线程池已达到最大线程数，那只能乖乖入队列
        if (parent.getPoolSize() == parent.getMaximumPoolSize()) {
            return super.offer(o);
        }
        // 还有空闲线程（已提交任务数 &lt;= 当前线程数），也入队
        if (parent.getSubmittedCount() &lt;= (parent.getPoolSize())) {
            return super.offer(o);
        }
        // 线程数没达到最大限制，并且提交的任务数已多余当前线程数（请求压力大）。则返回 false 触发线程池直接创建新建线程
        if (parent.getPoolSize() &lt; parent.getMaximumPoolSize()) {
            return false;
        }
        // 默认入队
        return super.offer(o);
    }

    // ================= 重写poll和take方法（仅对需要被终结的线程施加fallback策略，进而调整了线程的回收策略） =========================

    @Override
    public Runnable poll(long timeout, TimeUnit unit)
            throws InterruptedException {
        Runnable runnable = super.poll(timeout, unit);
        if (runnable == null &amp;&amp; parent != null) {
            // 内部会判断当前线程是否需要被终结，需要的话会抛出异常，最终终结当前线程
            parent.stopCurrentThreadIfNeeded();
        }
        // 只要有任务，还是直接返回，不影响活跃线程
        return runnable;
    }

    @Override
    public Runnable take() throws InterruptedException {
        if (parent != null &amp;&amp; parent.currentThreadShouldBeStopped()) {
            // fallback为poll方法，即允许超时
            return poll(parent.getKeepAliveTime(TimeUnit.MILLISECONDS),
                    TimeUnit.MILLISECONDS);
        }
        // 正常线程还是阻塞等待
        return super.take();
    }
}

总结​	ThreadLocalLeakPreventionListener 负责主动回收空闲的 worker 线程，而 TaskQueue 则通过重写 poll 和 take 方法，利用线程池的任务获取机制，实现对线程回收的兜底策略。两者配合，仅在 线程空闲时 才进行处理，不影响活跃线程的正常工作。通过这种机制，Tomcat 能够在热加载后安全且优雅的清理掉旧的所有worker 线程，从而避免因ThreadLocal残留导致的内存泄漏。
相关链接
ThreadLocal弱引用原因
线程池源码解析
Tomcat内存泄漏原文

]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>热加载</tag>
        <tag>内存泄漏</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-类加载器</title>
    <url>/2021-11-23/tomcat-lei-jia-zai-qi/</url>
    <content><![CDATA[
​	以问题切入，深入剖析了commonLoader与WebappClassLoader各自的定位与设计初衷，重点分析了WebappClassLoader如何在保证JVM核心类安全的前提下，部分打破双亲委派机制，实现Web应用之间的真正隔离。




​	以当前8.5.x版本为例，在具体分析之前，先想一个问题，带着这个问题再去思考为什么这么设计：

​	当我们把一个 Web 项目部署到 Tomcat 里后，项目里用到的各种 class 文件，Tomcat 到底是从哪些地方去加载它们的？以及为什么要用这些不同的类加载器去加载？

整体上可以简单归类为三部分来源：

Tomcat 自己的依赖（由commonLoader加载）：安装目录里lib目录下所有jar，这些都是 Tomcat 启动和运行时所需要的核心库。
Web 应用本身的依赖（由WebappClassLoader加载），以context为user举例。
webapps/user/WEB-INF/classes/：存放应用自身编译后的 class 文件
webapps/user/WEB-INF/lib/ ：存放应用所依赖的第三方 jar 包


JDK依赖（由 BootstrapClassLoader 加载）：比如 rt.jar（JDK 8 及以下）或 java.base（JDK 9 及以后），这些属于 JVM 层面的标准库，

​	Web 应用在运行时所依赖的 class，基本都来自于上述几个目录。而 Tomcat 为了支持不同context之间的隔离、避免类冲突、支持热部署等需求，专门设计了一套层级化的类加载器体系，来负责加载这些不同来源的 class。
commonLoaderconf&#x2F;catalina.properties相关配置common.loader="${catalina.base}/lib","${catalina.base}/lib/*.jar","${catalina.home}/lib","${catalina.home}/lib/*.jar"
server.loader=
shared.loader=

初始化代码调用路径为：Bootstrap#main -&gt; Bootstrap#start -&gt; Bootstrap#init -&gt; Bootstrap#initClassLoaders
默认的conf&#x2F;catalina.properties配置里server.loader和shared.loader都为空，所以catalinaLoader和sharedLoader都被赋值为了commonLoader

/**
 * 初始化三层类加载器：common、server（catalina）、shared
 */
private void initClassLoaders() {
    try {
        // commonLoader：公共类加载器，供 Tomcat 内部和所有 Web 应用共享
        // 默认搜索目录：
        //   ${catalina.base}/lib/
        //   ${catalina.base}/lib/*.jar
        //   ${catalina.home}/lib/
        //   ${catalina.home}/lib/*.jar
        //
        // 说明：
        //   - ${catalina.base}：运行时指定的工作目录，可以实现多实例共享一个 Tomcat 安装
        //   - ${catalina.home}：Tomcat 的安装目录
        //
        // 如果未在 catalina.properties 里配置 common.loader，则默认使用当前类的 ClassLoader
        commonLoader = createClassLoader("common", null);
        if (commonLoader == null) {
            commonLoader = this.getClass().getClassLoader();
        }
        // 默认为上面的commonLoader
        catalinaLoader = createClassLoader("server", commonLoader);
        // 默认为上面的commonLoader
        sharedLoader = createClassLoader("shared", commonLoader);
    } catch (Throwable t) {
        handleThrowable(t);
        log.error("Class loader creation threw exception", t);
        System.exit(1);
    }
}

private ClassLoader createClassLoader(String name, ClassLoader parent)
        throws Exception {
    // 从 catalina.properties 读取对应的 loader 配置
    String value = CatalinaProperties.getProperty(name + ".loader");
    // value为空，则使用parent
    if ((value == null) || (value.equals(""))) {
        return parent;
    }

    // value解析和占位符替换
    value = replace(value);

    List&lt;Repository> repositories = new ArrayList&lt;>();

    String[] repositoryPaths = getPaths(value);

    for (String repository : repositoryPaths) {
        try {
            @SuppressWarnings("unused")
            URL url = new URL(repository);
            repositories.add(new Repository(repository, RepositoryType.URL));
            continue;
        } catch (MalformedURLException e) {
            // Ignore
        }

        // Local repository
        if (repository.endsWith("*.jar")) {
            repository = repository.substring(0, repository.length() - "*.jar".length());
            repositories.add(new Repository(repository, RepositoryType.GLOB));
        } else if (repository.endsWith(".jar")) {
            repositories.add(new Repository(repository, RepositoryType.JAR));
        } else {
            repositories.add(new Repository(repository, RepositoryType.DIR));
        }
    }
    // 根据class所在的位置，创建一个URLClassLoader
    return ClassLoaderFactory.createClassLoader(repositories, parent);
}

classLoader引用设置
在Bootstrap#init()方法里，会将catalinaLoader绑定到当前线程的contextClassLoader里，同时，通过反射将sharedLoader设置到Catalina.parentClassLoader字段里

public void init() throws Exception {

    initClassLoaders();

    // 用catalinaLoader作为当前线程上下文的contextClassLoader，用于加载tomcat class
    Thread.currentThread().setContextClassLoader(catalinaLoader);

    SecurityClassLoad.securityClassLoad(catalinaLoader);

    Class&lt;?> startupClass = catalinaLoader.loadClass("org.apache.catalina.startup.Catalina");
    Object startupInstance = startupClass.getConstructor().newInstance();

  
    // 使用反射将sharedLoader设置到Catalina.parentClassLoader字段
    String methodName = "setParentClassLoader";
    Class&lt;?> paramTypes[] = new Class[1];
    paramTypes[0] = Class.forName("java.lang.ClassLoader");
    Object paramValues[] = new Object[1];
    paramValues[0] = sharedLoader;
    Method method =
        startupInstance.getClass().getMethod(methodName, paramTypes);
    method.invoke(startupInstance, paramValues);
}


在 Catalina 中创建用于解析 server.xml 的 Digester 时，涉及到类加载器的一些关键配置。这里仅整理与类加载器相关的部分逻辑

设置Digester.useContextClassLoader&#x3D;true

​	这一配置让 Digester 在解析 server.xml 并实例化各个 Tomcat 组件时，优先使用当前线程的 contextClassLoader（即 catalinaLoader，本质上就是 commonLoader）来加载类。这样可以确保 Tomcat 核心组件统一通过 common 层加载


设置 Engine 的 parentClassLoader

​	在实例化 Engine 时，会将其内部的 ContainerBase.parentClassLoader 设置为 sharedLoader（其实也是 commonLoader）。这一步非常关键，因为后续每个 WebappClassLoader 的父加载器就是从这里继承而来





protected Digester createStartDigester() {
    long t1=System.currentTimeMillis();
    // Initialize the digester
    Digester digester = new Digester();
    // 使用当前Thead的contextClassLoader加载指定的class
    digester.setUseContextClassLoader(true);
    // 将sharedLoader设置到Engine里的parentClassLoader字段
    digester.addRule("Server/Service/Engine",
                     new SetParentClassLoaderRule(parentClassLoader));
    return digester;

}

关键要点通过上诉的配置解析和设置，可总结出如下关键要点，对后续的WebappClassLoader分析有很大作用：

sharedLoader 和 catalinaLoader 基本都被废弃了，最终它们都被统一设置为了 commonLoader，即默认只使用 common 层的类加载器。
Tomcat 主线程的 contextClassLoader 被设置为了 catalinaLoader（也就是 commonLoader），主要用于加载 Tomcat 自身运行所需的类（即 lib 目录下的 jar 或 class 文件）。
StandardEngine 的 parentClassLoader 被设置为了 sharedLoader（实际上还是 commonLoader），用于作为后续每个 WebappClassLoader（即 web 应用类加载器）的父加载器

WebappClassLoader通过之前分析的文章，StandardContext#start会触发WebappLoader#start，需要注意的是，WebappLoader 本身并不是一个类加载器，而是通过实现 Loader 和 Lifecycle 接口，负责在各个生命周期阶段对真正的 WebappClassLoader 进行管理和控制。其创建真正的WebappClassLoader在WebappLoader#start阶段，核心如下
protected void startInternal() throws LifecycleException {
    try {

        // 创建真正的 Web 应用类加载器 WebappClassLoader
        classLoader = createClassLoader();
        classLoader.setResources(context.getResources());
        // 设置类加载委托模型，决定优先使用父加载器还是自身加载器（默认为false，即不优先使用父加载器加载class）
        classLoader.setDelegate(this.delegate);

        setClassPath();

        setPermissions();

        // 启动 WebappClassLoader（缓存/WEB-INF/classes和/WEB-INF/lib下的资源）
        ((Lifecycle) classLoader).start();

    } catch (Throwable t) {
        // ...省略
    }

    setState(LifecycleState.STARTING);
}

private WebappClassLoaderBase createClassLoader()
        throws Exception {

    // loader为org.apache.catalina.loader.ParallelWebappClassLoader
    Class&lt;?> clazz = Class.forName(loaderClass);
    WebappClassLoaderBase classLoader = null;

    if (parentClassLoader == null) {
        // 内部会递归向上查找，也就是最终会使用Engine内部的parentClassLoader，即sharedLoader
        parentClassLoader = context.getParentClassLoader();
    } else {
        context.setParentClassLoader(parentClassLoader);
    }
    // 使用反射将sharedLoader作为构造参数，实例化出ParallelWebappClassLoader加载器
    Class&lt;?>[] argTypes = { ClassLoader.class };
    Object[] args = { parentClassLoader };
    Constructor&lt;?> constr = clazz.getConstructor(argTypes);
    classLoader = (WebappClassLoaderBase) constr.newInstance(args);

    return classLoader;
}

ParallelWebappClassLoaderstart相关字段和方法如下，主要是将当前项目里的&#x2F;WEB-INF&#x2F;classes和&#x2F;WEB-INF&#x2F;lib目录下的class资源缓存到localRepositories（可以理解为classpath），以供后续来实际加载class

// 当前 Web 应用的本地 classpath 资源（/WEB-INF/classes 以及 /WEB-INF/lib 下的所有 jar）
private List&lt;URL> localRepositories = new ArrayList&lt;>();

/**
 * 生命周期的start方法，缓存class目录资源
 */
public void start() throws LifecycleException {

    state = LifecycleState.STARTING_PREP;

    // 1. 扫描 /WEB-INF/classes 目录，将其加入本地 classpath
    WebResource[] classesResources = resources.getResources("/WEB-INF/classes");
    for (WebResource classes : classesResources) {
        if (classes.isDirectory() &amp;&amp; classes.canRead()) {
            localRepositories.add(classes.getURL());
        }
    }
    // 2. 扫描 /WEB-INF/lib 目录下所有可读的 jar 包，将其加入本地 classpath，同时记录最后修改时间
    WebResource[] jars = resources.listResources("/WEB-INF/lib");
    for (WebResource jar : jars) {
        if (jar.getName().endsWith(".jar") &amp;&amp; jar.isFile() &amp;&amp; jar.canRead()) {
            localRepositories.add(jar.getURL());
            jarModificationTimes.put(jar.getName(), Long.valueOf(jar.getLastModified()));
        }
    }

    state = LifecycleState.STARTED;
}

loadClass核心字段和方法如下（已删除不重要的部分），通过如下源码可总结出loadClass的步骤：

缓存检查
先检查当前 WebappClassLoader 是否已加载过指定的类，如果已加载，直接返回已加载的类，避免重复加载


检查是否应尝试使用 JVM 内部类加载器（类似传统的类加载器加载方式）
若JVM内部类加载器能找到指定class资源，则由其加载指定的class


根据委派规则（delegateLoad）决定加载顺序，delegateLoad一般都为false（若为true则颠倒顺序）
先本地加载（当前 Web 应用内），尝试从&#x2F;WEB-INF&#x2F;classes、&#x2F;WEB-INF&#x2F;lib文件夹下加载指定class
否则交由父加载器（sharedLoader）兜底，即从tomcat的lib目录里的jar加载指定class


以上都没找到，则抛出ClassNotFoundException

public abstract class WebappClassLoaderBase extends URLClassLoader
        implements Lifecycle, InstrumentableClassLoader, WebappProperties, PermissionCheck {

    // 绑定的 Web 资源接口，实际提供 /WEB-INF/classes、/WEB-INF/lib 等资源访问能力
    protected WebResourceRoot resources = null;

    // 当前加载过的class的缓存(/WEB-INF/classes目录下)
    protected final Map&lt;String, ResourceEntry> resourceEntries = new ConcurrentHashMap&lt;>();

    // 是否强制委派给父类加载器优先加载。默认为false，表示优先当前类加载器先加载类
    protected boolean delegate = false;

    // /WEB-INF/lib 目录下jar包的修改时间（热加载使用）
    private final HashMap&lt;String, Long> jarModificationTimes = new HashMap&lt;>();

    // tomcat的sharedLoader（URLClassLoader）
    protected final ClassLoader parent;

    // 标识是否有外部 repository 被注册（即 localRepositories 是否有值）
    private boolean hasExternalRepositories = false;

    // 当前 Web 应用的本地 classpath 资源（/WEB-INF/classes 以及 /WEB-INF/lib 下的所有 jar）
    private List&lt;URL> localRepositories = new ArrayList&lt;>();

    /**
     * 把 webapp 的所有 classpath 资源（包括 /WEB-INF/classes 和 /WEB-INF/lib/*.jar）整理成 URL
     * 数组，
     * 供自己这个URLClassLoader实现去加载class。hasExternalRepositories也会被设置为true
     */
    @Override
    public URL[] getURLs() {
        ArrayList&lt;URL> result = new ArrayList&lt;>();
        result.addAll(localRepositories);
        result.addAll(Arrays.asList(super.getURLs()));
        return result.toArray(new URL[0]);
    }

    /**
     * 父类URLClassLoader的方法，配合getURLs()方法，设置hasExternalRepositories为true
     */
    @Override
    protected void addURL(URL url) {
        super.addURL(url);
        hasExternalRepositories = true;
    }

    public Class&lt;?> loadClass(String name, boolean resolve) throws ClassNotFoundException {

        synchronized (getClassLoadingLock(name)) {
            Class&lt;?> clazz = null;

            // 先检查 Web 应用是否已停止，防止在已停止的 webapp 中加载类
            checkStateForClassLoading(name);

            // 1、从缓存中resourceEntries查找当前类加载器是否已经加载了这个class
            clazz = findLoadedClass0(name);
            if (clazz != null) {
                if (resolve) {
                    resolveClass(clazz);
                }
                return clazz;
            }

            // 2、从当前类加载器的native中查找是否已经缓存过（范围比findLoadedClass0更大）
            clazz = findLoadedClass(name);
            if (clazz != null) {

                if (resolve) {
                    resolveClass(clazz);
                }
                return clazz;
            }

            // class名转换为路径。比如：site.shanzhao.Demo => /site/shanzhao/Demo.class
            String resourceName = binaryNameToPath(name, false);

            // 检查jvm的类加载器是否加载过当前class
            ClassLoader javaseLoader = getJavaseClassLoader();
            boolean tryLoadingFromJavaseLoader;
            try {

                URL url = javaseLoader.getResource(resourceName);
                tryLoadingFromJavaseLoader = (url != null);
            } catch (Throwable t) {
                tryLoadingFromJavaseLoader = true;
            }
            // 3. jvm类加载器加载过，直接从jvm类加载器获取这个Class
            if (tryLoadingFromJavaseLoader) {
                try {
                    clazz = javaseLoader.loadClass(name);
                    if (clazz != null) {
                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }

            // 强制委派父加载器加载 or 一些特定核心类 ：都先走父类加载器进行加载
            // 一般情况都应为false
            boolean delegateLoad = delegate || filter(name, true);

            // 4. 设置了delegate为true，则尝试使用父类加载器（默认即tomcat的common类加载器加载）
            if (delegateLoad) {

                try {
                    clazz = Class.forName(name, false, parent);
                    if (clazz != null) {

                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }

            // ================== 走到这，才开始尝试使用本类加载加载指定的class
            try {
                // 5. 开始使用当前类加载器加载（即 /WEB-INF/classes 与 /WEB-INF/lib）
                clazz = findClass(name);
                if (clazz != null) {
                    if (resolve) {
                        resolveClass(clazz);
                    }
                    return clazz;
                }
            } catch (ClassNotFoundException e) {
                // Ignore
            }

            if (!delegateLoad) {
                try {
                    // 6. delegateLoad为false，再使用父类加载器（为sharedLoader，默认也是commonLoader）尝试加载指定的class
                    clazz = Class.forName(name, false, parent);
                    if (clazz != null) {
                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }
        }

        throw new ClassNotFoundException(name);
    }

    /**
     * 从当前项目的/WEB-INF/classes 与 /WEB-INF/lib中加载指定class
     */
    public Class&lt;?> findClass(String name) throws ClassNotFoundException {
        Class&lt;?> clazz = null;
        try {
            try {
                // 1. 从/WEB-INF/classes文件夹下加载class(如果找到，还会缓存到resourceEntries字段里)
                clazz = findClassInternal(name);
            } catch (Exception e) {
                // ... 异常处理
            }
            if ((clazz == null) &amp;&amp; hasExternalRepositories) {
                try {
                    // 2. 利用父类URLClassLoader的功能，加载/WEB-INF/lib文件夹下jar里的class
                    clazz = super.findClass(name);
                } catch (Exception e) {
                    // ... 异常处理
                }
            }
            // =========== 到这说明/WEB-INF/classes 和/WEB-INF/lib 里都没找到指定的class，直接抛异常 =========
            if (clazz == null) {
                throw new ClassNotFoundException(name);
            }
        } catch (ClassNotFoundException e) {
            throw e;
        }
        return clazz;

    }
}

总结和思考
commonLoader存在的意义？

​	Tomcat 里其实只有一个 JVM，但可以部署多个 web 应用（多个 context）。这些应用共用 Tomcat 核心组件，比如：Server、Connector、Valve、Pipeline 等。这些 Tomcat 核心组件的 class 没必要每个应用都各自加载一份，只需 JVM 里统一加载一次就行。
​	commonLoader 就起这个作用，它其实就是一个 URLClassLoader，负责加载 $CATALINA_HOME/lib 目录下的 jar，把 Tomcat 自己的核心代码加载进来，供所有 Web 应用共享。


WebappClassLoader的意义？

​	这里就是隔离问题的核心：全限定类名是类加载器判定是否已加载的唯一依据。
​	假设有多个 web 应用，它们各自依赖了同一个类 site.shanzhao.Demo，但版本不同。如果 JVM 里只有一份类加载器，那只能加载一份，版本冲突就没法解决了。
​	所以 Tomcat 设计了 WebappClassLoader：每个 context 都有自己的类加载器，各自加载自己的 /WEB-INF/classes 和 /WEB-INF/lib 目录，互不影响。这样同一个类名的 class 文件可以在不同应用里加载出不同版本，实现真正的隔离。
​	另外，有独立的 WebappClassLoader 也方便支持应用的热部署和卸载：当某个 context 重新加载或被移除时，直接销毁这个 WebappClassLoader，连带其加载的所有 class、资源、线程都能一起回收，减少内存泄露风险。


为什么不使用jdk的AppClassLoader替换commonLoader？从表面看，AppClassLoader 和 Tomcat 自定义的 commonLoader 都继承自 URLClassLoader，两者在能力上类似，都可以加载来自指定 classpath 的类或资源。但 Tomcat 并没有使用 AppClassLoader 来加载自身核心组件，为什么呢？


AppClassLoader 的 classpath 是在 JVM 启动阶段静态确定的（通过系统属性：java.class.path）,而Tomcat 的类加载器的classpath支持占位符（如${catalina.base}和${catalina.home}），即允许用户扩展 classpath，更加灵活
Tomcat 在早期设计中区分了commonLoader，catalinaLoader和sharedLoader这三个类加载器用以实现模块隔离，AppClassLoader无法实现
WebappClassLoader 更不可能使用 AppClassLoader。单是启动时无法确定需要部署哪些Context以及各自classpath这条理由，就不可能用AppClassLoader，更别提Tomcat还支持了Web环境隔离和热加载这种高级特性了



哪个类加载器打破了双亲委派机制？

其实只有 WebappClassLoader 部分打破了双亲委派。
commonLoader、sharedLoader 本身都是标准的 URLClassLoader，没有动过 loadClass 逻辑，完全遵守双亲委派。
WebappClassLoader 才重写了 loadClass，实现了一个 可控双亲委派：

没完全打破：JVM 自带的类（JDK 标准库等）依然优先交给 JVM 自己的类加载器加载，保证不会被项目里的同名 class 覆盖，比如你项目里搞个自定义 java.lang.String，Tomcat 也不会用你这份
部分打破：对于非 JVM 内部类，WebappClassLoader 可以根据 delegate 参数决定是否优先本地加载，而不强行一律交给父加载器sharedLoader




]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-责任链之Pipeline+Valve和Filter</title>
    <url>/2021-11-02/tomcat-ze-ren-lian-zhi-pipeline-valve-he-filter/</url>
    <content><![CDATA[
​	分析了Tomcat中Pipeline+Valve和支持Filter的ApplicationFilterChain两种基于责任链模式的实现逻辑，并在最后总结了这两者的异同点以及为什么会有这两种类似的模块。




Pipeline​	可以理解为请求传递的管道，每个容器（Engine、Host、Context、Wrapper）都关联一个独立的 Pipeline（管道），用于处理 HTTP 请求的责任链式分发，其默认实现为 StandardPipeline
​	每个 Pipeline 内部由一系列 Valve（阀门）组成，Pipeline为其提供了一系列接口（包括添加，删除和管理其生命周期管理等），并将它们构造成链式结构（addValve方法将新 Valve 插入到链中 倒数第二个位置，即 basic Valve 之前）
​	请求到达某个容器时，会先被其 Pipeline 的第一个 Valve（first）处理，然后依次传递到后续的 Valve，最终到达 basic Valve。basic Valve 处理完成后，请求再被传递给下层子容器的 Pipeline，并最终传递到Filter中，从而达到请求贯穿全部容器的作用
核心字段和方法public class StandardPipeline extends LifecycleBase implements Pipeline {
    // basic valve（last valve），当前管道中最后处理的一个Valve
    protected Valve basic = null;

    // 关联的容器
    protected Container container = null;

    // value链首
    protected Valve first = null;

    public void addValve(Valve valve) {

        // 将容器也绑定搭到valve中
        if (valve instanceof Contained) {
            ((Contained) valve).setContainer(this.container);
        }

        // 如果当前 Pipeline 已处于运行状态，则启动Valve的生命周期start方法
        if (getState().isAvailable()) {
            if (valve instanceof Lifecycle) {
                try {
                    ((Lifecycle) valve).start();
                } catch (LifecycleException e) {
                    log.error(sm.getString("standardPipeline.valve.start"), e);
                }
            }
        }

        if (first == null) {
            first = valve;
            valve.setNext(basic);
        } else {
            // 将valve添加到Valve链中倒数第二个位置（最后一个位置为固定的basic）
            Valve current = first;
            while (current != null) {
                if (current.getNext() == basic) {
                    current.setNext(valve);
                    valve.setNext(basic);
                    break;
                }
                current = current.getNext();
            }
        }

        container.fireContainerEvent(Container.ADD_VALVE_EVENT, valve);
    }
}

Valve​	把http请求看作水流，Valve（阀门）即具有控制和预处理水流的作用。每个 Valve 通过其核心的 invoke 方法对请求 (Request) 和响应 (Response) 进行加工处理，并决定是否将请求继续传递给下一个 Valve。关键Valve如下
StandardEngineValve​	Engine中Pipeline里的最后一个阀门，主要是负责将请求传递给下一层容器Host的Pipeline中。源码较简单就不分析了
StandardHostValve​	不仅是 Host 容器中 Pipeline 的最后一个阀门，同时也负责将 WebappClassLoader 绑定到当前处理请求的 worker 线程上。 这样做可以保证：

 ​	在业务代码里通过 worker 线程间接创建的新对象、新类或新线程时，默认使用的都是当前 Context 下的 WebappClassLoader，从而确保整个 Web 应用内部始终使用一致的类加载器，避免类加载混乱问题。

public final void invoke(Request request, Response response)
        throws IOException, ServletException {

    // 获取当前请求对应的Web应用上下文
    Context context = request.getContext();
    if (context == null) {
        // 如果没有找到对应的Context，直接返回404
        if (!response.isError()) {
            response.sendError(404);
        }
        return;
    }

    try {
        // 1. 绑定Web应用的类加载器到当前worker线程
        // 将当前worker线程的上下文类加载器设置为WebappClassLoader，这样后续的类加载和创建新的线程就会使用这个WebappClassLoader
        context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);

        try {
            if (!response.isErrorReportRequired()) {
                // 2. 请求向后续容器传递
                context.getPipeline().getFirst().invoke(request, response);
            }
        } catch (Throwable t) {
            // 异常处理（忽略）
        }

    } finally {
        // 3. 恢复原来的类加载器
        // 将当前worker线程的上下文类加载器恢复为原来的值（commonClassLoader），确保其不会污染其他请求
        context.unbind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);
    }
}

StandardContextValve​	Context中Pipeline里的最后一个阀门，可以注意下对当前context的META-INF和WEB-INF目录访问的限制就是在这个Valve中做的。
public final void invoke(Request request, Response response)
        throws IOException, ServletException {

    // META-INF和WEB-INF目录下的资源不允许访问
    MessageBytes requestPathMB = request.getRequestPathMB();
    if ((requestPathMB.startsWithIgnoreCase("/META-INF/", 0))
            || (requestPathMB.equalsIgnoreCase("/META-INF"))
            || (requestPathMB.startsWithIgnoreCase("/WEB-INF/", 0))
            || (requestPathMB.equalsIgnoreCase("/WEB-INF"))) {
        response.sendError(HttpServletResponse.SC_NOT_FOUND);
        return;
    }
    // ...

    wrapper.getPipeline().getFirst().invoke(request, response);
}

StandardWrapperValve​	StandardWrapperValve值得重点分析，它是 Tomcat 容器中请求分发链路的最后一个核心 Valve，其职责是将请求最终交付给具体的 Servlet 实例。核心逻辑如下

分配Servlet（支持SingleThreadModel Servlet）
构建ApplicationFilterChain：基于当前请求的URL和对应的Servlet，筛选出所有匹配的 Filter实例
执行过滤器链ApplicationFilterChain.doFilter（内部会在所有Filter执行完毕后再执行Servlet#service方法）
资源回收和状态清理，并记录一些jmx的统计信息


final class StandardWrapperValve extends ValveBase {

    // ============== jmx统计使用（毫秒单位）===============
    // 当前servlet的总处理时间
    private volatile long processingTime;
    // 当前servlet一次处理的最大耗时时间
    private volatile long maxTime;
    // 当前servlet一次处理的最小耗时时间
    private volatile long minTime = Long.MAX_VALUE;
    // 请求总数
    private final AtomicInteger requestCount = new AtomicInteger(0);
    // 错误请求数
    private final AtomicInteger errorCount = new AtomicInteger(0);

    @Override
    public final void invoke(Request request, Response response)
        throws IOException, ServletException {

        boolean unavailable = false;
        Throwable throwable = null;
        long t1=System.currentTimeMillis();
        requestCount.incrementAndGet();
        StandardWrapper wrapper = (StandardWrapper) getContainer();
        Servlet servlet = null;
        Context context = (Context) wrapper.getParent();

        // 1. 分配servlet并初始化
        try {
            if (!unavailable) {
                servlet = wrapper.allocate();
            }
        }catch () {
            // ... 异常处理省略
        }

        // 2. 创建ApplicationFilterChain，并匹配合适的filter
        ApplicationFilterChain filterChain =
                ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);


        Container container = this.container;
        try {
            if ((servlet != null) &amp;&amp; (filterChain != null)) {
               // 3. 执行过滤器链
                filterChain.doFilter(request.getRequest(), response.getResponse());
            }
        } catch () {
            // ... 异常处理省略
        }finally {
            // =========== 4. 资源释放让其可在使用，减少垃圾收集器的活动 ================

            if (filterChain != null) {
                filterChain.release();
            }

            try {
                // servlet归还
                if (servlet != null) {
                    wrapper.deallocate(servlet);
                }
            } catch () {
                // ... 异常处理省略
            }

            try {
                if ((servlet != null) &amp;&amp;
                    (wrapper.getAvailable() == Long.MAX_VALUE)) {
                    wrapper.unload();
                }
            }  catch () {
                // ... 异常处理省略
            }
            long t2=System.currentTimeMillis();
            // 统计耗时，并更新相关数据
            long time=t2-t1;
            processingTime += time;
            if( time > maxTime) {
                maxTime=time;
            }
            if( time &lt; minTime) {
                minTime=time;
            }
        }
    }

}

FilterApplicationFilterChain​	过滤器链（FilterChain）用于管理多个过滤器（Filter）的执行顺序与截断逻辑，核心机制和 Spring AOP 中的切面调用逻辑类似：

​	每个请求对应一个独立的 FilterChain 实例，内部维护一个 pos 指针，在递归调用时通过传入当前 FilterChain 实例来控制指针的移动，从而实现 Filter 的顺序执行与截断控制。当所有 Filter 执行完毕（指针走到末尾）后，才会调用目标方法（FilterChain 中对应 Servlet#service()，Spring AOP 中则对应原始业务方法）；如果中间某个 Filter 没有继续调用 chain.doFilter()，则会直接返回，实现链路截断

​	整体实现其实就是典型的过滤器（增强器）模型，既能保证 Filter（切面） 之间的执行顺序，又支持灵活的拦截与提前返回。
public final class ApplicationFilterChain implements FilterChain {

    // 合适的Filter数组
    private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0];

    // 当前执行到的filter位置指针
    private int pos = 0;

    // filter的个数，&lt;= filters.lenght
    private int n = 0;
    private Servlet servlet = null;

    @Override
    public void doFilter(ServletRequest request, ServletResponse response)
            throws IOException, ServletException {

        internalDoFilter(request, response);
    }

    /**
     *  内部真正执行filter链逻辑
     */
    private void internalDoFilter(ServletRequest request,
            ServletResponse response)
            throws IOException, ServletException {

        // 依次调用下一个filter，直到filter链调用完毕
        if (pos &lt; n) {
            ApplicationFilterConfig filterConfig = filters[pos++];
            try {
                Filter filter = filterConfig.getFilter();
                // 将当前对象传入，以此触发递归调用
                filter.doFilter(request, response, this);
            } catch (){
                // ... 异常处理
            }
            // 若果某个Filter内部若未调用 chain.doFilter()，则会退回到这以终止链式调用，Servlet 不会被执行
            return;
        }

        // filter链调用完毕，最后再执行servlet的service方法
        try {
            servlet.service(request, response);
        } catch (){
            // ... 异常处理
        }finally {
            if (ApplicationDispatcher.WRAP_SAME_OBJECT) {
                lastServicedRequest.set(null);
                lastServicedResponse.set(null);
            }
        }
    }
}

对比总结​	Pipeline+Valve和Filter都是基于责任链模式实现的，看起来功能上高度重叠，甚至都能互相模拟对方的行为，那为什么Tomcat还要设计两套机制呢？核心其实一句话可以总结：职责分离，边界清晰

Pipeline + Valve是 Tomcat 内部容器模型的一部分，完全属于 Tomcat 自己的体系。每个容器都有自己的 Pipeline，也就有自己的 Valve 链，各自的Pipeline也只关心当前容器：


Host 层可以做虚拟主机级别的统一控制
Context 层可以做应用级别的资源隔离与控制
比方说其实在进入Pipiline之前的CoyoteAdapter里就解析出了当前url需要的Context容器，在这里就可以限制对web项目META-INF和WEB-INF目录的访问权限。但还是在Context的Valve里实现的，这是因为这些目录属于具体 web 项目，Tomcat定义了它们不允许被访问，所以它们的规则校验应当由 Tomcat的Context容器层编写


Wrapper 层可以做单个 Servlet 级别的调度和分配（缓存和回收）



而Filter则是标准 Servlet 规范定义的一部分，属于业务开发层面的能力扩展。比如用户鉴权、具体的web资源访问权限限制、业务日志埋点等需求都由业务催生，就完全不该在容器层面（Pipeline + Valve）中去处理


所以核心点：Pipeline + Valve 管容器架构，Filter 管业务，各司其职
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>责任链模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat-热加载和相关Class的垃圾回收探讨（一）</title>
    <url>/2021-12-11/tomcat-re-jia-zai-he-xiang-guan-class-de-la-ji-hui-shou-tan-tao-yi/</url>
    <content><![CDATA[
​	本文深入分析了 WebappClassLoader 的热加载整体流程，并对热加载过程中遗留的垃圾回收问题进行了系统性拆解。重点涵盖了：垃圾的分类、核心引用关系的梳理、各类资源的清理策略。最后详细解析了 Tomcat 如何通过兜底机制清理仍存活的线程，并结合实践给出了线程资源管理的最佳建议


热加载​	WebappLoader#backgroundProcess是负责检测和触发热加载的方法入口，其被standardEngine的backgroundThread线程周期性触发，被调用路径为：ContainerBackgroundProcessor#run -&gt; ContainerBackgroundProcessor#processChildren -&gt; StandardContext.backgroundProcess -&gt; Loader#backgroundProcess
​	当web可触发context的资源重加载时，backgroundThread线程会销毁（stop）当前context内部的所有资源，并进行重启context（start），start过程中使用了新的WebappClassLoader加载项目相关的class资源，因此可以在不重启整个 Tomcat 进程的前提下，以实现应用级别的热部署与资源更新
WebappLoader#backgroundProcesspublic void backgroundProcess() {
        // reloadable由StandardContext.reloadable设置，默认为false，也就表示需要在context.xml里主动配置reloadable=true才开启热加载检测资格
        if (reloadable &amp;&amp; modified()) { // Context里有class或jar改变了，需要进行热加载
            try {
                // 临时切换到Tomcat的commonLoader，避免使用即将被卸载的WebappClassLoader
                // 确保reload过程中使用的是稳定的类加载器环境
                Thread.currentThread().setContextClassLoader(WebappLoader.class.getClassLoader());
                if (context != null) {
                    context.reload();
                }
            } finally {
                if (context != null &amp;&amp; context.getLoader() != null) {
                    // 热加载完毕，将context里新的WebappClassLoader绑定到线程上下文中
                    Thread.currentThread().setContextClassLoader(context.getLoader().getClassLoader());
                }
            }
        }
    }

class资源变化监测WebappClassLoaderBase#modified() 负责监测当前 Web 应用中的 class 资源是否发生变更，用于触发 Context 重载。当以下任一变化发生时，Tomcat 会认为需要重新加载当前 Context：

&#x2F;WEB-INF&#x2F;classes 目录下已加载的 class 文件被修改
&#x2F;WEB-INF&#x2F;lib目录下的jar包有修改、新增和删除


public boolean modified() {

    // 1. 遍历所有已加载的 class 文件，判断是否有被修改
    for (Entry&lt;String, ResourceEntry> entry : resourceEntries.entrySet()) {
        long cachedLastModified = entry.getValue().lastModified;
        long lastModified = resources.getClassLoaderResource(
                entry.getKey()).getLastModified();
        if (lastModified != cachedLastModified) {
            // class 文件修改时间变化，说明 class 被更新，需要重载 Context
            return true;
        }
    }

    // 2. 遍历 /WEB-INF/lib 下的 jar 包，判断是否有变动
    WebResource[] jars = resources.listResources("/WEB-INF/lib");

    int jarCount = 0;
    for (WebResource jar : jars) {
        if (jar.getName().endsWith(".jar") &amp;&amp; jar.isFile() &amp;&amp; jar.canRead()) {
            jarCount++;
            Long recordedLastModified = jarModificationTimes.get(jar.getName());
            if (recordedLastModified == null) {
                // jar包没有记录上次修改时间，代表这个jar是新增的，也需要重载context
                return true;
            }
            if (recordedLastModified.longValue() != jar.getLastModified()) {
                // 时间变了，表示被修改过，也要重载context
                return true;
            }
        }
    }

    // 3. 检查是否有 jar 包被删除（jar 数量变少）
    if (jarCount &lt; jarModificationTimes.size()) {
        return true;
    }

    // 4. 无任何资源变化，则不需要重载Context
    return false;
}

context重加载Context 重加载的本质流程就是：先执行 stop()，再重新 start()。start流程可以看这里，stop则负责关闭和清理已有资源，避免内存泄露。我这里简要梳理 下stop() 过程中各核心组件的销毁逻辑：

子容器 Servlet (StandardWrapper#stop)
依次销毁所有已加载的 Servlet 实例，调用其 javax.servlet.Servlet#destroy() 方法，完成业务资源释放


Filter组件销毁
调用所有已注册的 javax.servlet.Filter#destroy() 方法，清理过滤器资源。


Session 管理器 (StandardManager#stop)
触发 Session 持久化（等待context重启后再加载进来），同时清理过期的 Session 实例


Listener组件销毁
执行所有注册的 javax.servlet.ServletContextListener#contextDestroyed() 方法，通知应用关闭，释放监听资源。


类加载器资源清理 (WebappLoader#stop)
销毁 WebappClassLoader，清理已加载的 class 缓存、jar 缓存、资源引用
停止并回收与类加载器相关的线程，断开对外部资源的强引用，避免内存泄漏



垃圾回收​	前面的都是铺垫，现在来探讨一个最重要的问题（当最终理解了这个问题后，任何java热加载工具如何垃圾回收探讨都不是难题）：

​	Tomcat 触发 Context 热加载后，系统中会产生哪些需要回收的垃圾？这些垃圾又该如何被回收？（如果回收不彻底，多次热加载最终可能引发 OOM 问题）

资源分类首先我们可以将需要回收的资源粗分为如下两大类
堆区堆区由GC自动回收，记住一点，这个区内的对象能被回收的唯一方法是对象不可达（软引用和弱引用这些具有特定回收限制的实例不再考虑范围内）

Context 内部的对象实例：比如Servlet、Filter、Session、Spring容器里的bean等等，这部分是最多的
线程相关对象：Context 内部自行启动的 Thread和线程池
Class 对象：由 WebappClassLoader 加载的所有 Class 实例
WebappClassLoader 实例本身

非堆区
元空间 (Metaspace) 中的 klass 元数据：回收依赖JVM的class卸载机制

回收探讨堆区垃圾回收的核心逻辑只有一点：对象是否可达（Reachable）。所以只要搞清楚对象的引用关系，就能推导出其回收条件。我们基于这个核心点，对上诉堆对内所有的对象进行追溯，看看到底它被哪些对象给持有
Context 内部的对象实例​	这部分是最简单的，这些对象都是应用程序中显示创建并赋值的对象。在context#stop期间，触发了各种内部组件的stop后，再对字段赋值为null就是在清除引用。Spring 容器则会在 ApplicationContext#close() 里统一销毁 Bean 并清理所有容器内引用。
线程相关对象​	Thread可作为GCRoot对象，所以对它的回收必须等Thread终结，否则任意一个存活的线程是不可能被回收的（其内部持有的contextClassLoader和其所有加载的class都不会被回收）
Class 对象​	Class对象稍复杂，它不仅有显示的引用（应用程序中显示使用），还有隐式的使用



引用链路
描述



A对象 → A.class
所有基于 A.class 创建的对象，其对象头中都隐式持有指向 A.class 的指针。


类加载器 → A.class
加载 A.class 的类加载器持有一份强引用。


其他显式引用
例如缓存、反射、Class.forName() 结果等都可能让其他对象显示持有 A.class 引用。


所以要回收Class对象，可以得出如下结论（以A.class为例）：

A.class创建的A对象都不可达，那么A对象头里的A.class指针也不可达
加载A.class的类加载器对象不可达
显示持有A.class的其他对象也不可达

WebappClassLoader 实例


引用链路
描述



所有其加载的 Class → WebappClassLoader
每个 Class 实例反向持有其加载器引用。


线程的 contextClassLoader → WebappClassLoader
活跃线程若未清理 contextClassLoader 也持有加载器引用。


WebappClassLoader回收前提：

所有由其加载的 Class 都已不可达
没有任何活跃线程仍在使用该类加载器作为 contextClassLoader
显示持有此类加载器的其他对象不可达

总结
class相关对象引用链

所以垃圾能别回收的本质，是让持有A.class和WebappClassLoader对象的链路断掉，在这里我们只要做好如下清理条件，相关垃圾即可被回收

context下创建的所有Thread需要终结
context内部强引用链全部断开（置为null）

tomcat释放资源​	在正式进入分析之前，先明确一点：子线程默认继承父线程的 contextClassLoader（Thread的构造方法）
​	通过前面文章的分析，可知在Context内部创建的线程都会使用Context的WebappClassLoadLoader作为其contextClassLoader，所以，只要线程的 Thread.contextClassLoader 是当前 Context 对应的 WebappClassLoader，就可以判断它属于当前 Context 内部创建的线程。
线程清理核心方法在WebappClassLoaderBase#clearReferencesThreads，调用链为：


WebappLoader#stop
WebappClassLoaderBase#stop
WebappClassLoaderBase#clearReferences 
WebappClassLoaderBase#clearReferencesThreads


逻辑总结：

获取当前JVM所有线程：通过遍历根 ThreadGroup进行所有线程的枚举
遍历并筛选出当前Context创建的线程：判断依据为Thread.contextClassLoader &#x3D;&#x3D; Context.WebappClassLoader
根据是否是线程池创建的线程来分开处理
线程池创建的Thread：使用线程池的shutdownNow来优雅的关闭线程
非线程池线程：先发送中断信号，若无法中断则再直接调用Thread.stop方法来强制终结线程



private void clearReferencesThreads() {
    // 获取系统内所有活动线程
    Thread[] threads = getThreads();
    List&lt;Thread> threadsToStop = new ArrayList&lt;>();

    for (Thread thread : threads) {
        if (thread != null) {
            ClassLoader ccl = thread.getContextClassLoader();
            // 只处理 contextClassLoader 是当前 WebappClassLoader 的线程
            if (ccl == this) {
                // 跳过当前线程自身，防止自杀
                if (thread == Thread.currentThread()) {
                    continue;
                }

                final String threadName = thread.getName();

                ThreadGroup tg = thread.getThreadGroup();
                if (tg != null &amp;&amp; JVM_THREAD_GROUP_NAMES.contains(tg.getName())) {
                    if (clearReferencesHttpClientKeepAliveThread &amp;&amp;
                            threadName.equals("Keep-Alive-Timer")) {
                        // Keep-Alive-Timer 特殊处理，仅替换其 contextClassLoader，避免泄露
                        thread.setContextClassLoader(parent);
                    }

                    // Don't warn about remaining JVM controlled threads
                    continue;
                }

                // // 已经死亡的线程，则不需要再清理了
                if (!thread.isAlive()) {
                    continue;
                }

                // TimerThread 可以被安全关闭
                if (thread.getClass().getName().startsWith("java.util.Timer") &amp;&amp;
                        clearReferencesStopTimerThreads) {
                    clearReferencesStopTimerThread(thread);
                    continue;
                }
                // 仅当配置允许强制停止线程时才处理（clearReferencesStopThreads默认为false）
                if (!clearReferencesStopThreads) {
                    continue;
                }

                // 尝试检测是否为 ThreadPoolExecutor 的 worker 线程，优先关闭线程池本身
                boolean usingExecutor = false;
                try {

                    // 兼容不同 JDK 实现，寻找包装的 runnable 字段
                    Object target = null;
                    for (String fieldName : new String[] { "target", "runnable", "action" }) {
                        try {
                            Field targetField = thread.getClass().getDeclaredField(fieldName);
                            targetField.setAccessible(true);
                            target = targetField.get(thread);
                            break;
                        } catch (NoSuchFieldException nfe) {
                            continue;
                        }
                    }

                    // 判断是否为 ThreadPoolExecutor.Worker，如果是则使用线程池的shutdownNow方法来优雅关闭线程
                    if (target != null &amp;&amp; target.getClass().getCanonicalName() != null &amp;&amp;
                            target.getClass().getCanonicalName().equals(
                                    "java.util.concurrent.ThreadPoolExecutor.Worker")) {
                        Field executorField = target.getClass().getDeclaredField("this$0");
                        executorField.setAccessible(true);
                        Object executor = executorField.get(target);
                        if (executor instanceof ThreadPoolExecutor) {
                            ((ThreadPoolExecutor) executor).shutdownNow();
                            usingExecutor = true;
                        }
                    }
                } catch (NoSuchFieldException | IllegalAccessException | RuntimeException e) {
                    log.warn(sm.getString("webappClassLoader.stopThreadFail",
                            thread.getName(), getContextName()), e);
                }

                // 非线程池线程，直接尝试 interrupt 终止
                if (!usingExecutor &amp;&amp; !thread.isInterrupted()) {
                    thread.interrupt();
                }

                // 记录仍需等待确认终止的线程
                threadsToStop.add(thread);
            }
        }
    }

    int count = 0;
    // 对需要stop的线程都直接终结
    for (Thread t : threadsToStop) {
        while (t.isAlive() &amp;&amp; count &lt; 100) {
            try {
                Thread.sleep(20);
            } catch (InterruptedException e) {
                // Quit the while loop
                break;
            }
            count++;
        }
        // 存活才终结
        if (t.isAlive()) {
            t.stop();
        }
    }
}

private Thread[] getThreads() {
    // 获取当前线程所在的线程组
    ThreadGroup tg = Thread.currentThread().getThreadGroup();
    // 向上遍历，找到根线程组（整个 JVM 的顶级线程组）
    try {
        while (tg.getParent() != null) {
            tg = tg.getParent();
        }
    } catch (SecurityException se) {

    }

    int threadCountGuess = tg.activeCount() + 50;
    Thread[] threads = new Thread[threadCountGuess];
    // 枚举所有的线程
    int threadCountActual = tg.enumerate(threads);
    // enumerate 方法在数组空间不足时会默默丢弃多余的线程，
    // 因此当实际数量等于猜测数量时，说明数组可能装不下，需要扩容重试
    while (threadCountActual == threadCountGuess) {
        threadCountGuess *= 2;
        threads = new Thread[threadCountGuess];
        // 继续枚举
        threadCountActual = tg.enumerate(threads);
    }

    return threads;
}

总结​	通过上述对 Context 内线程资源的兜底清理（这一部分其实是热加载内存泄漏中最核心、最容易被忽略的风险点 —— 因为实际项目中，大量使用了自定义线程或线程池，且它们往往没能纳入 Spring.ApplicationContext 的生命周期管理），再加上在 Context#stop 阶段，对各个强引用对象统一置 null，主动断开引用链，基本可以保证 Context 在热加载时不会产生内存泄漏问题。
最后需要特别强调一点：
​	项目中使用线程池时，强烈建议将其纳入 Context 生命周期统一管理（例如通过 Spring 的 ThreadPoolExecutorFactoryBean 来创建线程池）。
​	因为 Tomcat 在兜底清理时，如果无法识别线程归属，最终可能会直接调用 Thread.stop() 强行终止线程 —— 这种方式极其不安全，容易导致数据不一致等问题。让线程池受控于 Spring 容器，借助 shutdown() 或 shutdownNow() 做平滑关闭，是最稳妥、安全的方案。
]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>热加载</tag>
        <tag>内存泄漏</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈ThreadLocal为什么被设计为弱引用</title>
    <url>/2020-11-21/tan-tan-threadlocal-wei-shi-me-bei-she-ji-wei-ruo-yin-yong/</url>
    <content><![CDATA[
分析了ThreadLocal为什么要被设计为弱引用，并给出了ThreadLocal的建议使用方法




​	ThreadLocal在用作ThreadLocalMap的key时，是被设计为弱引用的。
​	ThreadLocalMap的内部类Entry被设计为实现了WeakReference，Entry用来存放数据。在构造Entry对象时，将传进来的ThreadLocal对象包装成了真正的弱引用对象，而Entry对象和内部的value对象本身是强引用的。
弱引用的解释：

​		只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。

​	简单理解就是当垃圾回收时，该对象只被WeakReference对象的弱引用字段（T reference）所引用，而未被任何强类型的对象引用，那么，该弱引用的对象就会被回收。
​	注意：WeakReference引用本身是强引用，它内部的（T reference）才是真正的弱引用字段，WeakReference就是一个装弱引用的容器而已。
1 回收测试示例public class ThreadLocalDemo {
    public static void main(String[] args) throws InterruptedException {
        firstStack();
        System.gc();
        TimeUnit.SECONDS.sleep(1);
        Thread thread = Thread.currentThread();
        System.out.println(thread); // 在这里打断点，观察thread对象里的ThreadLocalMap数据

    }
    // 通过是否获取返回值观察A对象里的local对象是否被回收
    private static A firstStack(){
        A a = new A();
        System.out.println("value: "+ a.get());
        return a;
    }
    private static class A{
        private ThreadLocal&lt;String> local = ThreadLocal.withInitial(() -> "in class A");

        public String get(){
            return local.get();
        }
        public void set(String str){
            local.set(str);
        }

    }
}


ThreadLocal 被强引用持有，不会被回收


ThreadLocal只被弱引用持有，gc后被回收了

​	如上面的代码，当构造一个A对象时，内部的local对象也构造了，之后调用get和set方法对local对象取值和设置值，当A对象不可达时，垃圾收集器就会回收A。
​	现在我们假设ThreadLocalMap的Entey里的key（ThreadLocal对象）不是弱引用的，且已经调用了A的对象的get或set方法，那么垃圾收集器回收A对象时，一定不会回收里面的local对象，为什么？

因为Entey已近持有了local对象的引用，我们没有设置引用类型，那这个引用就默认是个强引用。
Thread -&gt; ThreadLocal.ThreadLocalMap -&gt; Entry[] -&gt; Enrty -&gt; key（threadLocal对象）和value

​	引用链如上面所示，这个引用链全是强引用，当这个线程还未结束时，他持有的强引用，包括递归下去的所有强引用都不会被垃圾回收器回收。
​	那么回到正常情况，ThreadLocalMap里Entey的key是弱引用，在本例中也就是local对象在这里是弱引用，当对象A回收时，由于local对象只剩下被弱引用key所引用，所以local对象也会被回收。
2 重点来了，key为什么被设计为弱引用？？​	回归本质，ThreadLocalMap是用来存放对象的，在一次线程的执行栈中，存放数据后方便我们在任意的地方取得我们想要的值而不被其他线程干扰。ThreadLocalMap本身并没有为外界提供取出和存放数据的API，我们所能获得数据的方式只有通过ThreadLocal类提供的API来间接的从ThreadLocalMap取出数据，所以，当我们用不了key（ThreadLocal对象）的API也就无法从ThreadLocalMap里取出指定的数据。
​	在上面的例子中，A对象被回收了，这些get和set方法也访问不到了，也就没法从ThreadLocalMap里取出数据了。没法利用API取出数据，那这个Entry对象还有用吗？？所以最好的方法是在A对象被回收后，系统自动回收对应的Entry对象，但是让Entry对象或其中的value对象做为弱引用都是非常不合理的（这两个要是使用弱引用，都可能造成数据意外丢失）。所以，让key（threadLocal对象）为弱引用，自动被垃圾回收，key就变为null了，下次，我们就可以通过Entry不为null，而key为null来判断该Entry对象该被清理掉了。
​	至于ThreadLocalMap为什么不给外界提供API来操作数据，我觉得是因为这个Map对于一个线程只有一份，任何地方都在用，为了提供更方便的API和为了我们不破换其他框架保存到里面的数据（数据不被污染），所以才用ThreadLocal作为key和API来操作数据。
3 总结​	综上，Entry的key被设计为弱引用就是为了让程序自动的对访问不到的数据进行回收提醒。所以，在访问不到的数据被回收之前，内存泄漏确实是存在的，但是我们不用担心，就算我们不调用remove，ThreadLocalMap在内部的set，get和扩容时都会清理掉泄漏的Entry，内存泄漏完全没必要过于担心
所以，ThreadLocal的建议使用方法：

设计为static的，被class对象给强引用，线程存活期间就不会被GC。可根据实际情况来决定是否调用remove

非static的，放置在长对象（比如被spring管理的对象）的内部，也不会被GC。使用完后主动调用remove


​	个人也觉得没必要让创建的ThreadLocal对象生命周期过短，ThreadLocal被设计出来本身就是用来跨方法栈获取当前线程的数据或者无锁的获取线程安全的数据，空间交换了线程安全的上锁时间。只要让ThreadLocal具有线程的生命周期，就完全没必要使用remove方法，也完全不用担心内存泄漏的问题。
​	另外说一点，HashMap是使用拉链法解决hash冲突的，ThreadLocalMap是使用线性探测解决hash冲突的（内部只维护Entey数组，没有链表）。所以，源码中在清除泄漏的Entry时，会进行rehash，防止数组的当前位置为null后，有hash冲突的Entry访问不到的问题。
]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
</search>
