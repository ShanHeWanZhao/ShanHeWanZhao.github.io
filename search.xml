<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CMS</title>
    <url>/2020/09/19/cms/</url>
    <content><![CDATA[
​	主要分析了CMS收集器的算法实现和收集流程，和部分关键参数对CMS的影响，以及三色标记如何解决对象漏标问题。并在最后总结了CMS的优缺点


CMS​	CMS（Concurrent Mark-Sweep）是一种基于标记-清除算法实现的老年代垃圾回收器，以获取最短停顿时间为目标，适合对响应时间敏感的应用（如 Web 系统）。其核心思想是尽可能地让 GC 工作与用户线程并发执行，降低停顿时间。
​	一次CMS gc会算作两次full gc，分别为初始标记和最终标记（算上的时STW次数），但在多次收集后产生的空间碎片如果影响到了对象的分配，也会才用标记-整理算法收集一次
​	清除算法会产生空间碎片，如果cms区预留的空闲内存不能满足新对象的分配，那么会触发Concurrent Mode Failure，这时会冻结用户线程，临时启用Serial Old收集器重新回收老年代的垃圾，全程STW，耗时很长

初始标记(CMS initial mark): STW，仅标记GCRoots对象的下一个可达对象，很快
并发标记(CMS concurent mark)
重新标记(CMS remark): STW，解决并发标记时”那些消失的对象“
并发清除(CMS concurrent sweep)

1.参数
-XX:+UseConcMarkSweepGC   ： 启用CMS收集器（年轻代默认使用ParNew收集器）

–XX:CMSWaitDuration&#x3D;2000 ： cms后台线程的轮询间隔时间（ms单位)

-XX:+UseCMSInitiatingOccupancyOnly : 使用基于设定的阈值进行CMS gc，值为CMSInitiatingOccupancyFraction

-XX:CMSInitiatingOccupancyFraction&#x3D;80 : 在UseCMSInitiatingOccupancyOnly参数启用后生效。当CMS区（老年代）占比达到80%后，启用CMS垃圾回收。默认为-1，代表不启用，则老年代垃圾回收阈值算法为：**( (100 - MinHeapFreeRatio) + (CMSTriggerRatio * MinHeapFreeRatio) &#x2F; 100.0) &#x2F; 100.0** &#x3D; 92%

-XX:ConcGCThreads&#x3D;2 ：并发gc线程数，默认为（ParallelGCThreads+3）&#x2F; 4。ParallelGCThreads为新生代并行GC线程数，当CPU数量小于8时，ParallelGCThreads的值就是CPU的数量，当CPU数量大于8时，ParallelGCThreads的值等于3+5*cpuCount &#x2F; 8 （可用jstack查看）


2 三色标记2.1 含义


颜色
含义



白色
尚未被标记的对象，可能是垃圾


灰色
被标记为可达，但其内部引用的对象还没有全部扫描完


黑色
可达，且其所有引用的对象也都已经被标记（扫描完）


​	在三色标记开始时，所有对象初始状态都是白色。GC 从 GCRoots 出发，只能扫描到 GCRoots 可达的对象。每当扫描到一个新对象时，它会先被标记为灰色（表示已经被发现但尚未处理完）。当该对象的所有引用对象也都被扫描并标记后，它就会被染为黑色（表示处理完毕，不可回收）。
而对于那些不可达的对象，由于没有任何路径从 GCRoots 可以触达它们，因此它们不会被扫描，颜色保持为白色，最终被识别为垃圾对象。
因此，在三色标记结束时，只会存在黑色和白色两类对象：

黑色对象：可达、已完全处理，不能被回收
白色对象：不可达、未被处理，将被回收

2.2 问题
浮动垃圾：被标记为黑色的对象还会继续存活。但如果我们的用户线程此时对黑色对象丢弃引用，这个黑色对象就不可达了，就应该在本次垃圾清理中被回收。但这个影响不大，下次GC可进行处理
对象漏标：在并发标记阶段，应用线程可能会修改对象引用关系，导致本应可达的对象未被正确扫描，仍然保持白色，最终被误回收。有如下两种情况
对黑色对象A（此时A已完全扫描完毕）内部赋值一个白色对象B。B产生了漏标
对灰色对象C（此时C内部还未扫描完）内部暂时断开了一个对象D使其变为白色，并在扫描完成后重新将D赋值到C中



2.3 增量更新（Incremental Update）顾名思义，表示增加了引用。增量更新关注的是引用新增的情况，尤其是解决以下对象漏标场景：

黑色对象 A 在并发标记后，新增引用了一个未被标记的白色对象 B。	

在这种情况下，为了避免漏标，写屏障机制会将 A 重新标记为灰色，使其在“重新标记（Remark）”阶段重新被扫描一次，从而发现并标记 B，确保其不会被错误回收。总结就是黑色对象A一旦新插入了白色对象B的引用之后，A就变回灰色对象了。
​	CMS 使用增量更新策略，因为它是老年代回收器，老年代中的对象多数是长寿命的，结构稳定，引用新增比引用删除更常见。但增量更新只能处理“新增引用”，无法处理“引用删除”导致的漏标，因此并不完美。这也是 CMS 在 JDK9 被标记为过时的重要原因之一。
2.4 原始快照（Snapshot-At-The-Beginning，SATB）​	保存一份并发标记开始时的引用快照，当后续并发标记过程中对这些引用删除时，都会被记录到SATB缓冲区，标记结束后SATB缓冲区的对象被重新标记为存活。
​	原始快照只处理对灰色对象C删除白色对象D的情况（将D记录到SATB缓冲区），重新标记阶段会在将D标为活跃。但不处理黑色新增引用，需要依赖其他机制保证（一般都是依赖写屏障，将B直接标为存活）
​	G1使用原始快照能完全避免对象漏标，因为它就是用写屏障直接标记白色对象为存活的方式来处理给黑色对象新增的白色对象这种漏标情况。即SATB处理删除，写屏障兜底新增。虽不可避免的会增加浮动垃圾，但肯定不会漏标
3 cms gc触发条件
原文
foreground collector  ：空间分配不够触发
background collector
显式调用 System.gc()，且配置了 -XX:+ExplicitGCInvokesConcurrent
未配置 UseCMSInitiatingOccupancyOnly 时，JVM 会根据运行统计数据动态判断
OldGen 达到某个使用阈值（静态或动态计算）
Young GC 失败或预计失败，JVM 触发 CMS 作为悲观策略
元空间（Metaspace）扩容触发，且 CMSClassUnloadingEnabled=true（默认开启）



4 总结
CMS 是一种低停顿老年代收集器，适合延迟敏感型系统。
优点是并发执行、停顿低，缺点如下
空间碎片严重
需要预留足够空间，否则触发Concurrent Mode Failure 会退化为Serial GC，非常耗时
只用了增量更新，没有完全解决漏标
会产生浮动垃圾


推荐配合 CMSInitiatingOccupancyFraction 与 UseCMSInitiatingOccupancyOnly 控制触发阈值，防止内存不足时被动触发 Full GC。

]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>CMS</tag>
        <tag>三色标记</tag>
      </tags>
  </entry>
  <entry>
    <title>G1</title>
    <url>/2020/11/25/g1/</url>
    <content><![CDATA[
​	简单总结了G1和其常用参数，并分析了的G1日志


G1​	G1（Garbage First）是 JDK 7 引入，并在 JDK 9 默认启用的服务端垃圾回收器。它的核心理念是将整个 Java 堆划分为多个大小相等的 Region，打破了传统“新生代 &#x2F; 老年代”的物理分区模式，转而以 Region 为基本单位进行垃圾管理与回收。	

整堆收集：G1 是一个真正的 整堆并行压缩收集器，新生代和老年代都可以并行回收。
并发标记：采用 三色标记法 + SATB + 写屏障机制，保证并发标记期间的准确性。
可预测的停顿时间：用户可设置 -XX:MaxGCPauseMillis 控制最大停顿时间，G1 会在这个目标下选择哪些 Region 进入回收集（CSet）。

常用参数设置
-XX:+UseG1GC
-XX:G1HeapRegionSize&#x3D;2M：一个Region的大小
-XX:MaxGCPauseMillis&#x3D;80：允许收集停顿的最大时常（毫秒）
-XX:InitiatingHeapOccupancyPercent&#x3D;45 ：老年代占用到 45% 时触发并发标记周期（默认45）
不要再设置-xmn和-XX:NewRatio

Region划分
整个堆被分成多个 Region（默认 2048 个），每个 Region 的大小为 1MB ~ 32MB，并且必须是 2 的幂次方。
每个 Region 会被动态标记为不同用途：
E：Eden 区（新生代分配对象）
S：Survivor 区（新生代存活对象）
O：Old 区（长生命周期对象）
H：Humongous 区（大对象，直接分配在老年代）



​	大对象（如数组、长字符串等）若超过一个 Region 一半大小，会被当作 Humongous 对象，分配连续的多个 Region。由于这些对象移动成本高，G1 默认不会移动 Humongous 对象，而是直接将它们标记为老年代区域。
Remembered Set（RSet）​	由于 G1 会独立地对某些 Region 进行回收，它必须知道老年代是否引用了某个新生代对象。这正是 Remembered Set（记忆集） 的作用：

每个 Region 都维护了一个对应的 RSet，记录有哪些其它 Region 的对象引用了自己。
在回收某个 Region 时，G1 只需要扫描这个 RSet，而不必全堆扫描，大幅降低了跨代引用处理的成本。


简单说：RSet 让分区式回收变得可能而高效。

Card Table（卡表）RSet 的实现依赖于 Card Table + 写屏障：

Java 堆被进一步划分为更小的单位：Card，默认每个 Card 是 512 字节。
JVM 在写引用字段时会触发 写屏障（Write Barrier），将对应 Card 标记为 dirty，并记录引用变更。
在 GC 时，这些 dirty Card 会被用于更新 RSet，确保引用信息完整。


卡表是写屏障的基础，RSet 是分区引用追踪的核心，三者协同构成 G1 的并发收集体系。

日志解析2020-11-23T11:40:46.167+0800: 1.503: [GC pause (G1 Evacuation Pause) (young), 0.0048336 secs]
   // 下面的Min,Avg,Max,Diff,Sum分别表示GC线程最小启动或耗时时间（后面的也是），平均，最大，最大差值，和总耗时，单位都为ms
   [Parallel Time: 3.1 ms, GC Workers: 6] // 本次YGC共6个GC线程，总耗时3.1ms
      [GC Worker Start (ms): Min: 1503.0, Avg: 1504.5, Max: 1506.1, Diff: 3.0] // 本次GC线程启动（相对于JVM的启动）
      [Ext Root Scanning (ms): Min: 0.0, Avg: 0.2, Max: 0.7, Diff: 0.7, Sum: 1.1] // 本次GC线程的GC Roots扫描时间
      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] // 更新Remember Sets 的耗时统计信息（记忆集一般使用来解决跨Region的引用）
         [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0]
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] // 每个Region都会有一个RSet，RSet又包含指向这个Region的Cards引用，这个阶段就是扫描RSet中的Cards，从而分辨出Eden哪些对象被老年代引用，从而这些不会被GC
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.2, Diff: 0.2, Sum: 0.2] // 扫描代码中的root节点（局部变量）
      [Object Copy (ms): Min: 0.0, Avg: 1.3, Max: 2.7, Diff: 2.7, Sum: 7.6] // 对象copy，将存活的对象copy到目标Region中
      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]
         [Termination Attempts: Min: 1, Avg: 1.2, Max: 2, Diff: 1, Sum: 7]
      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.2] // GC线程完成其他任务的时间
      [GC Worker Total (ms): Min: 0.0, Avg: 1.6, Max: 3.1, Diff: 3.1, Sum: 9.4] // GC线程整个生命周期总计消耗时间
      [GC Worker End (ms): Min: 1506.1, Avg: 1506.1, Max: 1506.1, Diff: 0.0] // GC线程完成任务的停止时间（相对于JVM）
   [Code Root Fixup: 0.0 ms]
   [Code Root Purge: 0.0 ms]
   [Clear CT: 0.1 ms] // 清理Card Table（卡表）
   [Other: 1.6 ms]
      [Choose CSet: 0.0 ms] // 选择要回收的Region放入CSet（会根据停顿时间来决定）
      [Ref Proc: 1.4 ms] // 处理引用对象耗时时间（Weak、Soft、Phantom、JNI等等）
      [Ref Enq: 0.0 ms] // 遍历所有引用，将不能回收的放入pending列表
      [Redirty Cards: 0.0 ms] // 重置card为dirty
      // 大型对象的回收
      [Humongous Register: 0.0 ms] 
      [Humongous Reclaim: 0.0 ms]
      [Free CSet: 0.0 ms] // 释放CSet中Region占用的内存空间所耗时间
   [Eden: 51.0M(51.0M)->0.0B(46.0M) Survivors: 0.0B->5120.0K Heap: 51.0M(1024.0M)->4815.7K(1024.0M)]
 [Times: user=0.05 sys=0.00, real=0.01 secs] 

总结
G1 不再物理区分年轻代和老年代，转而统一使用多个 Region 管理整个堆。

支持 并发标记 + 并发回收 + 可预测停顿，是整堆压缩收集器。

使用 Remembered Set + Card Table + 写屏障 高效维护跨代引用关系。

避免 Full GC 的目标是：通过周期性并发标记、预测性选择 CSet 来进行碎片整理。


]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>G1</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM参数</title>
    <url>/2020/12/18/jvm-can-shu/</url>
    <content><![CDATA[JVM常用参数整理和垃圾收集器组合
 

JVM参数和垃圾收集器组合jvm参数整理
-Xms64m ：初始堆大小
-Xmx128m ：最大堆大小
-Xmn32m ：年轻代大小
-XX:MaxNewSize&#x3D;256m : 最大新生代大小
-Xss512k：栈大小
-XX:MetaspaceSize&#x3D;256M ：Metaspace扩容时触发FullGC的初始化阈值(并不是元空间的初始化大小，元空间是不断扩容的，当达到这个值时，就会触发full gc，链接）
-XX:MaxMetaspaceSize&#x3D;512M：Metaspace最大大小
-XX:NewRatio&#x3D;2：老年代和新生代的比例
-XX:SurvivorRatio&#x3D;8 ：Eden区与一个Survivor区的大小比值（所以s0:s1:eden&#x3D;1:1:8）
-XX:MinHeapFreeRatio&#x3D;40：空闲堆空间的最小百分比。如果空闲堆空间的比例小于它，则会进行堆扩容
-XX:MaxHeapFreeRatio&#x3D;70：空闲堆空间的最大百分比。如果空闲堆空间的比例大于它，则会进行堆缩容
-XX:-DisableExplicitGC：禁止显式GC，即禁止程序中System.gc()。个人感觉没必要
-XX:+HeapDumpOnOutOfMemoryError：OOM时导出堆快照到文件
-XX:HeapDumpPath&#x3D;&#x2F;home&#x2F;huskie&#x2F;gc&#x2F;oom.hprof：OOM时导出文件路径
-Xloggc:&#x2F;home&#x2F;ruidong&#x2F;gc.log   存储gc日志的路径
-XX:OnOutOfMemoryError：OOM时操作，比如如执行脚本发送邮件
-XX:+TraceClassLoading：打印加载类的详细信息
-XX:+PrintGCDetails：打印GC详细信息
-XX:+PrintGCTimeStamps：打印CG发生的时间戳（相对于项目启动时间）
-XX:+PrintGCDateStamps：打印GC发生的时间
-XX:+PrintHeapAtGC：每一次GC前和GC后，都打印堆信息
-XX:+PrintClassHistogram：按下Ctrl+Break后，打印类的信息
-XX:+PrintGCApplicationConcurrentTime ：打印应用程序的运行时间（许多事情会导致JVM暂停所有线程，停在安全点。gc也只是其中的一种，当暂停之后在重启应用线程，则会刷新这个时间（归0），在重新计数）链接
-XX:+PrintGCApplicationStoppedTime ：打印应用线程暂停的时间，显示应用线程被暂停了多久和应用线程暂停到安全点花费的时间
-XX:TargetSurvivorRatio&#x3D;50 ：survivor空间的晋升大小空间百分比（默认为50）
-XX:MaxTenuringThreshold&#x3D;15  ：年轻代晋升到老年代的最大年龄阈值(tenuring threshold)。默认值为 15[每次GC，增加1岁，到15岁如果还要存活，放入Old区]。jvm还会动态的计算晋升阈值，方法：依次从年龄为1的对象大小加起来，一直加到大小超过了 [（TargetSurvivorRatio * survivor_capacity）&#x2F; 100 ]值，这时加起来的最大年龄大小即为这次晋升的临界阈值（具体算法在：hotspot\src\share\vm\gc_implementation\shared\ageTable.cpp文件里，方法为compute_tenuring_threshold）
-XX:+PrintTenuringDistribution ：ygc 时打印当前晋升年龄信息

垃圾收集器新生代Serial（hotspot虚拟机在客户端下的默认新生代垃圾收集器）单线程新生代收集器，复制算法，整个过程STW
优势：内存消耗最小
缺点：不适合大内存多处理器工作，慢
ParNew多线程并行的新生代收集器，复制算法，整个过程STW

-XX:ParallelGCThreads&#x3D;4 ：并行收集的线程数

Parallel Scavenge
吞吐量 &#x3D; 运行用户代码时间 &#x2F; ( 运行用户代码时间 + 垃圾收集时间 )

吞吐量优先的新生代并行多线程收集器，复制算法（标记-复制算法）
三个重要参数：

XX:MaxGCPauseMillis ：垃圾收集最大停顿时间，大于0的毫秒数
-XX:GCTimeRatio: 大于0小于100的整数（运行用户代码时间比上垃圾回收的时间），默认为99，即允许最大1%的垃圾回收时间
-XX:+UseAdaptiveSizePolicy：开启垃圾收集器的自适应调节策略。虚拟机动态调整新生代，Eden区，Survivor区的比例和晋升大小

老年代CMS标记-清除算法的老年代收集器
Serial OldSerial的老年代会收集，标记-整理算法
Parallel Scavenge OldParallel Scavenge收集器的老年代版本，标记-整理算法
整堆G1（garbage-frist收集器）垃圾收集器组合
Serial + SerialOld
Serial + CMS (jdk8声明废弃，jdk9已被取消)
ParNew +CMS （使用CMS收集器的默认组合)
ParNew + SerialOld (jdk8声明废弃，jdk9已被取消)
Parallel Scavenge +  SerialOld
Parallel Scavenge + Parallel Scavenge Old（jdk8的默认组合）G1（jdk9的默认收集器，且CMS被标记为废弃了）

tips
java -XX:+PrintFlagsFinal -version  ：查看jvm默认参数。数据太多可配合grep使用

GCRoots对象
虚拟机栈(栈帧中的本地变量表)中引用的对象
本地方法栈(Native 方法)中引用的对象
方法区中类静态属性引用的对象
方法区中常量引用的对象
所有被同步锁持有的对象

]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>JVM参数</tag>
      </tags>
  </entry>
  <entry>
    <title>CloudFlare-CDN缓存清除</title>
    <url>/2024/06/14/cloudflare-cdn-huan-cun-qing-chu/</url>
    <content><![CDATA[
​	给出了一些api用于清除Cloudflare的CDN缓存方式
 

CloudFlare-CDN缓存清除​		搭建个人博客网站时，域名托管到CF，会使用CF的CDN。当你重新修改博客网站的样式css和js文件等再重新部署，一般都不会立马生效，因为CDN里的缓存还在，前端访问用的还是旧css和js文件。这时我们需要主动清除CDN的缓存，来让缓存重新加载，以便让我们修改的样式在网站立马生效
1 purgeUrl
2 使用ApiKey清除（不推荐）
ZONE_ID：区域id，即你在CF上托管的根域名id
EMAIL：你的邮箱
API_KEY：可自建apiKey，也可使用CF默认有的GlobalApiKey（个人资料 -&gt; API令牌 -&gt; API密钥 -&gt; Global API Key）

2.1 全部清除curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "X-Auth-Email: $EMAIL" \
    -H "X-Auth-Key: $API_KEY" \
    -d '{"purge_everything": true}'

2.2 批量清除具体文件一次性调用有文件数量限制： Free&#x2F;Pro&#x2F;Business一次上限30个，Enterprise一次上限500个
curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "X-Auth-Email: $EMAIL" \
    -H "X-Auth-Key: $API_KEY" \
    -d '{
    "files": [
        "https://blog.shanzhao.site/css/my.css",
        "https://blog.shanzhao.site/libs/others/snow.js"
    ]
}'

3 自定义token清除（推荐）自定义token不仅可以最小化的控制权限，也可以设置token的有效时常。使用如下方式创建一个专用于清理指定根域名的token

3.1 验证token是否生效curl -X GET "https://api.cloudflare.com/client/v4/user/tokens/verify" \
     -H "Authorization: Bearer $API_TOKEN" \
     -H "Content-Type:application/json"

3.2 全部清除curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "Authorization: Bearer $API_TOKEN" \
    -d '{"purge_everything": true}'

3.3 批量清除具体文件一次性调用有文件数量限制： Free&#x2F;Pro&#x2F;Business一次上限30个，Enterprise一次上限500个
curl https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache \
    -H 'Content-Type: application/json' \
    -H "Authorization: Bearer $API_TOKEN" \
    -d '{
    "files": [
        "https://blog.shanzhao.site/css/my.css",
        "https://blog.shanzhao.site/libs/others/snow.js"
    ]
}'

4 其他还有其他的参数，比如tags，hosts，prefixes，但这些都是企业版的用户才能使用，这里就不写了
5 参考链接
官方清除缓存文档
cloudflare dashboard创建token和查看ApiKey
ZoneId获取

]]></content>
      <categories>
        <category>cloudflare</category>
      </categories>
      <tags>
        <tag>cdn缓存清除</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-Future</title>
    <url>/2020/05/09/java-yuan-ma-pian-future/</url>
    <content><![CDATA[
​	jdk中Future接口实现类相关源码解析。包括FutureTask和 ScheduledFutureTask
 

1 FutureFuture接口表示一个异步操作的结果，即未来的结果，同时实现了 Runnable 和 Future 接口。提供了如下的一些基础方法可获取、判断和取消等操作

get()：阻塞直到计算完成并返回结果（支持超时设置）

isDone()：非阻塞检查任务是否完成（成功&#x2F;失败&#x2F;取消）

cancel(boolean mayInterruptIfRunning)：尝试取消任务，参数决定是否中断执行中的线程

isCancelled()：判断任务是否被取消


其实现类为FutureTask，就是用它来实现Callable接口的功能

1.1 FutureTask1.1.1 重点字段和方法public class FutureTask&lt;V> implements RunnableFuture&lt;V> {
    // state字段，表示了当前Future的状态，取值为如下字段
    private volatile int state;

    private static final int NEW          = 0; // 初始状态，新建
    private static final int COMPLETING   = 1; // 正在结束
    private static final int NORMAL       = 2; // 正常执行完毕
    private static final int EXCEPTIONAL  = 3; // 异常执行完毕
    private static final int CANCELLED    = 4; // 前一个状态必须是NEW，已取消（未中断）
    private static final int INTERRUPTING = 5; // 前一个状态必须是NEW，正在中断（中断）
    private static final int INTERRUPTED  = 6; // 取消成功的才可以设置，中断完成（中断）

    // 待运行的Callable任务
    private Callable&lt;V> callable;
    // Callable执行的结果。如果出现执行的过程中异常，则保存的是异常对象
    private Object outcome;
    // 运行Callable#call方法的线程（也即是运行业务代码的线程）
    private volatile Thread runner;
    // 当这里面的Callable还未执行完，却有其他线程调用Future#get()方法，
    // 	会将其他线程阻塞并构造为等待节点，维持一个链表结构，以便在Callable执行完毕后唤醒并回调
    private volatile WaitNode waiters;


    public void run() {
        if (state != NEW ||
            !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                         null, Thread.currentThread()))
            return;
        try {
            Callable&lt;V> c = callable;
            if (c != null &amp;&amp; state == NEW) {
                V result;
                boolean ran;
                try {
                    // 执行业务方法
                    result = c.call();
                    ran = true;
                } catch (Throwable ex) {
                    result = null;
                    ran = false;
                    setException(ex); // 异常结束，将状态设为EXCEPTIONAL，如果等待队列有节点，则唤醒对应的线程
                }
                if (ran)
                    set(result); // 正常结束，将状态设为NORMAL，如果等待队列有节点，则唤醒对应的线程
            }
        } finally {
            runner = null;
            int s = state;
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
    }
    // 阻塞获取
    public V get() throws InterruptedException, ExecutionException {
        int s = state;
        if (s &lt;= COMPLETING) // 还未完全结束Callabke，进入等待
            s = awaitDone(false, 0L);
        return report(s);
    }
    // 根据state判断是否需要阻塞并做对于的事
    private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
        final long deadline = timed ? System.nanoTime() + nanos : 0L;
        WaitNode q = null;
        boolean queued = false;
        for (;;) {
            if (Thread.interrupted()) { // 当前线程支持响应中断
                removeWaiter(q);
                throw new InterruptedException();
            }

            int s = state;
            if (s > COMPLETING) { // Callable运行完毕，且result已经设置完毕
                if (q != null)
                    q.thread = null;
                return s;
            }
            // 进入到以下分支，就代表Callable还未完全执行完毕

            else if (s == COMPLETING) // cannot time out yet  Callable运行完毕，但正在设置result，让出执行时间，等待下次判断
                Thread.yield();
            else if (q == null) // 第一次循环，构造等待节点
                q = new WaitNode();
            else if (!queued) // 还未加入等待队列，则将节点加入到等待队列中
                queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                                     q.next = waiters, q);
            else if (timed) { // 是否运行超时判断
                nanos = deadline - System.nanoTime();
                if (nanos &lt;= 0L) {
                    removeWaiter(q);
                    return state;
                }
                LockSupport.parkNanos(this, nanos);
            }
            else // 暂停当前线程，等待任务执行完毕的唤醒
                LockSupport.park(this);
        }
    }
    // 任务执行完毕，唤醒等待队列的所有节点
    private void finishCompletion() {
        // assert state > COMPLETING;
        for (WaitNode q; (q = waiters) != null;) {
            if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {
                for (;;) {
                    Thread t = q.thread;
                    if (t != null) {
                        q.thread = null;
                        LockSupport.unpark(t);
                    }
                    WaitNode next = q.next;
                    if (next == null)
                        break;
                    q.next = null; // unlink to help gc
                    q = next;
                }
                break;
            }
        }

        done();

        callable = null;        // to reduce footprint
    }
}

1.1.2 总结
FutureTask根据内部的state字段来判断当前任务运行到了哪个阶段并作出对于的抉择，也使用volatile修饰保证它在多线程环境下的可见性。
state状态流转：
NEW→COMPLETING→NORMAL（成功）
NEW→COMPLETING→EXCEPTIONAL（失败）
NEW→CANCELLED&#x2F;INTERRUPTED（取消）




如果想获取任务执行的结果，要使用get来获取结果，get是个阻塞的方法。当任务还未执行完毕时，会将调用get的方法阻塞并构造成WaitNode，再通过内部的next字段链接下一个WaitNode，形成一个链表结构。当任务执行完毕后，内部调用的finishCompletion方法会判断等待链表是否为空，不为空就代表有线程在获取结果时被阻塞了，这时唤醒阻塞队列的所有线程，最终，调用get方法的线程返回结果。即使用 WaitNode 链表 + CAS 操作管理阻塞线程，避免显式锁开销
只会允许任务执行一次，状态不可逆转

1.2 ScheduledFutureTask​	ScheduledFutureTask继承了FutureTask，当向定时任务线程池投递任务时（Runnable或Callable），都会将其封装为ScheduledFutureTask
1.2.1 重点字段和方法 private class ScheduledFutureTask&lt;V>
            extends FutureTask&lt;V> implements RunnableScheduledFuture&lt;V> {
     /** 
     * 当前任务的id（自增的），代表了进入队列的顺序 &lt;br/>
     * 当两个定时任务下次执行时间一致时，sequenceNumber越小就会越早执行
     */
    private final long sequenceNumber;
    // 下次执行当前任务的纳秒时间戳
    private long time;

    /**
     * 执行定时任务的纳秒间隔时间
     * 大于0：代表固定的频率，不受任务的执行所花费的时间影响
     * 等于0：代表不是一个重复的任务（只会执行一次
     * 小于0：代表固定的时间间隔，基于任务执行完毕后的时间计算。（任务执行完后再基于当前时间计算下次执行时间）
     */
    private final long period;
    // 当前任务在数组中的索引
    int heapIndex;

    public long getDelay(TimeUnit unit) {
        return unit.convert(time - now(), NANOSECONDS);
    }
    // 比较方法，决定了放入数组的位置
    public int compareTo(Delayed other) {
        if (other == this) // compare zero if same object
            return 0;
        if (other instanceof ScheduledFutureTask) {
            ScheduledFutureTask&lt;?> x = (ScheduledFutureTask&lt;?>)other;
            long diff = time - x.time;
            if (diff &lt; 0)
                return -1;
            else if (diff > 0) // 当前任务的下次执行时间更长，返回正数
                return 1;
            else if (sequenceNumber &lt; x.sequenceNumber)
                return -1;
            else
                return 1;
        }
        long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS);
        return (diff &lt; 0) ? -1 : (diff > 0) ? 1 : 0;
    }

    /**
     * false: 代表当前任务为一次性任务
     * true: 定时任务
     */
    public boolean isPeriodic() {
        return period != 0;
    }
    // 当前任务执行完毕后，用来计算下次执行时间
    private void setNextRunTime() {
        long p = period;
        // p为两次执行时间的时间间隔的纳秒值
        if (p > 0) // p大于0，即为固定时间执行的任务，基于初始运行时间计算下一次的执行时间
            time += p;
        else // p小于0，为基于完成任务的时间来执行，基于任务运行完的时间，来计算出下一次的执行时间
            time = triggerTime(-p);
    }
    // 主方法，运行当前定时任务
    public void run() {
        boolean periodic = isPeriodic();
        if (!canRunInCurrentRunState(periodic))
            cancel(false);
        else if (!periodic) // 非定时任务，当作普通任务直接调用FutureTask的run方法运行
            ScheduledFutureTask.super.run();
        else if (ScheduledFutureTask.super.runAndReset()) { // 运行定时任务，且运行成功（没抛异常）
            setNextRunTime(); // 设置下一次执行时间
            reExecutePeriodic(outerTask); // 再把当前任务重新入队列
        }
    }
    /**
      父类的FutureTask中的方法，运行并重置状态，用于任务的多次执行 
         * 正常执行时：不会修改运行状态（也就是说这个操作不会修改state字段值，保持初始值，以支持重复执行）。
         * 出现异常时：还是将state设为EXCEPTIONAL，也就是说一个定时任务要是抛出了异常，之后就不会再执行它了
         */
    protected boolean runAndReset() {
        if (state != NEW || // 不为NEW状态的都不执行
            !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                         null, Thread.currentThread()))
            return false;
        boolean ran = false;
        int s = state;
        try {
            Callable&lt;V> c = callable;
            if (c != null &amp;&amp; s == NEW) {
                try {
                    c.call(); // 不设置返回结果。多次执行的任务就不该有执行结果
                    ran = true;
                } catch (Throwable ex) {
                    setException(ex);  // 抛出异常，修改state为EXCEPTIONAL，以后也不在执行它
                }
            }
        } finally {
            // runner must be non-null until state is settled to
            // prevent concurrent calls to run()
            runner = null;
            // state must be re-read after nulling runner to prevent
            // leaked interrupts
            s = state;
            if (s >= INTERRUPTING)
                handlePossibleCancellationInterrupt(s);
        }
        return ran &amp;&amp; s == NEW;
    }
 }

1.2.2 总结ScheduledFutureTask 通过 period 字段判断任务类型：0 表示一次性任务，&gt;0 表示固定频率，&lt;0 表示固定延迟。
在 run() 方法中，若任务为周期性任务，执行完当前任务后会计算下次执行时间，并将自身重新提交至基于小顶堆的 DelayedWorkQueue 中，以维持调度。

基于纳秒时间精度，避免 System.currentTimeMillis() 的系统时间变动干扰。
复用 FutureTask 的任务封装机制，增强任务调度能力。
精简实现，不依赖额外锁，主要通过最小堆和 Delayed 接口实现调度。

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-Map</title>
    <url>/2020/04/09/java-yuan-ma-pian-map/</url>
    <content><![CDATA[​	jdk中常用Map实现类相关源码解析。包括 HashMap，LinkedHashMap，ConcurrentHashMap
 

Java源码篇-Map1 HashMap1.1 重点字段 
/**
 * 数组默认长度
 */
static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16

/**
 * 最大容量（即数组最大长度）
 */
static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;

/**
 * 默认加载因子
 * 加载因子（loadFactor）是哈希表中用于控制数组存放数据疏密程度的参数。
 * 当loadFactor越趋近于1时，数组中存放的数据（entry）越多，哈希冲突的概率增加，
 * 导致单个桶中的链表长度可能增加，进而影响查找元素的效率。反之，当loadFactor越小，
 * 数组中存放的数据越少，数据分布越稀疏，数组的利用率降低。
 *
 * 默认的loadFactor值为0.75f，是官方经过权衡后给出的一个较为理想的平衡点，
 * 旨在兼顾查找效率和空间利用率。
 */
static final float DEFAULT_LOAD_FACTOR = 0.75f;

/**
 * 树化阈值。当桶(bucket)上的结点数大于这个值时会转成红黑树
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 链表化阈值（当桶(bucket)上的结点数小于这个值时树转链表）
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * 桶中结构树化对应的table的最小长度
 */
static final int MIN_TREEIFY_CAPACITY = 64;

/**
 * 扩容阈值（threshold）
 * threshold = loadFactor * 数组长度
 * 当HashMap中元素的数量超过threshold时，会触发数组的扩容操作。
 * 扩容是为了减少哈希冲突，保持查找效率。
 */
int threshold;

1.2 核心方法1.2.1 put1 初始化数组
如果是第一次添加元素，先初始化数组（即分配内存空间）。
计算键的哈希值并确定索引位置，然后将键值对放入对应的桶（bucket）中。

2 目标桶为空
如果计算索引后，数组中对应的桶为空，则直接将键值对放入该桶中。

3 目标桶不为空
根节点匹配：
如果桶中的根节点（第一个节点）与待插入节点的键 equals，则直接替换根节点的值。


树化节点：
如果根节点是树形节点（即红黑树节点），则调用红黑树的插入方法将节点放入树中。


链表遍历：
如果根节点是链表节点，则遍历链表：
如果找到与待插入节点键 equals 的节点，则替换其值。
如果遍历到链表末尾仍未找到匹配的节点，则将新节点插入链表末尾。
树化条件：
如果链表长度（包括待插入节点）达到 8 且数组长度大于等于 64，则将链表转换为红黑树。
如果链表长度达到 8 但数组长度小于 64，则仅进行数组扩容，不进行树化。







1.2.2 resizeHashMap 数组的长度始终为 2 的次幂，且扩容时长度加倍。这样设计的主要目的是为了方便扩容时的索引计算。以下为具体的扩容过程
1 创建新数组
先创建一个长度为原数组 2 倍的新数组。

2 迁移数据
遍历原数组中的每个桶（bucket）：

如果桶为空或只有一个元素：

直接计算该元素在新数组中的索引，并将其放入新数组。


如果桶中有链表结构：

遍历链表中的每个节点（Node），计算其在新数组中的索引。

由于新数组长度是原数组的 2 倍，且长度始终为 2 的次幂，因此新索引的计算方法为：
newIndex = (key.hashCode() &amp; (newCapacity - 1))


新索引的结果只有两种可能：

与原索引相同：如果 key 的哈希值在高一位为 0。
等于原索引加上原数组长度：如果 key 的哈希值在高一位为 1。


根据计算结果，将节点放入新数组的对应位置。






3 链表拆分
如果原桶中的链表被拆分为两个链表（一个保持原索引，另一个为原索引加上原数组长度），则分别将它们放入新数组的对应位置。

1.2.3 部分核心代码final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
             boolean evict) {
  Node&lt;K,V>[] tab; Node&lt;K,V> rootNode; int tableLength, index;
  if ((tab = table) == null || (tableLength = tab.length) == 0) // 添加第一个元素
      tableLength = (tab = resize()).length;
  if ((rootNode = tab[index = (tableLength - 1) &amp; hash]) == null) // 数组上对于的索引为空，代表这个kv可以直接放到这
      tab[index] = newNode(hash, key, value, null);
  else {
      Node&lt;K,V> e; K k;
      if (rootNode.hash == hash &amp;&amp;
          ((k = rootNode.key) == key || (key != null &amp;&amp; key.equals(k)))) // bucket上的元素equals要放进来的kv，直接覆盖
          e = rootNode;
      else if (rootNode instanceof TreeNode)  // bucket上已经是红黑树结构了，直接存放为红黑树结构
          e = ((TreeNode&lt;K,V>)rootNode).putTreeVal(this, tab, hash, key, value);
      else { // 向链表的末尾添加
          for (int binCount = 0; ; ++binCount) {
              if ((e = rootNode.next) == null) { // 到链表末尾了
                  rootNode.next = newNode(hash, key, value, null);
                  if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                  { // 链表的长度（算上bucket）已经大于等于了8，转换为红黑树
                      treeifyBin(tab, hash);
                  }
                  break;
              }
              if (e.hash == hash &amp;&amp;
                  ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { // 遍历链表时有equals，直接替换
                  break;
              }
              rootNode = e;
          }
      }
      if (e != null) { // existing mapping for key
          // e不为空，代表是覆盖的情况，不是新增
          V oldValue = e.value;
          if (!onlyIfAbsent || oldValue == null)
              e.value = value;
          afterNodeAccess(e);
          return oldValue;
      }
  }
  ++modCount;
  if (++size > threshold)
      resize();
  afterNodeInsertion(evict);
  return null;
}

/**
 * resize方法，只展示了部分核心代码
 * 数组的初始化或扩容，扩容是加倍的
 */
final Node&lt;K,V>[] resize() {
    if (oldTab != null) { // 旧数组存在元素
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V> e;
            if ((e = oldTab[j]) != null) { // bucket存在元素
                oldTab[j] = null;
                if (e.next == null) // 这个bucket没有链表，只需要将它重新计算下在新数组的索引，并放入对于的bucket中
                    newTab[e.hash &amp; (newCap - 1)] = e;
                else if (e instanceof TreeNode) // 红黑树结构
                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    /* 旧数组的桶在新数组的索引位的节点 */
                    // 索引大小没有变化
                    Node&lt;K,V> loHead = null, loTail = null;
                    // 索引扩大了旧数组的长度（即新索引位：旧索引位+旧数组长度）
                    Node&lt;K,V> hiHead = null, hiTail = null;
                    Node&lt;K,V> next;
                    do {
                        next = e.next;
                        // e.hash &amp; oldCap == 0 就代表e的hash值（转换为2进制）高一位为0，
                        // 与（新的容量-1）相与后，其在数组的索引位置不变
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else { // 这里则高一位为1，与新的容量 &amp; 后，
                             // 其在新数组的索引位置会增加新容量的扩大值（即原容量的大小）
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}

1.3 线程不安全

当两个线程同时put数据时，且被put的两个数据能定位到HashMap数组的相同那个bucket位置上，就可能产生一个覆盖掉另一个的可能，造成一个数据消失。
多个线程同时修改 HashMap的结构时（如插入、删除或扩容），可能会导致部分数据丢失。比如线程A插入，而线程B正在扩容，最终导致A线程插入的数据丢失
没有volatile或锁的同步机制，会导致一个线程的修改对另一个线程不可见


2 LinkedHashMapLinkedHashMap 是 HashMap 的子类，它不仅实现了 Map 接口，还具有排序功能。其排序行为由 accessOrder 字段控制
2.1 核心字段
head：链表的头节点，指向最早插入或访问的节点。
tail：链表的尾节点，指向最近插入或访问的节点。
accessOrder（默认 false）：
false：按照插入顺序排序，越晚插入的元素越排在链表末尾。
true：按照访问顺序排序，最近访问的元素会被移动到链表末尾。可用于实现 LRU 缓存。



2.2 排序实现原理2.2.1 双向链表// 继承了HashMap.Node的Entry内部结构
static class Entry&lt;K,V> extends HashMap.Node&lt;K,V> { // 具有链表结构的Entry
    // 前驱节点和后继节点
    Entry&lt;K,V> before, after;
    Entry(int hash, K key, V value, Node&lt;K,V> next) {
        super(hash, key, value, next);
    }
}

2.2.2 添加元素// 重写了HashMap的newNode方法，在构造新节点时将其添加到链表末尾
Node&lt;K,V> newNode(int hash, K key, V value, Node&lt;K,V> e) {
    Entry&lt;K,V> p = new Entry&lt;>(hash, key, value, e);
    // 将新节点链接到链表末尾
    linkNodeLast(p);
    return p;
}

2.2.3 访问节点移动到末尾如果 accessOrder 为 true，LinkedHashMap 会在访问节点时（如调用 get 方法）触发 afterNodeAccess 方法，将最近访问的节点移动到链表末尾，基于此可以实现LRU缓存
// 重写的HashMap#afterNodeAccess方法，
void afterNodeAccess(Node&lt;K,V> e) {
    LinkedHashMap.Entry&lt;K,V> last;
    if (accessOrder &amp;&amp; (last = tail) != e) { // accessOrder为true，e不为tail
        // 重排序当前元素，将当前节点设为新的tail（保持最近一次被访问的节点在最后面）
        LinkedHashMap.Entry&lt;K,V> p =
            (LinkedHashMap.Entry&lt;K,V>)e, b = p.before, a = p.after;
        p.after = null;
        if (b == null) // e为head，更新头节点
            head = a;
        else
            b.after = a;
        if (a != null) // e不为tail
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}

3 ConcurrentHashMapConcurrentHashMap 是一个线程安全的 Map 实现，通过 **CAS 和 分段锁 机制实现高效的并发操作。其数据结构与 HashMap 类似，采用 数组 + 链表 + 红黑树 的形式：

当链表长度超过 8 时，链表会转换为红黑树。
当红黑树节点数小于 6 时，红黑树会退化为链表。

3.1 put方法死循环put元素，直到操作成功才退出

数组还没初始化，开始数组的初始化
数组的bucket还未被占用，CAS占用（成功了就break，失败了就代表已经被其他节点占用了，进行下一次循环进入其他if分支）
当前桶为ForwardingNode，表示有线程正在进行扩容操作，则先帮助扩容，等扩容完毕在继续put
bucket被占用，锁住根节点，开始构造到链表的为尾节点。添加到尾节点后，在判断当前链表长度是否超过8，否则就转换为红黑树

3.2 扩容（重点）​		核心是通过 多线程协作 和 分段迁移 的方式进行高效的数据迁移，同时尽量减少对读写操作的影响
3.2.1 扩容触发时机
当 ConcurrentHashMap 中的元素数量超过 阈值（threshold） 时触发
阈值计算公式：阈值 = 数组长度 * 负载因子（loadFactor，默认 0.75）。

3.2.2 具体步骤
首先创建一个新的数据，为元素组大小的2倍。将其设置到nextTable字段

通过CAS设置transferIndex（初始设为旧数组的长度，即是从旧数组末尾开始向前遍历转移数据的）

每个线程通过CAS从transferIndex获取一段连续长度为stride（步长）的桶，stride计算如下

// 计算步长：即扩容时每个线程每次最小处理的数组连续长度
// cpu为1，则由这个线程全部处理；cpu数量大于1，每个核心负责的步长为 数组长度/(8 * cpu核数) ，不过如果计算出步长小于16，则会被设置为16。确保线程的工作量均衡
if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE){
  stride = MIN_TRANSFER_STRIDE;
} 




开始迁移数据，到这一步了每个线程就只会迁移自己所负责的步长索引数据，不会冲突

空桶：则放置一个 ForwardingNode，表示该桶已迁移
桶为ForwardingNode：当前桶已迁移。因为整体是从后向前迁移的，可推测当前线程负责的这段步长索引一定已处理完毕，即这段步长内这个桶后面的所有桶也都已经被处理完成了，需要重新计算它下一次该负责的新步长索引
桶未迁移：则操作加锁，对桶中的链表或红黑树进行迁移，迁移完成后，再将当前桶放置为ForwardingNode节点


当最后一个线程迁移完毕后，则更新table为新数据和sizeCtl，表示扩容完成


3.2.3 相关思考
步长计算安全嘛？

​		安全，通过CAS设置公共变量transferIndex（初始值为table.length），同时该变量为volatile，它的变化能立马被其他线程感知到，可以保证每个线程处理的步长索引不会重复和交叉


其他线程如何感知并帮助扩容？

​		通过判断桶节点为ForwardingNode，则表示正在扩容，此时这个线程则帮助扩容，计算自己需要处理的步长索引来转移数据到新数组中。每处理完一个桶也将其设为ForwardingNode节点


get方法并没有加锁，如果桶已被转移怎么获取到数据？

​		首先扩容是读写分离的，扩容时不会对桶本身做任何修改（即不会修改Node的内部指针数据），所以如果拿到原桶数据，则能直接遍历获取数据。而如果拿到的是ForwardingNode，它本身也提供了find方法，会到新数组中去找到需要的数据


扩容完成如何处理？

​		每个线程完成自己负责区间的迁移后，会更新sizeCtl字段中的扩容线程数计数，判断确定最后一个完成迁移的线程会将新数组赋值给table并重新计算sizeCtl的阈值


最后需要注意，在操作数组中的桶时，都会获取这个桶节点的锁（put和resize等等修改方法），锁是相同的，所以不必担心某一个桶的相关数据被多个线程同时处理（put，resize等）


3.2.4 核心代码private final void transfer(Node&lt;K,V>[] tab, Node&lt;K,V>[] nextTab) {
    int n = tab.length, stride;
    // 计算步长：即扩容时每个线程每次最小处理的数组连续长度
    // cpu为1，则由这个线程全部处理；cpu数量大于1，每个核心负责的步长为 数组长度/(8 * cpu核数) ，不过如何计算出步长小于16，则会被设置为16。确保线程的工作量均衡
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            // 创建新数组，2次幂便于扩容计算新索引位置
            Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        // 表示从数组末尾开始分配迁移任务
        transferIndex = n;
    }
    int nextn = nextTab.length;
    ForwardingNode&lt;K,V> fwd = new ForwardingNode&lt;K,V>(nextTab);
    // 当前线程是否需要继续在旧数组上截取一段桶来处理数据，默认是
    boolean advance = true;
    // 扩容完毕的标志
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) { // i 是当前线程正在处理的桶的索引，bound 是当前线程负责的迁移任务的起始索引（也就是在处理中则 i>bound）
        Node&lt;K,V> f; int fh;
        // 检查当前线程负责的步长内的桶是否处理完毕。处理完毕，则选取下一段当前现场该处理的步长索引段
        while (advance) {
            int nextIndex, nextBound;
            if (--i >= bound || finishing)
                advance = false;
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                // i初始化为旧数组最后一个索引位置
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i &lt; 0 || i >= n || i + n >= nextn) { // 当前线程扩容完毕处理
            int sc;
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n &lt;&lt; 1) - (n >>> 1);
                return;
            }
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        else if ((f = tabAt(tab, i)) == null) // 空桶，CAS放置ForwardingNode，让其他线程可以感知到，以帮助扩容
            advance = casTabAt(tab, i, null, fwd);
        else if ((fh = f.hash) == MOVED) // 当前桶已被处理
            // 到这了就说明这段步长索引处理完毕，需要重新计算新步长索引
            advance = true; // already processed
        else {
            synchronized (f) { // 桶加锁，开始转移当前桶的链表或红黑树到新的数组里
                if (tabAt(tab, i) == f) { // 获取成功，再次校验桶节点是否变化，未变才继续操作（避免被其他刚释放了这个锁的线程给修改了）
                    // 桶数据转移到新数组去，和HashMap类似计算新数组中的索引
                    Node&lt;K,V> ln, hn;
                    if (fh >= 0) {
                        int runBit = fh &amp; n;
                        Node&lt;K,V> lastRun = f;
                        for (Node&lt;K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node&lt;K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                ln = new Node&lt;K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V>(ph, pk, pv, hn);
                        }
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        // 转移完后，旧数组的桶放置ForwardingNode，表示当前桶已处理完毕并表示为扩容中
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin&lt;K,V> t = (TreeBin&lt;K,V>)f;
                        TreeNode&lt;K,V> lo = null, loTail = null;
                        TreeNode&lt;K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V> e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V> p = new TreeNode&lt;K,V>
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V>(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V>(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        // 转移完后，旧数组的桶放置ForwardingNode，表示当前桶已处理完毕并表示为扩容中
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}

3.4 为什么key和value不允许为null，而HashMap可以呢？
​		ConcurrentHashMap如果允许key和value为null，会产生二义性。即不能确定map里本身没有这个数据，还是说有这个数据，但这个数据存的是null值。
​		为什么HashMap可以允许呢？因为它不会产生二义性，使用HashMap设计用于单线程下，假设我们获取key为A的数据返回了null，之后还马上可以通过containsKey来判断到底是不存在A还是A就为null（因为是单线程，不用担心其他线程会修改数据）
​		但ConcurrentHashMap是线程安全的，也就是默认会在多线程下修改数据。假设ConcurrentHashMap支持设置null，这时线程A获取key为null的数据返回了null，此时我们不确定A在不在ConcurrentHashMap里，需要用containsKey来判断key为null是否存在于ConcurrentHashMap里。但多线程的情况下，B线程在A线程containsKey操作前添加了key为null的数据，导致A线程containsKey返回了true，导致和第一步预期不同（第一步可能是不存在key为null的数据）
​		综上：ConcurrentHashMap，它是为并发而生的，它是要用在并发场景中的。假如允许使用 map.get(key)返回 null ，这时是没办法通过 map.containsKey来准确的检测，因为在检测过程中可能会被其他线程锁修改，而导致检测结果并不可靠。所以直接禁用了null，好处就是返回null一定能表示key不存在，而不是有其他的含义，让语义更明确了
​		所以这个设计选择反映了并发编程的一个重要原则：通过适当的限制来换取更好的可靠性和简单性。虽然失去了存储null值的能力，但换来了更清晰的语义和更好的并发安全性。

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>Map</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>Git</title>
    <url>/2020/02/07/git/</url>
    <content><![CDATA[​	Git常用命令总结


Git1 git config# git查看配置
git config --list
# ================= 全局配置（保存在用户目录下的 ～/.gitconfig 文件中）======================
# 设置全局用户名和邮箱（在 git commit 时记录为提交者信息））
git config --global user.name  "reef"
git config --global user.email "shanzhao.rd@gmail.com"
# 设置全局代理（socks5 协议，端口号为 7890）
git config --global http.proxy=socks5://127.0.0.1:7890
git config --global https.proxy=socks5://127.0.0.1:7890

# ================= 当前仓库单独配置（保存在当前仓库中 .git/config 文件中）======================
# 设置仓库专属用户名和邮箱（覆盖全局设置）
git config  user.name  "reef"
git config  user.email "shanzhao.rd@gmail.com"
# 设置当前仓库的代理（仅对该仓库生效）
git config  http.proxy=socks5://127.0.0.1:7890
git config  https.proxy=socks5://127.0.0.1:7890

2 初始化仓库# 将当前文件夹初始化为一个 Git 本地仓库
git init
# 将指定文件夹初始化为一个 Git 本地仓库
git init &lt;目录路径>

3 本地仓库的操作3.1 查看文件状态# 可以查看分支名（branch）和文件的状态，如已修改（Modified），未跟踪的（untracked）,未修改的不会有提示
git status
# 简洁版的git status
# 红色M 代表文件修改了但未加入暂存区
# 绿色M 代表文件修改了并且已加入暂存区
# ?? 代表未跟踪的，
# A 代表文件已被加入到暂存区
git status -s

3.2 未暂存的文件添加到暂存区和解暂存# 将文件加入暂存区
git add 文件名
# 将暂存区的文件取消暂存
git reset 文件名

3.3 commit(暂存区文件的提交)# 不带文件名会提交暂存区所有的文件
git commit -m "提交的日志信息"
# 提交全部暂存区文件，并打开一个编辑器，让你写入提交日志（'i':插入，'ESC':退出编辑，':wq':保存并退出）
git commit
# 该语句可将不是暂存区的文件直接commit，因为-a就代表提交到了暂存区。两步合为一步了
git commit -a -m "提交的日志信息"

3.4 已commit的文件删除# 会放在暂存区，在commit之后就删除了。如果直接在文件夹中删除，则不会放在暂存区，要将其删除，就必须先add进暂存区，再commit
git rm 文件名

3.5 将文件添加至忽略列表
 自动生成的文件，比如日志文件，class文件就不需要通过git提交，git一般只负责提交源代码。这种情况下，我们可以在工作区中创建一个.gitignore文件（文件名固定，可以在git命令行中用touch .gitignore语句创建）

# 通配符（匹配任意）
*
# 取反。比如!hello.class文件，git就不会忽略掉hello.class文件
!
# 忽略当前目录下的xxx文件
/xxx
# 忽略当前目录下的doc文件夹下的所有
doc/
# 忽略当前目录下的doc文件夹里的所有txt文件
doc/*.txt
# 忽略当前目录下的doc文件里的所有文件夹里的class文件
doc/**/*.class

3.6 查看git操作日志# 因为日志太多，不会一次性全部显示，按回车会显示下面的，按Q会退出。
git log

4. 远程仓库的操作4.1 remote# 可以查看到本地关联的的远程仓库的别名（粗略查看）
git remote
# 显示远程仓库地址（详细点）
git remote -v
# 可查看更多信息（更详细）
git remote show 远程仓库的别名
# 添加(add)远程仓库（一个本地仓库可以添加多个远程仓库）
git remote add 仓库别名 远程仓库的url
# 删除本地仓库中配置的某个远程仓库别名及其对应的 URL（该命令不会影响到真正的远程仓库）
git remote rm 远程仓库的别名

4.2 clone# 克隆远程仓库到此命令行文件夹下面
git clone 远程仓库的url

4.3 fetch &amp; pull# 从远程仓库获取最新版本带本地仓库，不会合并(merge)。如果省略这两个参数，即别名为origin，分支为matser
git fetch 仓库别名 远程仓库的branchName
# 合并到本地仓库
git merge origin/master

# 从远程仓库获取最新版本带本地仓库，会合并(merge)。如果省略这两个参数，即别名为origin，分支为matser
git pull 仓库别名 远程仓库的branchName
# 用于合并本地和远程仓库之间没有共同历史的分支内容。（强制合并）
git pull 仓库别名 远程仓库的branchName --allow-unrelated-histories

5 Git分支操作# 列出所有本地分支
git branch
# 列出所有远程分支
git branch -r
# 列出所有本地和远程的分支
git branch -a
# 查看所有本地分支，并可查看是否和远程分支建立映射关系
git branch -v
# 在本仓库中新建一个分支(在正在使用的分支下创建新的分支，新的分支将会复制正在使用的分支的所有内容进行初始化)
git branch 新分支名
# 切换到指定的分支下，前面会有*提示
git checkout 已存在的分支名
# 本地仓库分支推送到远程仓库
git push 仓库别名(shortname) 本地仓库的分支名(branchName)
# 将指定的分支名的分支文件合并到正在使用的分支里（branchName -> 正在使用的分支）
git merge 分支名(branchName)
# 根据分支名删除分支，未push的不能删除
git branch -d 分支名
# 根据分支名强力删除分支，未push的也能删除
git branch -D 分支名
# 删除远程仓库中的分支
git push 远程仓库的别名 -d 分支名
# oldName是当前分支名，newName是想改成的名
git branch -m oldName newName
# 本地更新远程仓库分支
git remote update origin --prune
# =========分支追踪（名字不同也可以）============
# 在本地新建分支local-branchName，并和对应的远程分支remote-branchName做映射，最后再checkout并pull
git checkout -b local-branchName origin/remote-branchName
# 将本地分支local-branchName分支追踪远程分支origin/remote-branchName（建立映射关系）   
git branch --set-upstream local-branchName origin/remote-branchName
# 将当前分支跟踪远程分支origin/remote-branchName   
git branch -u origin/remote-branchName

6 Git标签操作
 标签指的是某个分支的某个特定时间点的状态，记录了截止到当前时间的当前分支的全部内容。根据标签，我们可以很方便的切回到标签标记时的状态

# 创建一个新标签
git tag 新的标签名
# 列出所有标签
git tag
# 查看tag的信息
git show 标签名
# 将指定的标签推送至远程仓库
git push 仓库别名 标签名
# 新建一个分支，根据标签名指向指定的标签
git checkout -b 新的分支名 标签名
# 删除本地仓库中指定的标签
git tag -d 标签名
# 删除远程仓库中指定的标签
git push origin :refs/tags/标签名

7 SSH（secure shell）认证# 生成 SSH 密钥对的命令（由公钥和私钥组成，常用语SSH的连接和认证）
ssh-keygen -t rsa

上诉命令会生成两个文件，将公钥放在git远程仓库的ssh key里接可以使用ssh操作远程仓库了

~&#x2F;.ssh&#x2F;id_rsa：私钥，用于客户端身份认证，需保密，放在本地
~&#x2F;.ssh&#x2F;id_rsa.pub：公钥，可放在远程服务器上

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-线程池</title>
    <url>/2020/05/12/java-yuan-ma-pian-xian-cheng-chi/</url>
    <content><![CDATA[​	对jdk的ThreadPoolExecutor和ScheduledThreadPoolExecutor进行了详细的源码分析
 

线程池1 ThreadPoolExecutor1.1 重要字段//状态控制器，初始值： 1110 0000 0000 0000 0000 0000 0000 0000
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static final int COUNT_BITS = Integer.SIZE - 3; // 29位
// 0001 1111 1111 1111 1111 1111 1111 1111
// 1110 0000 0000 0000 0000 0000 0000 0000 取反后
private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;
                                                            

// 运行中：111 00000000000000000000000000000
private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS; 
// 不再接受新任务的入队列，但已经入队列还未还未的任务还可以继续执行
// 000 00000000000000000000000000000
private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS; 
// 不接受新任务入队列，也不处理队列中的任务，中断正在处理任务的worker
// 001 00000000000000000000000000000
private static final int STOP       =  1 &lt;&lt; COUNT_BITS; 
// 全部完成，任务终止，worker数为0
// 010 00000000000000000000000000000
private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;
// 011 00000000000000000000000000000
private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;

// 计算线程池的状态
private static int runStateOf(int c)     { return c &amp; ~CAPACITY; } // 后29位为0，前3为跟随c
// 计算线程池有多少工作线程
private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 前3位为0，后面29为跟随 c
private static int ctlOf(int rs, int wc) { return rs | wc; }

// 任务队列
private final BlockingQueue&lt;Runnable> workQueue;
// 主锁
private final ReentrantLock mainLock = new ReentrantLock();
// 工作线程的Set
private final HashSet&lt;Worker> workers = new HashSet&lt;Worker>();

private final Condition termination = mainLock.newCondition();
// 池已经创建的线程最大数（一个动态值，线程池整个周期同时存在的最多线程数）
private int largestPoolSize;
// 完成的任务数
private long completedTaskCount;
// 创建线程的工厂
private volatile ThreadFactory threadFactory;
// 拒绝策略
private volatile RejectedExecutionHandler handler;
// 非核心线程数的保持时间
private volatile long keepAliveTime;
// 是否允许核心线程过期
private volatile boolean allowCoreThreadTimeOut;
// 核心线程数
private volatile int corePoolSize;
// 最大线程数
private volatile int maximumPoolSize;


 ​	ThreadPoolExecutor利用一个int类型的数来同时保存当前线程池状态和工作线程的数量，高3为用来表示当前线程的状态，低29为用来保存工作线程的数量。通过位运算实现状态和数量的原子性操作，避免单独维护两个变量时的竞态条件
​	ThreadPoolExecutor内部的Worker就是工作线程的抽象，每一个Worker都是一个工作线程。同时，Worker又继承了AQS可以充当锁的角色，目的是更好的让外部知道当前worker是否正在运行，以帮助回收或中断Worker。worker运行时（获取到任务后开始运行）会加锁，通过测试当前worker是否加上锁或者是否可以获得当前worker的锁，便可知道worker是否繁忙，有助于worker的清理

1.2 核心方法1.2.1 shutdown（平滑关闭）​	将当前线程池状态设为SHUTDOWN状态，再中断空闲的Worker（判断Worker是否空闲就通过它的锁方法）。所以，执行了这个方法后，正在执行的任务不会被中断，且已经存在workQueue中的Runnable也可以被执行，但是不能放入新的Runnable
1.2.2 shutdownNow（立即关闭）​	将当前线程池状态设为STOP状态，将所有Worker设置为中断位，且倒出workQueue中的所有Runnable。所以，执行了这个方法后，正在运行的任务如果检测了中断位就会立即退出，如果没检测就还是会执行完，而已经存在workQueue中的Runnable将不会被执行，会将这些Runnable返回给调用者，让调用者处理
/**
 * 平滑关闭线程池：
 * 1. 将线程池状态设为SHUTDOWN，此时：
 *    - 继续执行已提交的任务（包括正在执行的和队列中的）
 *    - 拒绝新任务提交（execute()会抛出RejectedExecutionException）
 * 2. 仅中断空闲Worker（通过tryLock()判断）
 * 
 * 注意：正在执行的任务不会被中断，调用者需确保任务有合理的终止逻辑
 */
public void shutdown() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();// 检查每个worker线程是否可以修改
        advanceRunState(SHUTDOWN); // CAS操作更新状态为SHUTDOWN
        interruptIdleWorkers(); // interrupt所有空闲的worker
    onShutdown(); // hook for ScheduledThreadPoolExecutor
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
}
/**
 * 立即关闭线程池：
 * 1. 将线程池状态设为STOP，此时：
 *    - 中断所有Worker（无论是否在执行任务）
 *    - 丢弃队列中未执行的任务
 *    - 拒绝新任务提交
 * 2. 返回被丢弃的任务列表供调用者处理
 * 
 * 注意：
 * - 正在执行的任务是否停止取决于任务是否响应中断
 * - 典型使用场景：需要快速释放资源的紧急关闭
 */
public List&lt;Runnable> shutdownNow() {
    List&lt;Runnable> tasks;
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();
        advanceRunState(STOP);// 设置当前线程池状态为STOP
        interruptWorkers();// interrupt所有Worker
        tasks = drainQueue(); // 将任务队列中的task全部丢弃给方法调用者
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
    return tasks;
}
/**
 * 尝试终止线程池的最终状态转换：
 * 1. 检查是否满足终止条件（3种直接返回的情况）：
 *    - RUNNING状态：还有任务在执行
 *    - 已经是TIDYING/TERMINATED状态：避免重复操作
 *    - SHUTDOWN状态但队列不空：等待任务处理完成
 * 2. 如果仍有活跃Worker，尝试中断单个空闲Worker
 * 3. 最终状态转换：
 *    SHUTDOWN/STOP -> TIDYING -> TERMINATED
 */
final void tryTerminate() {
    for (;;) {
        int c = ctl.get();
        // 三种情况下直接退出
        // 1.线程池处于Running状态，还在运行
        // 2.线程池状态大于TIDYING，代表当前线程池已经终结
        // 3.shutdown状态，并且任务队列不为空，代表需等待这些任务完成
        if (isRunning(c) ||
            runStateAtLeast(c, TIDYING) ||
            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
            return;
        if (workerCountOf(c) != 0) { // Eligible to terminate
            interruptIdleWorkers(ONLY_ONE);
            return;
        }

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {
                try {
                    terminated(); // hook方法
                } finally {
                    ctl.set(ctlOf(TERMINATED, 0));
                    termination.signalAll();
                }
                return;
            }
        } finally {
            mainLock.unlock();
        }
        // else retry on failed CAS
    }
}

1.2.3 execute（投递任务）// 执行execute的方法
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    // 获取当前线程池状态
    int c = ctl.get();
    // 判断是否小于核心线程数，是则新建线程运行任务
    if (workerCountOf(c) &lt; corePoolSize) {
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 核心数满了，并且当前线程池状态为Running，加到等待队列中
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        if (! isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 等待队列满了，新建线程，但不能大于最大线程数
    else if (!addWorker(command, false))
        // 创建失败，直接调用拒绝策略
        reject(command);
}

1.2.4 worker的运行和阻塞// Worker的Runnable方法
public void run() {
    runWorker(this);
}

final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
    try {
        // 利用阻塞队列，一直循环取任务执行（阻塞队列为空时会阻塞当前想取出元素的线程）
        // 如果getTask为null，就代表会终结当前工作线程
        while (task != null || (task = getTask()) != null) {
            w.lock();
            if ((runStateAtLeast(ctl.get(), STOP) ||
                 (Thread.interrupted() &amp;&amp;
                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;
                !wt.isInterrupted())
                wt.interrupt();
            try {
                beforeExecute(wt, task); // hook before
                Throwable thrown = null;
                try {
                    task.run(); // 真正的运行Runnable
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    afterExecute(task, thrown); // hook after
                }
            } finally {
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        processWorkerExit(w, completedAbruptly);
    }
}
// 核心方法之一，从阻塞队列中取任务
private Runnable getTask() {
    boolean timedOut = false; // Did the last poll() time out?
    // 死循环取任务
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        // Check if queue empty only if necessary.
        if (rs >= SHUTDOWN &amp;&amp; (rs >= STOP || workQueue.isEmpty())) {
            decrementWorkerCount();
            return null;
        }

        int wc = workerCountOf(c);

        // 允许核心线程过期和非核心线程都可以超时取任务
        boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

        if ((wc > maximumPoolSize || (timed &amp;&amp; timedOut))
            &amp;&amp; (wc > 1 || workQueue.isEmpty())) {
            // 原子性的尝试减少一个工作线程，减少成功才返回结束线程
            if (compareAndDecrementWorkerCount(c)) 
                return null;
            continue;
        }

        try {
            // 如果是超时取任务，时间结束后还是取不到，则设置timedOut为true，下次循环就可以直接返回null退出了，这样，这个Worker也就终结了
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
            workQueue.take();
            // 不为null才返回，就不用担心返回null而终结了当前线程
            if (r != null)
                return r;
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}

1.3 总结execute Runnable的流程

先判断线程池的工作线程数量是否小于核心线程数，小于核心线程数直接新建线程来执行
如果核心线程数满了，则将Runnable投入到workQueue中
如果workQueue满了，则创建非核心线程来继续执行任务
如果线程池中的工作现场数量到达了maximumPoolSize的值，则使用拒绝策略来执行任务

Worker的工作流程
​		调用getTask取任务来执行，如果取出的任务为空，则这个Worker也就结束了（终结了）。getTask不为空的话，还是先进性一系列的线程池状态校验，在执行hook函数（beforeExecute），在真正的执行这个Runnable，再执行hook函数（afterExecute），最后再将completedTasks加1，表示当前Worker完成的任务总数
getTask流程（实现线程超时回收的关键）

先进行一系列的状态校验
判断是否允许超时（满足任意一个就行）
allowCoreThreadTimeOut为true（都允许核心线程超时了，那没任务的情况下线程池就不该有worker线程）
当前线程池的工作线程数量大于核心线程数量就允许超时


判断是否触发减少工作线程数量的机制，然后使用CAS减少工作线程数量，减少成功才返回null，结束当前工作线程
通过阻塞队列取Runnable，如果不允许超时，则会一直阻塞到这。如果允许超时，则会超时等待keepAliveTime纳秒取Runnable，如果取不出来，则设置一次已经超时，再来循环一次，来判断是否该减少工作线程

2 ScheduledThreadPoolExecutor2.1 ScheduledExecutorServicepublic interface ScheduledExecutorService extends ExecutorService {
    /**
     * 创建一个一次性的延迟（定时）任务。
     * 框架中cron表达式就是通过此接口实现（只需要在任务完成后，在计算下一次的执行时间，再用此方法定时执行，以此类推）
     */
    public ScheduledFuture&lt;?> schedule(Runnable command,
                                       long delay, TimeUnit unit);

    /**
    * 执行Callable接口的任务，也是一个一次性的定时任务
    */
    public &lt;V> ScheduledFuture&lt;V> schedule(Callable&lt;V> callable,
                                           long delay, TimeUnit unit);
    /**
     * 基于固定的频率执行定时任务 
     * 例：初始执行任务的时间戳：当前时间戳（调用时）+ initialDelay 
     * 第二次执行：初始执行任务开始时的时间戳 + period 
     * 第三次执行：第二次执行任务开始时的时间戳 + period
     *
     * 典型场景：严格周期性的任务，如：
     * - 每分钟采集一次系统指标
     * - 每5秒发送心跳包
     */
    public ScheduledFuture&lt;?> scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit);
    /**
     * 基于固定的周期执行定时任务 
     * 例：初始执行任务的时间戳：当前时间戳（调用时）+ initialDelay
     *  第二次执行：初始任务执行完结时的时间戳 + delay
     *  第三次执行：第二次任务执行完结时的时间戳 + delay
     *
     * 典型场景：需要冷却时间的任务，如：
     * - 数据库批量处理（保证每次处理完成后再间隔）
     * - 异步结果轮询（避免密集请求）
     */
    public ScheduledFuture&lt;?> scheduleWithFixedDelay(Runnable command,
                                                     long initialDelay,
                                                     long delay,
                                                     TimeUnit unit);
}

2.2 DelayedWorkQueue​	为ScheduledThreadPoolExecutor内部固定的阻塞队列，基于小顶堆数据结构实现。
​	投递的每个任务被封装后都扔进DelayedWorkQueue中，按照任务被执行的时间戳进行小顶堆排序，堆顶就刚好是队列中下个需要执行的任务。同时基于Leader-Follower 模式进行线程调度的优化，只有leader进行延时等待堆首任务，其余线程直接阻塞等待
​	核心字段和方法如下
static class DelayedWorkQueue extends AbstractQueue&lt;Runnable>
        implements BlockingQueue&lt;Runnable> {
        // 数组初始容量
        private static final int INITIAL_CAPACITY = 16;
        // 数组实现的最小顶堆结构，queue[0]始终都是最快需要被执行的那个任务
        private RunnableScheduledFuture&lt;?>[] queue =
            new RunnableScheduledFuture&lt;?>[INITIAL_CAPACITY];
        private final ReentrantLock lock = new ReentrantLock();
        private int size = 0;
        // leader线程，定时等待queue[0]任务的那个线程
        private Thread leader = null;

        private final Condition available = lock.newCondition();
        // 向堆尾新加入任务，进行上移（和父节点换个位置）调整位置
        private void siftUp(int k, RunnableScheduledFuture&lt;?> key) {
            while (k > 0) {
                int parent = (k - 1) >>> 1; // 父节点的索引
                RunnableScheduledFuture&lt;?> e = queue[parent];
                if (key.compareTo(e) >= 0) // 调整完毕，直接break
                    break;
                // 当前节点的下次执行时间更快，继续递归向上遍历，直到放到合适的位置
                queue[k] = e;
                setIndex(e, k);
                k = parent;
            }
            queue[k] = key;
            setIndex(key, k);
        }
              /**
         * Sifts element added at top down to its heap-ordered spot.
         * Call only when holding lock.&lt;p/>
         * 元素下移操作（弹出堆顶元素后，将堆尾元素放置到堆顶再重新调整下移）
         */
        private void siftDown(int k, RunnableScheduledFuture&lt;?> key) {
            int half = size >>> 1;
            while (k &lt; half) {
                // 较小值节点的索引（初始为左子节点）
                int child = (k &lt;&lt; 1) + 1;
                // 小值，初始为左子节点
                RunnableScheduledFuture&lt;?> c = queue[child];
                // 右子节点索引
                int right = child + 1;
                if (right &lt; size &amp;&amp; c.compareTo(queue[right]) > 0) // 如果右子节点更小，则将c替换为右子节点，同时替换child为右子节点索引
                    c = queue[child = right];
                if (key.compareTo(c) &lt;= 0) // 目标元素比最小的子节点元素还小，目的就达成了，直接break
                    break;
                // 左右子节点中较小的节点和父节点交换
                queue[k] = c;
                setIndex(c, k);
                // 替换目标索引，继续将参数k向下比较
                k = child;
            }
            queue[k] = key;
            setIndex(key, k);
        }
        /**
          重写的offer方法（该方法就是线程池投递任务的方法）
         */
        public boolean offer(Runnable x) {
            if (x == null)
                throw new NullPointerException();
            RunnableScheduledFuture&lt;?> e = (RunnableScheduledFuture&lt;?>)x;
            final ReentrantLock lock = this.lock;
            lock.lock();
            try {
                int i = size;
                if (i >= queue.length)
                    grow();
                size = i + 1;
                if (i == 0) { // 数组中还没有任务，直接放在首位
                    queue[0] = e;
                    setIndex(e, 0);
                } else { // 已存在定时任务，看是否需要调整位置
                    siftUp(i, e);
                }
                 if (queue[0] == e) {// 代表向队列添加了一个需要最快执行的任务
                    // 需要重置leader线程，并唤醒一个阻塞的线程（可能为无限阻塞的，也可能为上个定时等待的leader线程）来定时等待这个任务
                    // 换种角度，如果唤醒的是上个定时等待的leader线程，那肯定是很赚的，因为不需要启动多个定时等待的线程了
                    // 如果唤醒的不是上个leader线程，那就会存在多个定时等待的线程，这是没法避免的
                    leader = null;
                    available.signal(); // 将阻塞的线程从等待队列转移到同步队列，当下面的unlock后再唤醒阻塞线程
                }
            } finally {
                lock.unlock();
            }
            return true;
        }
        
        /*
        重写的take方法
        
        所以，多线程多任务且没有任务需要立即执行造成的结果就是：
            1、1个leader线程定时等待队首任务（实时的向线程池添加最快需要执行的任务，可能存在多个定时等待的线程，且至少他们曾经是leader线程）
            2、其余全部线程无限期等待，最大程度的减少资源损耗（因为任务都有顺序，没必要同时让所有线程都定时等待，给底层的通知增加压力）
        总结：
        1、当没有任务时：所有线程都无限等待，没有leader线程，等待任务入队列的唤醒
        2、当有任务时：唤醒的线程成为leader线程，当这个leader线程等待到期时，
            取消自己为leader线程（另一种说法就是自己变成了follower线程），
            唤醒一个无限期等待的线程，然后自己就去执行这个到期的任务，被唤醒的线程就会变成新的leader线程。一直这么循环下去
        3、当实时向线程池添加最快需要执行的任务时：会取消当前leader线程，并唤醒一个阻塞的线程，让其成为新的leader线程

         */
        public RunnableScheduledFuture&lt;?> take() throws InterruptedException {
            final ReentrantLock lock = this.lock;
            lock.lockInterruptibly();
            try {
                for (;;) {
                    RunnableScheduledFuture&lt;?> first = queue[0];
                    if (first == null) // 不存在定时任务，所有线程都在这等待
                        available.await();
                    else {
                        long delay = first.getDelay(NANOSECONDS);
                        if (delay &lt;= 0) // 时间已过，弹出队首任务去执行它
                            return finishPoll(first);
                        // 进入下面，无论怎样都要等待，所以直接把first置为null，下次循环再获取
                        // 因为可能多个线程走到下面，都持有了队首的引用。避免出现RunnableScheduledFuture运行完了但不能及时回收的情况
                        // 当然，也只有一次性的RunnableScheduledFuture才会回收，定时任务都是循环使用这个RunnableScheduledFuture的
                        first = null; // don't retain ref while waiting
                        if (leader != null) // 由leader存在，其他线程只需要无限期等待就行
                            available.await();
                        else { // 没有leader存在，设置当前线程为leader，并定时等待（时间就为最近待执行的那个任务的距离下次执行时间间隔）
                            Thread thisThread = Thread.currentThread();
                            leader = thisThread;
                            try {
                                available.awaitNanos(delay); // 定时等待
                            } finally { // 时间一到，说明队首任务可执行了，但当前线程可能不是leader线程了，需要判断一下再置空
                                if (leader == thisThread) // 必须判断，有可能实时的添加了一个最快需要执行的线程，导致当前线程被取消了leader
                                    leader = null;
                            }
                        }
                    }
                }
            } finally {
                if (leader == null &amp;&amp; queue[0] != null)
                    // 任务取出来了，leader为空且存在队首任务，需要唤醒一个无限等待的线程
                    // 让其成为leader线程并继续定时等待
                    available.signal();
                lock.unlock();
            }
        }
}

2.3 总结​	ScheduledThreadPoolExecutor本质还是个线程池，内部的DelayedWorkQueue就是工作队列。投递的定时任务和普通任务都会封装为ScheduledFutureTask，并最终放入DelayedWorkQueue里的那个数组（只不过定时任务有延时，可能会放在队列中的任何位置。而普通任务封装的ScheduledFutureTask执行时间就是当前而已，始终会放到队列的队首并立马执行）
​		DelayedWorkQueue实现了BlockingQueue，是基于数组的最小顶堆的数据结构实现，以此保证数组的第一个位置就是最近需要被执行的任务。结构图和特点如下
​		ScheduledThreadPoolExecutor还使用了Leader-Follower模式，leader线程定时等待工作队列中第一个任务，其余线程一般就都无限期等待（如果向工作队列添加的是一个最快需要被执行的任务，可能就有多个定时等待的线程，但leader线程始终都会是最快需要被执行任务的线程）。
为什么使用Leader-Follower模式：

​		避免资源的浪费。定时任务再怎么排序，也只会有一个是最快需要执行的任务（时间相同会根据sequenceNumber排序），只需要设计一个定时等待线程等待这个最快需要执行的任务。当这个最快需要执行的任务触发后，再设计一个新的leader线程等待下一个最近的定时任务。理想的情况下，定时任务线程池只会有一个定时等待的线程（Leader线程），其余线程要么正在运行定时任务，要么全部无限期阻塞（Follower线程），最大程度的避免资源浪费（无限期等待的线程不用想其它的，乖乖等待被其他线程唤醒就行。而定时等待的线程需要在时间到达后被唤醒，至少需要被定时器监视以用来执行唤醒操作）


固定周期：受执行时常影响，只有当任务结束后才相对于结束时间来计算任务的下次执行时间
固定频率：不受任务的执行时常所影响，当任务投递到队列时就可以预判到以后任何执行该任务的时间

​	一个被投递的周期任务首先会封装成ScheduledFutureTask，再根据其下次执行时间放在DelayedWorkQueue的某个位置。如果放在了DelayedWorkQueue的队首，则使用定时任务线程池里的线程超时等待，以便时间到达后开始执行。正常执行完毕则会先根据其是固定周期任务还是固定频率的任务来计算下次执行时间并修赋值到ScheduledFutureTask的time字段，再将这个任务再次入队列，这样递归去执行。执行中如果抛出了异常，则会将ScheduledFutureTask的state修改为异常，之后就不再执行这个任务了
]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-AQS</title>
    <url>/2020/04/17/java-yuan-ma-pian-aqs/</url>
    <content><![CDATA[
​	总结了LockSupport的作用，并从源码分析了AbstractQueuedSynchronizer的实现逻辑


Java源码篇-AQS1 LockSupport1.1 总结Java中实现当前线程的阻塞和定时阻塞，并提供唤醒指定线程的工具，在内部使用sun.misc.Unsafe来实现这一系列的操作。在AQS中普遍被使用

阻塞当前线程：通过 park() 方法使当前线程进入等待状态。
定时阻塞：通过 parkNanos(long nanos) 或 parkUntil(long deadline) 方法使当前线程在指定时间内等待。
唤醒指定线程：通过 unpark(Thread thread) 方法唤醒指定的处于等待状态的线程。

1.2 核心代码/**
 * 唤醒指定的线程（如果该线程被park了）
 * 如果线程先被unpark（解除等待）了，那么该线程下一次调用park(进入等待)则不起作用，也就不会被阻塞
 */
public static void unpark(Thread thread) {
    if (thread != null)
        UNSAFE.unpark(thread);
}

/**
 * 阻塞当前线程，并设置一个blocker（俗称阻塞器，这个只是用来jstack查看，并不能通过notifyAll来唤醒阻塞的线程）
 * blocker只能用来调试和诊断，并不影响线程的阻塞和唤醒
 */
public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}

/**
 * 定时等待，阻塞当前线程指定的纳秒数，当时间到达时就自动唤醒（定时任务会调用）
 */
public static void parkNanos(long nanos) {
    if (nanos > 0)
        UNSAFE.park(false, nanos);
}

/**
 * 定时等待，阻塞当前线程直到指定的时间戳（deadline）到来就自动唤醒（定时任务会调用）
 */
public static void parkUntil(long deadline) {
    UNSAFE.park(true, deadline);
}

2 AbstractQueuedSynchronizer
​		Node是AQS的核心内部类，它是构建同步器的基础数据结构，通过不同的配置可以实现同步队列，也可实现等待队列

2.1 同步队列​		当线程尝试获取锁时，未获取到锁的线程会被构造成一个Node，利用CAS放入同步尾部作为尾节点，等待被唤醒。同步队列关联的是整个锁，一对一的关系。而同步队列中的Node又根据nextWaiter字段判断当前Node是共享节点还是独占节点

Node之间通过prev和next指针构成双向链表

头节点(head)代表当前持有锁的线程

包含waitStatus字段标记节点状态

CANCELLED(1): 线程已取消
SIGNAL(-1): 后继节点需要唤醒
CONDITION(-2): 节点在等待队列中
PROPAGATE(-3): 共享锁需要向后传播
0: 初始状态


使用nextWaiter区分共享&#x2F;互斥模式

共享节点：共享锁的实现（Semaphore、CountDownLatch等）。nextWaiter字段为固定的Node#SHARED。释放当前节点的线程后，还具有向后传播的能力（根据state的值判断是否需要释放后继共享节点里的线程）

互斥节点：互斥锁的实现（ReentrantLock等），nextWaiter字段为Node#EXCLUSIVE（即null），只会释放当前节点里的线程




2.2 等待队列​		当已经获取到锁的线程触发java.util.concurrent.locks.Condition#await()方法阻塞自己，让出锁时。会将当前线程构造成一个Node（等待节点，状态为CONDITION），利用CAS放入等待队列尾部。等待队列关联的是Condition。所以，当ReentrantLock构造多个Condition时，就有多个等待队列，ReentrantLock和等待队列可以为一对多，而Condition和等待队列时一对一。而当其他线程获取当前锁（ReentrantLock）的线程调用java.util.concurrent.locks.Condition#signal等方法时，便会将等待队列的首节点转入到同步队列的尾节点，并重新设置Node的状态

单向链表结构，只使用nextWaiter指针

nextWaiter字段为等待队列中下一个等待节点的指针

当调用signal()时，节点从等待队列转移到同步队列过程中的状态变化如下

CONDITION -&gt; 0
入队同步队列
等待获取锁



2.3 核心代码// 同步队列专属的头尾节点。
// 因为只有在同步队列里的线程才需要被唤醒。等待队列里的线程如果要被唤醒，需要先加入到同步队列
private transient volatile Node head;
private transient volatile Node tail;
// 核心，可获取到锁的次数
// - ReentrantLock: 表示重入次数
// - Semaphore: 表示剩余许可数
// - CountDownLatch: 表示剩余计数
private volatile int state;
// 自旋的阈值（纳秒）。当超时等待时间小于这个值时，就不会再暂停线程，而是自旋。因为这个时间已经很少了，考虑到阻塞线程后上线文切换会消耗时间，就没必要再阻塞了
static final long spinForTimeoutThreshold = 1000L;
// 获取到独占锁的线程
private transient Thread exclusiveOwnerThread;

/**
    留给子类实现的尝试获取共享锁的方法，共享锁获取，返回AQS里state的剩余值 
    1：返回值 > 0，代表当前线程获取成功，且state还有剩余值，表示可以继续传播给下一个共享节点线程，让其尝试获取锁 
    2：返回值 = 0，代表当前线程获取成功，但state值刚好被用完，那么下一个共享节点线程就不应该被唤醒了（因为这时已经获取不到state的剩余值了）
    3：返回值 &lt; 0，代表当前线程都没获取成功，直接获取失败，阻塞等待被其他线程唤醒后在尝试获取
*/
protected int tryAcquireShared(int arg) {
    throw new UnsupportedOperationException();
}

// 获取共享锁
private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    final Node node = addWaiter(Node.SHARED);
    boolean failed = true;
    try {
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) { // 首节点的下个节点才有资格获取锁（首节点就是获取到锁的节点）
                int r = tryAcquireShared(arg);
                if (r >= 0) { // 至少当前线程获取成功了，但可能state值已经被用完了
                    // 获取成功，传播给下一个共享Node，根据state的剩余值来判断是否需要唤醒下一个共享Node里的线程
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt()) // 不能获取到锁线程就park
                throw new InterruptedException();
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
// 释放共享锁（Semaphore会使用）
private void doReleaseShared() {
      // 必要的循环
      // 1. CAS操作可能失败需要重试
    // 2. 在设置head的过程中可能有新的节点入队
    // 3. 传播机制要求必须确保传播状态正确设置
    for (;;) {
        Node h = head;
          // h != tail 检查确保队列中还有后继节点
        if (h != null &amp;&amp; h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            // loop to recheck cases
                unparkSuccessor(h);
            }
            else if (ws == 0 &amp;&amp;
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;                // loop on failed CAS
        }
        if (h == head)                   // loop if head changed
            break;
    }
}

/*
    将目标节点（参数node）设为同步队列的尾部（使用CAS来解决并发问题）。
    所以，在这整个过程中，链表中除首节点外其余节点的prev在任何时刻都不会为空；
        但除尾节点外其余节点的next字段有可能为空 （刚好走完第②步，还没走到第③步）
*/
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // 初始化同步队列，设置一个空Node为首尾节点
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t; // 先将目标节点的prev设置程原尾节点 ①
            if (compareAndSetTail(t, node)) { // CAS设置尾节点 ②
                t.next = node; // 设置成功了，才把原尾节点的next设为目标节点（现尾节点）③
                return t;
            }
        }
    }
}

// 唤醒目标节点（参数node）的最近下一个可唤醒节点中的线程
private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);
    // 首节点的下个节点唤醒失败时，就从尾节点向前遍历，直到找到距首节点最近的可唤醒的节点
    // 目的是避免并发时（节点入队列和唤醒），倒数第二个节点（甚至不止）的next字段为空，导致拿不到其实已经入队列里的后续节点
    Node s = node.next;
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}

// ============内部的Node数据结构=================
static final class Node {
    // 共享锁
    static final Node SHARED = new Node();
    // 互斥锁
    static final Node EXCLUSIVE = null;
    //  取消获取锁
    static final int CANCELLED =  1;

    static final int SIGNAL    = -1;
    // 等待condition唤醒（等待队列才会用到这个状态）
    static final int CONDITION = -2;
    static final int PROPAGATE = -3;
        // 当前节点的状态
    volatile int waitStatus;
    // 同步队列专用
    volatile Node prev;
    // 同步队列专用
    volatile Node next;
    // 等待线程
    volatile Thread thread;
    // 1. 当前Node为同步队列中的共享节点时：SHARED
    // 2. 当前Node为同步队列中的独占节点时：null
    // 3. 当前Node为等待队列中的节点时：下一个等待节点的指针
    Node nextWaiter;
        // 判断当前节点是互斥锁，还是共享锁
    final boolean isShared() {
        return nextWaiter == SHARED;
    }
        // 当前节点的前驱结点
    final Node predecessor() throws NullPointerException {
        Node p = prev;
        if (p == null)
            throw new NullPointerException();
        else
            return p;
    }
}

]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>LockSupport</tag>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title>Java源码篇-锁</title>
    <url>/2020/04/18/java-yuan-ma-pian-suo/</url>
    <content><![CDATA[​	jdk中AQS实现类相关源码解析。包括 ReentrantLock，Condition，CountDownLatch，Semaphore，ReentrantReadWriteLock


锁1 ReentrantLock​		基于AQS实现的一种可重入互斥锁，所以只允许一个线程获取到锁。获取到锁时state设为1，当获取到锁的线程尝试重入时，便会增加state，同理需要将state减到0才会释放锁
1.1 非公平锁（NonfairSync）lock

java.util.concurrent.locks.ReentrantLock.Sync#nonfairTryAcquire：利用CAS尝试设置state，能设置成功，代表获取到锁，成功返回。设置失败，代表已经被其他线程获取了锁，返回失败
返回失败后将当前线程构造为Node节点，设置到同步队列的链表中进入到java.util.concurrent.locks.AbstractQueuedSynchronizer#acquireQueued方法：死循环获取当前Node的前一个节点（同步队列的首节点是成功获取到锁的节点），如果前驱结点为首节点，当前Node才有资格获取锁。如果还是获取不到，就调用java.util.concurrent.locks.LockSupport#park(java.lang.Object)方法阻塞当前线程，等待其他线程唤醒再去竞争锁


unlock

java.util.concurrent.locks.ReentrantLock.Sync#tryRelease：复原state（将其归0），exclusiveOwnerThread设为null
java.util.concurrent.locks.AbstractQueuedSynchronizer#release：在tryRelease成功后，使用java.util.concurrent.locks.LockSupport#unpark方法唤醒同步队列首节点的下一个节点里的线程，让他再去尝试获取锁


1.2 公平锁（FairSync）lock
​		和非公平锁很像，不同的部分就在覆盖了java.util.concurrent.locks.AbstractQueuedSynchronizer#tryAcquire这个方法和非公平锁略有不同。在新的线程获取锁失败，并将自己构造为Node节点并放入同步队列链表后，还会通过调用java.util.concurrent.locks.AbstractQueuedSynchronizer#hasQueuedPredecessors方法

unlock：和非公平锁一样核心代码
// ReentrantLock的公平锁第一次尝试获取锁
protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (!hasQueuedPredecessors() &amp;&amp; // 测试当前线程是否是等待最久的线程
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
} 

/** 
 * 查询是否有线程等待获取的时间长于当前线程
 * 判断是否存在队列中第二个Node(因为首节点是个空节点)，且第二个节点中的线程是否是当前线程
 * 也就是说：判断同步队列中当前节点是否有前驱结点
 * true:代表当前线程不是等待最久的线程或压根就没有等待的线程
 * false:在代表当前线程已经是等待最久的线程（毕竟队列越前面，则代表进去的越久）&lt;p/>
 * 只有公平锁才需要用到这个方法，来判断当前线程是否等待时间最长
 */
public final boolean hasQueuedPredecessors() {
    Node t = tail; 
    Node h = head;
    Node s;
    // 用 h != t 来做判断是因为调用这个方法的线程此时还没有进入等待队列
    // 如果 h != t，则代表队列中有线程在等待获取锁
    return h != t &amp;&amp;
        ((s = h.next) == null || s.thread != Thread.currentThread());
}

1.3 总结1.3.1 为什么叫公平锁和非公平锁​	根据上面的分析，公平锁在获取锁是总是会先判断当前线程是否是等待最久的线程。所以，就算是同步队列存在大量Node，且有线程第一次在获取锁，那么，下一次获取到锁的线程也一定是同步队列的首节点的下一个节点，即必须排队。（首节点就是当前获取到锁的节点，只有获取成功了，同步才会更新首节点）
​	非公平锁中：对于已经进入同步队列的线程来说，也只能首节点的下一个节点里的线程能尝试获取锁。但对于还未构造成Node加入到同步队列的线程来说，这个线程和首节点的下一个节点里的线程能竞争获取锁，所以非公平。但对于已经进入同步队列的线程来说，前驱结点是一定比后面的节点先获取到锁的
1.3.2 各自优势
公平锁：防止线程饥饿，分散性很好，适合线程等待时间敏感的场景
非公平锁：更快。一是获取锁是不用判断当前线程是否是等待最久的线程。二是上下文交换没有公平锁频繁。在存在大量锁竞争的前提下，可以肯定，公平锁上下文切换很频繁，获取锁后的线程再次获取锁时是一定会阻塞的。而非公平锁则不一样，下一次获取到锁的线程仍可能是上一次获取到锁的线程，没有上下文切换

2 Condition等待通知接口，代替Object原生的wait和notify，其具体实现为AQS里的ConditionObject（定义在AQS里的非静态内部类，所以使用了AQS部分方法来实现其功能）。只有获取到锁的线程才能调用Condition的阻塞和唤醒方法。三个核心组件如下

等待队列：使用 Node 节点串联，与 AQS 同步队列共用 Node 结构 
状态转换：Node 在等待队列和同步队列之间的转换 
线程控制：包括阻塞、唤醒、中断处理等机制

主要字段
// 等待队列中的首节点
private transient Node firstWaiter;
// 等待队列中的尾节点
private transient Node lastWaiter;

2.1 Condition#await流程

首先将当前线程构造为等待节点，并加入到等待队列的末尾
其次释放锁资源（能够await的线程一定是获取到锁的），同时唤醒同步队列的第二个节点，让其尝试获取锁
死循环判断当前节点是否为同步节点（等待节点在等待队列里，是一定要阻塞的。同步节点在同步队列里，是可以并被唤醒并尝试获取锁的），await到这里线程就阻塞了
当被唤醒后，当前节点一定被加入了同步队列，再尝试获取锁，如果能获取到，代表就可以返回了。如果获取不到，就表示当前同步块被其他线程暂用了，也还是阻塞。不过下一次被唤醒后就会通过同步队列的唤醒方式来尝试获取锁


代码public final void await() throws InterruptedException {
    if (Thread.interrupted()) // 响应中断
        throw new InterruptedException();
    // 构建等待节点并加入等待队列
    Node node = addConditionWaiter();
    // 先检查当前线程是否已获取到锁，否则抛异常。然后完全释放锁并且唤醒同步队列中的第二个节点
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    // 死循环判断当前节点是否在等待队列中
    // 等待队列中的节点一定要阻塞，而同步队列中的节点是可以被唤醒的
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 当signal后，需要重新获取锁，要复原现场，需要重新持有上一次所持有的所有的state值
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0) // 当前节点有中断
        reportInterruptAfterWait(interruptMode);
}
/**
 *   将当前线程构造为一个等待节点，并加入到等待队列的尾部，并通过nextWaiter字段建立联系 &lt;br/>
 *  注意：等待队列建立关联用的是nextWaiter字段，不是prev和next字段
 */
private Node addConditionWaiter() {
    Node lastW = lastWaiter; // 尾节点
    // If lastWaiter is cancelled, clean out.
    if (lastW != null &amp;&amp; lastW.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        lastW = lastWaiter;
    }
    Node node = new Node(Thread.currentThread(), Node.CONDITION);
    if (lastW == null)
        firstWaiter = node;
    else
        lastW.nextWaiter = node;
    lastWaiter = node;
    return node;
}

// ====================以下为AQS中的方法===================
// 判断这个节点是否在同步队列上
// false -> 这个节点在等待队列上
// true -> 这个节点在同步队列上
final boolean isOnSyncQueue(Node node) {
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    if (node.next != null) // If has successor, it must be on queue
        return true;
    return findNodeFromTail(node);
}
/**
* 当前节点尝试获取锁
* 返回true -> 获取锁的过程有中断
*/
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node prevNode = node.predecessor();
            // 只有当前节点的前驱结点为首节点，当前节点里的线程才有资格获取锁
            // 只可能有一个线程获取成功（即获取锁），所以设置首节点不需要同步了
            if (prevNode == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                prevNode.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(prevNode, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

2.2 Condition#signal和signalAll分析singal的目的很简单，就是将等待队列的首节点转移到同步队列的尾节点，signalAll则是将等待队列中的所有节点都转移到同步节点。signal方法本身不能唤醒线程，只是让这些节点里的线程有资格被唤醒，可以将signal和排队买票做类比

等待队列相当于候补区
signal 相当于叫号，让候补区的人去正式排队区（同步队列）
但叫号本身并不会直接让人拿到票，还需要排队区的人按顺序获取票（锁）

代码private void doSignal(Node first) {
    do {
        // 将首节点的nextWaiter转移到首节点，如果nextWaiter为空，则表示队列中只有一个节点，且首尾相同
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null; // gc处理
    } while (!transferForSignal(first) &amp;&amp;
             (first = firstWaiter) != null);
}
// 将当前的等待节点转换为同步节点，并加入到同步队列的末尾
final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;
    Node p = enq(node);
    int ws = p.waitStatus;
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        LockSupport.unpark(node.thread); // 前驱节点被取消了，或者设置为SIGNAL失败
    return true;
}

2.3 总结​		Condition实现了等待通知，当一个线程进入同步块后，就可以调用await，释放自己获取的锁资源，将自己阻塞。内部实现是首先将当前线程构造成一个等待节点，加入ConditionObject的等待队列的末尾，再释放锁资源，之后唤醒同步队列的第二个节点让其尝试获取锁。而当其他进入同步块的线程调用signal后，会将等待队列的首节点转移到同步队列，并将其变成同步节点，最后再使用同步队列的唤醒机制等待被唤醒。
​		所以signal并不能直接唤醒一个await的线程，最佳使用案例就是消费者发送者机制，比如阻塞队列。
3 CountDownLatchCountDownLatch为共享锁实现，只能使用一次。用来“卡点”，阻塞的线程需要等待其他线程准备好了后（countDown直到AQS里的state为0），才继续被唤醒执行后面的代码。
在CountDownLatch中，AQS里的state值并不表示可获取到锁的次数，而是java.util.concurrent.CountDownLatch#countDown state值的次数后会释放所有调用了**java.util.concurrent.CountDownLatch#await()**的线程
内部的同步器Sync主要方法
/**
    获取共享锁，只有AQS的state为0才能获取到
    通过这个接口就可以猜到，当state为0时（拉下了所有门闩），总会返回1，代表获取锁成功。
    并依次传播下去递归调用这个方法，直到同步队列的所有Node里的线程全部唤醒，这就是CountDownLatch的原理
*/
protected int tryAcquireShared(int acquires) {
    return (getState() == 0) ? 1 : -1;
}

// 释放共享锁，state第一次被减为0才释放成功，也就表示了CountDownLatch只能用一次
protected boolean tryReleaseShared(int releases) {
    // Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}

await方法会阻塞当前线程，直到其他线程“拉下所有门闩”。阻塞的线程会构造为共享节点加入同步队列，只有队首节点的下一个节点才有资格尝试获取锁，获取不到就LockSupport#park
countDown会将state值减小1，当state将为0时，释放同步队列里的第二个共享节点里的线程。当这个线程释放后，就能成功获取到锁了，将这个事件传播下去，一次唤醒同步队列里的所有共享节点。至此，所有被阻塞的线程都被唤醒且会成功获取到锁，最终从await方法里返回
4 Semaphore信号量，共享锁实现。可以利用构造器指定令牌（permits）的数量。当线程到达时，获取（acquire）指定数量的令牌，当没有可用令牌（premits为0）时，阻塞线程，等待令牌的释放（release）再被唤醒后继续执行。基于此，即可实现共享锁（permits大于1），也可实现不可重入的互斥锁（permits为1）
也分为公平锁和分公平锁，其判断方式完全和ReentrantLock一致。
​		非公平锁允许准备进入同步块的线程（还未加入同步队列）和同步队列中的第二个节点竞争获取锁。而公平锁则只允许同步队列中第二个节点里的线程能尝试获取锁。
​		其实现方式就是将state设为我们允许并发运行的线程数量，每当一个线程获取到锁后，将state - 1，如果state为0则阻塞所有准备进入同步块的线程，并将其构造为共享节点加入同步队列。每当有线程从同步块退出时，将state + 1，并根据是否非公平来唤醒同步队列的第二个节点来尝试获取锁
5 ReentrantReadWriteLock​		读写锁，支持并发的读或互斥的写。读写锁分别各自实现，读锁使用共享锁，写锁使用互斥锁。ReentrantReadWriteLock内部的ReadLock和WriteLock都使用了内部同一个Sync对象来实现读写加锁的功能，在Sync内，他将AQS的state转换为二进制，高十六位表示读状态位，低十六位表示写状态位。由于读是共享的，所以state的高十六位表示了当前有多少个线程在读，在此期间写锁是禁用的。而低十六位是写锁，所以只可能有一个线程，但可能数字大于1（这是就表示写锁重入了）。当写锁被占用是，读是不允许的
static final int SHARED_SHIFT= 16;                     //   读状态位            写状态位
static final int SHARED_UNIT  = (1 &lt;&lt; SHARED_SHIFT); // 0000000000000001 0000000000000000
static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;//0000000000000000 1111111111111111
static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;//0000000000000000 1111111111111111
// 获取共享锁冲入次数（读锁专用）
static int sharedCount(int c)    { return c >>> SHARED_SHIFT; }
// 获取排他锁冲入次数（写锁专用）
static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; }


读写锁都支持重入，但写锁只能让当前线程重入，并且要解锁时需要unlock重入的次数。

支持锁降级但不支持锁升级

 锁降级：即一个线程在持有写锁的情况下，可以继续获取读锁，然后释放写锁，从而将写锁降级为读锁。在某些场景下很有用，比如

在写操作完成后，仍然需要保持对数据的读访问权限
避免其他线程在写锁释放后立即获取写锁，导致数据不一致




]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>AQS实现类</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈ThreadLocal为什么被设计为弱引用</title>
    <url>/2020/11/21/tan-tan-threadlocal-wei-shi-me-bei-she-ji-wei-ruo-yin-yong/</url>
    <content><![CDATA[
分析了ThreadLocal为什么要被设计为弱引用，并给出了ThreadLocal的建议使用方法


谈谈ThreadLocal为什么被设计为弱引用​	ThreadLocal在用作ThreadLocalMap的key时，是被设计为弱引用的。
​	ThreadLocalMap的内部类Entry被设计为实现了WeakReference，Entry用来存放数据。在构造Entry对象时，将传进来的ThreadLocal对象包装成了真正的弱引用对象，而Entry对象和内部的value对象本身是强引用的。
弱引用的解释：

​		只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。

​	简单理解就是当垃圾回收时，该对象只被WeakReference对象的弱引用字段（T reference）所引用，而未被任何强类型的对象引用，那么，该弱引用的对象就会被回收。
​	注意：WeakReference引用本身是强引用，它内部的（T reference）才是真正的弱引用字段，WeakReference就是一个装弱引用的容器而已。
1 回收测试示例public class ThreadLocalDemo {
    public static void main(String[] args) throws InterruptedException {
        firstStack();
        System.gc();
        TimeUnit.SECONDS.sleep(1);
        Thread thread = Thread.currentThread();
        System.out.println(thread); // 在这里打断点，观察thread对象里的ThreadLocalMap数据

    }
    // 通过是否获取返回值观察A对象里的local对象是否被回收
    private static A firstStack(){
        A a = new A();
        System.out.println("value: "+ a.get());
        return a;
    }
    private static class A{
        private ThreadLocal&lt;String> local = ThreadLocal.withInitial(() -> "in class A");

        public String get(){
            return local.get();
        }
        public void set(String str){
            local.set(str);
        }

    }
}


ThreadLocal 被强引用持有，不会被回收


ThreadLocal只被弱引用持有，gc后被回收了

​	如上面的代码，当构造一个A对象时，内部的local对象也构造了，之后调用get和set方法对local对象取值和设置值，当A对象不可达时，垃圾收集器就会回收A。
​	现在我们假设ThreadLocalMap的Entey里的key（ThreadLocal对象）不是弱引用的，且已经调用了A的对象的get或set方法，那么垃圾收集器回收A对象时，一定不会回收里面的local对象，为什么？

因为Entey已近持有了local对象的引用，我们没有设置引用类型，那这个引用就默认是个强引用。
Thread -&gt; ThreadLocal.ThreadLocalMap -&gt; Entry[] -&gt; Enrty -&gt; key（threadLocal对象）和value

​	引用链如上面所示，这个引用链全是强引用，当这个线程还未结束时，他持有的强引用，包括递归下去的所有强引用都不会被垃圾回收器回收。
​	那么回到正常情况，ThreadLocalMap里Entey的key是弱引用，在本例中也就是local对象在这里是弱引用，当对象A回收时，由于local对象只剩下被弱引用key所引用，所以local对象也会被回收。
2 重点来了，key为什么被设计为弱引用？？​	回归本质，ThreadLocalMap是用来存放对象的，在一次线程的执行栈中，存放数据后方便我们在任意的地方取得我们想要的值而不被其他线程干扰。ThreadLocalMap本身并没有为外界提供取出和存放数据的API，我们所能获得数据的方式只有通过ThreadLocal类提供的API来间接的从ThreadLocalMap取出数据，所以，当我们用不了key（ThreadLocal对象）的API也就无法从ThreadLocalMap里取出指定的数据。
​	在上面的例子中，A对象被回收了，这些get和set方法也访问不到了，也就没法从ThreadLocalMap里取出数据了。没法利用API取出数据，那这个Entry对象还有用吗？？所以最好的方法是在A对象被回收后，系统自动回收对应的Entry对象，但是让Entry对象或其中的value对象做为弱引用都是非常不合理的（这两个要是使用弱引用，都可能造成数据意外丢失）。所以，让key（threadLocal对象）为弱引用，自动被垃圾回收，key就变为null了，下次，我们就可以通过Entry不为null，而key为null来判断该Entry对象该被清理掉了。
​	至于ThreadLocalMap为什么不给外界提供API来操作数据，我觉得是因为这个Map对于一个线程只有一份，任何地方都在用，为了提供更方便的API和为了我们不破换其他框架保存到里面的数据（数据不被污染），所以才用ThreadLocal作为key和API来操作数据。
3 总结​	综上，Entry的key被设计为弱引用就是为了让程序自动的对访问不到的数据进行回收提醒。所以，在访问不到的数据被回收之前，内存泄漏确实是存在的，但是我们不用担心，就算我们不调用remove，ThreadLocalMap在内部的set，get和扩容时都会清理掉泄漏的Entry，内存泄漏完全没必要过于担心
所以，ThreadLocal的建议使用方法：

设计为static的，被class对象给强引用，线程存活期间就不会被回收，也不用remove，完全不用担心内存泄漏

非static的，放置在长对象（比如被spring管理的对象）的内部，也不会被回收


​	个人也觉得没必要让创建的ThreadLocal对象生命周期过短，ThreadLocal被设计出来本身就是用来跨方法栈获取当前线程的数据或者无锁的获取线程安全的数据，空间交换了线程安全的上锁时间。只要让ThreadLocal具有线程的生命周期，就完全没必要使用remove方法，也完全不用担心内存泄漏的问题。
​	另外说一点，HashMap是使用拉链法解决hash冲突的，ThreadLocalMap是使用线性探测解决hash冲突的（内部只维护Entey数组，没有链表）。所以，源码中在清除泄漏的Entry时，会进行rehash，防止数组的当前位置为null后，有hash冲突的Entry访问不到的问题。
]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
</search>
